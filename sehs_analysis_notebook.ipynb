{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse-Engineering CPS Selective Enrollment Admissions: An MLE Approach\n",
    "\n",
    "## Recovering Hidden Population Parameters from Truncated Distributions via Maximum Likelihood Estimation, and Constructing a Monte-Carlo Physics Simulation Using These Parameters\n",
    "\n",
    "**Author:** Andrew Hood  \n",
    "**Date:** November 2025  \n",
    "**Data Source:** CPS Official 2024-2025 Cutoffs (released 3/14/2025)\n",
    "\n",
    "---\n",
    "\n",
    "### Abstract\n",
    "\n",
    "Chicago Public Schools (CPS) operates 11 Selective Enrollment High Schools (SEHS) where admission is determined by a composite score (grades + HSAT exam). CPS publishes cutoff scores and average scores of *admitted* students, but crucially, they do not publish the distribution of *all applicants*. Since we only observe students above a threshold, we're dealing with **truncated distributions**. This notebook develops a Maximum Likelihood Estimation (MLE) framework to recover the hidden population parameters $(\\mu, \\sigma)$ from the published truncated statistics, then uses these recovered parameters to inform a physics-based Monte Carlo simulation of the full admissions process.\n",
    "\n",
    "You can view this notebook online here:\n",
    "\n",
    "https://hub.2i2c.mybinder.org/user/homo-morphism-cps_match-j8vb0bcx/notebooks/sehs_analysis_notebook.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Background: The CPS Selective Enrollment System\n",
    "\n",
    "### 1.1 Institutional Context\n",
    "\n",
    "Chicago Public Schools (CPS) operates 11 Selective Enrollment High Schools (SEHS), the most academically competitive public high schools in the city. These schools admit students based on a **composite score** ranging from 0 to 900 points:\n",
    "\n",
    "$$\\text{Composite Score} = \\text{Grades Component (0-450)} + \\text{HSAT Score (0-450)}$$\n",
    "\n",
    "The Grades Component derives from 7th grade coursework in core subjects (Math, English, Science, Social Studies). The HSAT (High School Admissions Test) is a standardized exam administered by CPS each fall.\n",
    "\n",
    "### 1.2 The Tier System: Designing for Socioeconomic Diversity\n",
    "\n",
    "CPS faces a fundamental tension: selective schools should admit the highest-achieving students, but without intervention, this would disproportionately favor students from affluent neighborhoods with better-resourced elementary schools. The **tier system** addresses this by segmenting the city into four socioeconomic tiers based on census tract characteristics:\n",
    "\n",
    "| Tier | Socioeconomic Status | Typical Characteristics |\n",
    "|------|---------------------|------------------------|\n",
    "| Tier 1 | Lowest | High poverty rate, low median income, low homeownership |\n",
    "| Tier 2 | Below average | Moderate poverty, below-average income |\n",
    "| Tier 3 | Above average | Low poverty, above-average income |\n",
    "| Tier 4 | Highest | Very low poverty, high income, high educational attainment |\n",
    "\n",
    "Each census tract is assigned to exactly one tier based on a composite index. Students inherit the tier of their home address, not their elementary school.\n",
    "\n",
    "### 1.3 Seat Allocation: The 30/70 Split\n",
    "\n",
    "Each school allocates seats in two phases:\n",
    "\n",
    "**Phase 1: Rank-Based (30% of seats)**\n",
    "- The top 30% of seats go to the highest-scoring applicants *citywide*, regardless of tier.\n",
    "- This rewards absolute academic excellence.\n",
    "- In practice, these seats are dominated by Tier 3 and Tier 4 students.\n",
    "\n",
    "**Phase 2: Tier-Based (70% of seats)**\n",
    "- The remaining 70% is divided equally among the four tiers (17.5% each).\n",
    "- Within each tier, seats go to the highest-scoring applicants *from that tier*.\n",
    "- This ensures each socioeconomic group has guaranteed representation.\n",
    "\n",
    "### 1.4 The Serial Dictatorship Matching Mechanism\n",
    "\n",
    "CPS uses a **serial dictatorship** (also called **deferred acceptance** in mechanism design) to match students to schools:\n",
    "\n",
    "1. **Application phase**: Each student submits a ranked list of up to 6 SEHS schools.\n",
    "2. **Sorting phase**: Students are sorted by composite score (ties broken by lottery).\n",
    "3. **Matching phase**: Students are processed in score order. Each student is assigned to their highest-ranked school with available seats in their allocation category (Rank or Tier).\n",
    "4. **Cutoff determination**: The cutoff for each school-tier combination is the score of the last admitted student.\n",
    "\n",
    "This mechanism is **strategy-proof**: students should truthfully rank schools by preference, not by perceived admission chances. It is also **Pareto-efficient**: no reallocation can make a student better off without making another worse off.\n",
    "\n",
    "### 1.5 The Data Availability Problem\n",
    "\n",
    "CPS publishes:\n",
    "- **Cutoff scores**: Minimum score for admission by tier at each school\n",
    "- **Average scores**: Mean score of *admitted* students by tier\n",
    "- **Maximum scores**: Highest score among admitted students by tier\n",
    "\n",
    "CPS does **not** publish:\n",
    "- The full distribution of applicant scores (rejected + admitted)\n",
    "- The number of applicants by tier at each school\n",
    "- Individual-level application or outcome data\n",
    "\n",
    "This creates a **truncation problem**: we observe only the right tail of the score distribution (students at or above the cutoff). The published \"average\" is not the population mean; it is the mean of a truncated distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Truncation Problem: Mathematical Framework\n",
    "\n",
    "### 2.1 Notation and Setup\n",
    "\n",
    "Let $X$ denote the random variable representing applicant scores within a given tier. I model this as:\n",
    "\n",
    "$$X \\sim \\mathcal{N}(\\mu, \\sigma^2)$$\n",
    "\n",
    "**Notation:**\n",
    "- $\\mu$ = population mean (the true average score of *all* applicants in this tier, not just those admitted)\n",
    "- $\\sigma$ = population standard deviation (the spread of scores among all applicants)\n",
    "- $c$ = cutoff score (the minimum score for admission)\n",
    "- $M$ = maximum possible score (900 in the CPS system)\n",
    "\n",
    "**Justification for the normality assumption**: Composite scores are the sum of two components, each aggregating multiple sub-scores (grades across subjects, exam scores across sections). By the Central Limit Theorem, such sums tend toward normality for large populations. This assumption is standard in educational measurement. However, I later relax this in the simulation by using skewed normal distributions to capture empirical deviations from symmetry.\n",
    "\n",
    "### 2.2 The Truncated Distribution\n",
    "\n",
    "CPS admits students with $X \\geq c$, where $c$ is the cutoff. The *observed* data comes from the **truncated distribution**:\n",
    "\n",
    "$$X \\mid X \\geq c$$\n",
    "\n",
    "The critical insight is that the observed mean is systematically biased upward:\n",
    "\n",
    "$$\\bar{X}_{\\text{observed}} = \\mathbb{E}[X \\mid X \\geq c] > \\mu$$\n",
    "\n",
    "This bias is called **selection bias** or **truncation bias**. It arises because we only see high scorers; the full population includes many students who scored below the cutoff and were rejected.\n",
    "\n",
    "### 2.3 The Truncated Normal Mean Formula\n",
    "\n",
    "For a normal distribution truncated to the interval $[c, M]$, the conditional expectation is:\n",
    "\n",
    "$$\\mathbb{E}[X \\mid c \\leq X \\leq M] = \\mu + \\sigma \\cdot \\frac{\\phi(\\alpha) - \\phi(\\beta)}{\\Phi(\\beta) - \\Phi(\\alpha)}$$\n",
    "\n",
    "where:\n",
    "- $\\alpha = \\frac{c - \\mu}{\\sigma}$ is the standardized lower bound (cutoff in $z$-score units)\n",
    "- $\\beta = \\frac{M - \\mu}{\\sigma}$ is the standardized upper bound\n",
    "- $\\phi(\\cdot)$ is the standard normal PDF: $\\phi(z) = \\frac{1}{\\sqrt{2\\pi}} e^{-z^2/2}$\n",
    "- $\\Phi(\\cdot)$ is the standard normal CDF: $\\Phi(z) = \\int_{-\\infty}^{z} \\phi(t) \\, dt$\n",
    "\n",
    "The ratio $\\lambda(\\alpha) = \\frac{\\phi(\\alpha)}{1 - \\Phi(\\alpha)}$ is the **inverse Mills ratio** (or **hazard rate** of the standard normal). It quantifies how much truncation inflates the observed mean. When $\\alpha$ is large (cutoff far above the mean), $\\lambda(\\alpha)$ is large, and selection bias is severe.\n",
    "\n",
    "### 2.4 The Identification Problem\n",
    "\n",
    "Given only:\n",
    "- The truncated mean $\\bar{X}_{\\text{obs}}$ (published by CPS as \"average score\")\n",
    "- The cutoff $c$ (published by CPS)\n",
    "\n",
    "I have **one equation in two unknowns** $(\\mu, \\sigma)$. The locus of solutions forms a curve (often called a \"banana\" due to its shape in parameter space). Many different $(\\mu, \\sigma)$ pairs produce the same truncated mean.\n",
    "\n",
    "**Solution: Add a second constraint.** I use the **acceptance rate**:\n",
    "\n",
    "$$P(X \\geq c) = 1 - \\Phi\\left(\\frac{c - \\mu}{\\sigma}\\right) = \\frac{\\text{seats}}{\\text{applicants}} \\equiv r$$\n",
    "\n",
    "With two independent constraints (truncated mean and acceptance rate), I can uniquely identify both $\\mu$ and $\\sigma$.\n",
    "\n",
    "**Caveat**: CPS does not publish tier-specific applicant counts. I estimate the acceptance rate $r$ using total seat counts and city-wide applicant estimates. This introduces some uncertainty, but sensitivity analysis shows the MLE results are robust to reasonable variations in $r$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T10:38:08.677500Z",
     "start_time": "2025-11-29T10:38:08.674491Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# LIBRARY IMPORTS AND CONFIGURATION\n",
    "# ==============================================================================\n",
    "#\n",
    "# This cell loads all required libraries for the analysis:\n",
    "#   - numpy: Array operations and random number generation\n",
    "#   - pandas: DataFrame manipulation for tabular data\n",
    "#   - matplotlib/seaborn: Visualization\n",
    "#   - scipy.stats: Statistical distributions (norm, skewnorm) and optimization\n",
    "#   - dataclasses: Structured containers for tier data and results\n",
    "#\n",
    "# I suppress optimization warnings because L-BFGS-B may not converge perfectly\n",
    "# for edge cases (e.g., schools with very low cutoffs), but the results are\n",
    "# still usable.\n",
    "# ==============================================================================\n",
    "\n",
    "import numpy as np                          # Numerical array operations\n",
    "import pandas as pd                         # DataFrame manipulation\n",
    "import matplotlib.pyplot as plt             # Core plotting library\n",
    "import seaborn as sns                       # Statistical visualization\n",
    "from scipy import stats, optimize           # Distributions and optimization\n",
    "from scipy.stats import skewnorm            # Skewed normal distribution for simulation\n",
    "from dataclasses import dataclass           # Structured data containers\n",
    "from typing import Optional, Dict, List, Tuple, Callable\n",
    "import warnings\n",
    "\n",
    "# Suppress convergence warnings from optimizer\n",
    "# These occur for schools with extreme parameters (e.g., very tight T4 at elite schools)\n",
    "# and do not affect the validity of results\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure plot aesthetics for publication-quality figures\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\", font_scale=1.1)\n",
    "\n",
    "# Set global random seed for reproducibility\n",
    "# All stochastic operations (simulation, Monte Carlo validation) use this seed\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(\"Libraries loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MLE Framework Implementation\n",
    "\n",
    "### 3.1 Core Mathematical Functions\n",
    "\n",
    "I now implement the truncated normal distribution formulas from Section 2. The two key functions are:\n",
    "\n",
    "1. **`truncated_mean(mu, sigma, lower, upper)`**: Computes $\\mathbb{E}[X \\mid c \\leq X \\leq M]$\n",
    "2. **`acceptance_prob(mu, sigma, cutoff)`**: Computes $P(X \\geq c) = 1 - \\Phi\\left(\\frac{c-\\mu}{\\sigma}\\right)$\n",
    "\n",
    "**Variable-to-LaTeX correspondence:**\n",
    "\n",
    "| Code Variable | LaTeX Symbol | Meaning |\n",
    "|---------------|--------------|---------|\n",
    "| `mu` | $\\mu$ | Population mean (hidden, to be estimated) |\n",
    "| `sigma` | $\\sigma$ | Population standard deviation (hidden) |\n",
    "| `lower` | $c$ | Cutoff score (lower truncation point) |\n",
    "| `upper` | $M$ | Maximum score (900; upper truncation point) |\n",
    "| `alpha` | $\\alpha$ | Standardized lower bound: $(c - \\mu)/\\sigma$ |\n",
    "| `beta` | $\\beta$ | Standardized upper bound: $(M - \\mu)/\\sigma$ |\n",
    "| `phi` | $\\phi$ | Standard normal PDF |\n",
    "| `Phi` | $\\Phi$ | Standard normal CDF |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T10:38:20.598324Z",
     "start_time": "2025-11-29T10:38:20.594307Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# GLOBAL CONSTANTS\n",
    "# ==============================================================================\n",
    "# M: Maximum possible composite score in the CPS system.\n",
    "#    This acts as the implicit upper bound for truncation.\n",
    "#    In LaTeX: M = 900\n",
    "# ==============================================================================\n",
    "MAX_SCORE = 900  # M in LaTeX notation\n",
    "\n",
    "\n",
    "def truncated_mean(mu: float, sigma: float, lower: float, upper: float = MAX_SCORE) -> float:\n",
    "    \"\"\"\n",
    "    Compute the expected value of a normal distribution truncated to [lower, upper].\n",
    "    \n",
    "    Implements the formula:\n",
    "        E[X | c <= X <= M] = mu + sigma * (phi(alpha) - phi(beta)) / (Phi(beta) - Phi(alpha))\n",
    "    \n",
    "    where:\n",
    "        alpha = (c - mu) / sigma    (standardized lower bound)\n",
    "        beta  = (M - mu) / sigma    (standardized upper bound)\n",
    "        phi   = standard normal PDF\n",
    "        Phi   = standard normal CDF\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mu : float\n",
    "        Population mean of the untruncated distribution (the hidden parameter we estimate).\n",
    "        In LaTeX: mu\n",
    "    sigma : float\n",
    "        Population standard deviation (the hidden spread parameter).\n",
    "        In LaTeX: sigma\n",
    "    lower : float\n",
    "        Lower truncation point (the cutoff score c).\n",
    "        In LaTeX: c\n",
    "    upper : float\n",
    "        Upper truncation point (default: MAX_SCORE = 900).\n",
    "        In LaTeX: M\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The conditional expectation E[X | c <= X <= M].\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    When the probability mass in [lower, upper] is negligible (< 1e-10),\n",
    "    the function returns NaN to signal a degenerate case.\n",
    "    \"\"\"\n",
    "    # Compute standardized bounds\n",
    "    # alpha = (c - mu) / sigma: how many standard deviations the cutoff is above the mean\n",
    "    # beta = (M - mu) / sigma: how many standard deviations the max score is above the mean\n",
    "    alpha = (lower - mu) / sigma\n",
    "    beta = (upper - mu) / sigma\n",
    "    \n",
    "    # Get standard normal PDF (phi) and CDF (Phi) from scipy\n",
    "    phi = stats.norm.pdf  # phi(z) = (1/sqrt(2*pi)) * exp(-z^2 / 2)\n",
    "    Phi = stats.norm.cdf  # Phi(z) = integral_{-inf}^{z} phi(t) dt\n",
    "    \n",
    "    # Compute probability mass in the truncation region\n",
    "    # This is P(c <= X <= M) = Phi(beta) - Phi(alpha)\n",
    "    prob_mass = Phi(beta) - Phi(alpha)\n",
    "    \n",
    "    # Handle degenerate case: if almost no probability mass in region, return NaN\n",
    "    # This can happen if cutoff is extremely high relative to the mean\n",
    "    if prob_mass < 1e-10:\n",
    "        return np.nan\n",
    "    \n",
    "    # Apply the truncated mean formula\n",
    "    # The numerator (phi(alpha) - phi(beta)) / prob_mass is the \"correction factor\"\n",
    "    # that quantifies the selection bias from observing only the truncated region\n",
    "    truncated_expectation = mu + sigma * (phi(alpha) - phi(beta)) / prob_mass\n",
    "    \n",
    "    return truncated_expectation\n",
    "\n",
    "\n",
    "def acceptance_prob(mu: float, sigma: float, cutoff: float) -> float:\n",
    "    \"\"\"\n",
    "    Compute the probability that a randomly drawn score exceeds the cutoff.\n",
    "    \n",
    "    Implements:\n",
    "        P(X >= c) = 1 - Phi((c - mu) / sigma)\n",
    "    \n",
    "    This represents the fraction of applicants who score at or above the cutoff,\n",
    "    i.e., the acceptance rate if all applicants above the cutoff were admitted.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mu : float\n",
    "        Population mean. In LaTeX: mu\n",
    "    sigma : float\n",
    "        Population standard deviation. In LaTeX: sigma\n",
    "    cutoff : float\n",
    "        Admission cutoff score. In LaTeX: c\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        P(X >= c), the probability of exceeding the cutoff.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    This is the second constraint used to identify (mu, sigma).\n",
    "    The target acceptance rate r = seats / applicants.\n",
    "    \"\"\"\n",
    "    # P(X >= c) = 1 - P(X < c) = 1 - Phi((c - mu) / sigma)\n",
    "    # Using scipy's norm.cdf with loc=mu, scale=sigma\n",
    "    return 1.0 - stats.norm.cdf(cutoff, loc=mu, scale=sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Demonstrating Selection Bias\n",
    "\n",
    "Before fitting the full model, I demonstrate the magnitude of selection bias with a concrete example. Consider a hypothetical tier where:\n",
    "- True population mean $\\mu = 700$ points\n",
    "- True population standard deviation $\\sigma = 80$ points\n",
    "- Cutoff score $c = 800$ points\n",
    "\n",
    "The cutoff is 1.25 standard deviations above the mean, so only about 10% of applicants are admitted. For those who *are* admitted, what is their average score?\n",
    "\n",
    "The truncated mean will be **substantially higher** than 700 because we only observe the right tail of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T10:38:40.922331Z",
     "start_time": "2025-11-29T10:38:40.918617Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# DEMONSTRATION: SELECTION BIAS IN TRUNCATED DISTRIBUTIONS\n",
    "# ==============================================================================\n",
    "# This example shows how truncation inflates the observed mean.\n",
    "#\n",
    "# Variables (LaTeX correspondence):\n",
    "#   mu_true    -> mu     : true population mean (700)\n",
    "#   sigma_true -> sigma  : true population std dev (80)\n",
    "#   cutoff     -> c      : admission cutoff (800)\n",
    "#   trunc_mean -> E[X|X>=c] : expected value given admission\n",
    "#   accept_rate -> P(X>=c)  : probability of admission\n",
    "#   selection_bias -> E[X|X>=c] - mu : upward bias from truncation\n",
    "# ==============================================================================\n",
    "\n",
    "# Define hypothetical population parameters\n",
    "# These represent the TRUE (hidden) distribution of ALL applicants\n",
    "mu_true = 700       # mu: True population mean\n",
    "sigma_true = 80     # sigma: True population standard deviation\n",
    "cutoff = 800        # c: Admission cutoff (only X >= 800 are admitted)\n",
    "\n",
    "# Compute the truncated mean using our formula\n",
    "# This is what CPS would publish as the \"average admitted score\"\n",
    "trunc_mean = truncated_mean(mu_true, sigma_true, cutoff)\n",
    "\n",
    "# Selection bias: the difference between observed and true mean\n",
    "# This quantifies how much truncation inflates the published average\n",
    "selection_bias = trunc_mean - mu_true\n",
    "\n",
    "# Compute acceptance probability: P(X >= c)\n",
    "# This is the fraction of applicants who get admitted\n",
    "accept_rate = acceptance_prob(mu_true, sigma_true, cutoff)\n",
    "\n",
    "# Display results\n",
    "print(\"SELECTION BIAS DEMONSTRATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"True population mean (mu):           {mu_true}\")\n",
    "print(f\"True population std dev (sigma):     {sigma_true}\")\n",
    "print(f\"Cutoff score (c):                    {cutoff}\")\n",
    "print(f\"Z-score of cutoff: (c - mu)/sigma =  {(cutoff - mu_true)/sigma_true:.2f}\")\n",
    "print()\n",
    "print(f\"Truncated mean E[X | X >= c]:        {trunc_mean:.1f}\")\n",
    "print(f\"Selection bias (E[X|X>=c] - mu):     +{selection_bias:.1f} points\")\n",
    "print(f\"Acceptance rate P(X >= c):           {accept_rate:.1%}\")\n",
    "print()\n",
    "print(\"INTERPRETATION:\")\n",
    "print(f\"  If CPS published an 'average score' of {trunc_mean:.0f}, a naive reader\")\n",
    "print(f\"  might conclude the typical applicant scores around {trunc_mean:.0f}.\")\n",
    "print(f\"  In fact, the true population mean is only {mu_true}.\")\n",
    "print(f\"  The {selection_bias:.0f}-point gap is pure selection bias.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Data Structures\n",
    "\n",
    "I define two dataclasses to organize the analysis:\n",
    "\n",
    "**TierData**: Holds the *observed* (public) data for a single tier at a school.\n",
    "- `cutoff`: The published minimum score $c$ for admission\n",
    "- `observed_mean`: The published average score $\\bar{X}_{\\text{obs}}$ of admitted students\n",
    "- `seats` and `applicants`: Used to compute the target acceptance rate $r$\n",
    "\n",
    "**FittedTier**: Holds the *estimated* (recovered) parameters after MLE.\n",
    "- `mu` and `sigma`: The MLE estimates $\\hat{\\mu}$ and $\\hat{\\sigma}$\n",
    "- `selection_bias`: The difference $\\bar{X}_{\\text{obs}} - \\hat{\\mu}$\n",
    "\n",
    "**Variable-to-LaTeX correspondence:**\n",
    "\n",
    "| Code Variable | LaTeX Symbol | Meaning |\n",
    "|---------------|--------------|---------|\n",
    "| `cutoff` | $c$ | Admission cutoff (observed) |\n",
    "| `observed_mean` | $\\bar{X}_{\\text{obs}}$ | Published average of admitted students |\n",
    "| `seats` | - | Number of seats at the school for this tier |\n",
    "| `applicants` | - | Estimated applicants for this tier |\n",
    "| `target_accept_rate` | $r$ | seats / applicants |\n",
    "| `mu` | $\\hat{\\mu}$ | MLE estimate of population mean |\n",
    "| `sigma` | $\\hat{\\sigma}$ | MLE estimate of population std dev |\n",
    "| `selection_bias` | $\\bar{X}_{\\text{obs}} - \\hat{\\mu}$ | Truncation-induced bias |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T10:38:55.118026Z",
     "start_time": "2025-11-29T10:38:55.114209Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# DATA STRUCTURES FOR MLE ANALYSIS\n",
    "# ==============================================================================\n",
    "# These dataclasses organize the input data and output results.\n",
    "# Using dataclasses provides type safety and clean attribute access.\n",
    "# ==============================================================================\n",
    "\n",
    "@dataclass\n",
    "class TierData:\n",
    "    \"\"\"\n",
    "    Container for OBSERVED (public) data about a single tier at a school.\n",
    "    \n",
    "    This represents information CPS publishes. The goal of MLE is to recover\n",
    "    the hidden parameters (mu, sigma) that generated this observed data.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    name : str\n",
    "        Tier identifier, e.g., \"Tier 1\", \"Tier 4\"\n",
    "    \n",
    "    cutoff : float\n",
    "        Minimum score for admission (c in LaTeX).\n",
    "        This is the score of the last admitted student.\n",
    "    \n",
    "    observed_mean : float or None\n",
    "        Mean score of ADMITTED students (X_bar_obs in LaTeX).\n",
    "        IMPORTANT: This is NOT the population mean. It is the truncated mean,\n",
    "        which is systematically higher than mu due to selection.\n",
    "    \n",
    "    seats : float\n",
    "        Number of seats allocated to this tier at this school.\n",
    "        CPS allocates 17.5% of seats to each tier (70% total / 4 tiers).\n",
    "    \n",
    "    applicants : float\n",
    "        Estimated number of applicants from this tier.\n",
    "        CPS does not publish this; I estimate from total applicants / 4.\n",
    "    \"\"\"\n",
    "    name: str\n",
    "    cutoff: float\n",
    "    observed_mean: Optional[float]\n",
    "    seats: float\n",
    "    applicants: float\n",
    "    \n",
    "    @property\n",
    "    def target_accept_rate(self) -> float:\n",
    "        \"\"\"\n",
    "        Compute target acceptance rate r = seats / applicants.\n",
    "        \n",
    "        This is the second constraint for MLE. If we know r and c, combined\n",
    "        with the truncated mean constraint, we can uniquely identify (mu, sigma).\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            The implied acceptance rate (fraction of applicants admitted).\n",
    "        \"\"\"\n",
    "        return self.seats / self.applicants\n",
    "\n",
    "\n",
    "@dataclass  \n",
    "class FittedTier:\n",
    "    \"\"\"\n",
    "    Container for MLE ESTIMATION RESULTS for a single tier.\n",
    "    \n",
    "    After optimization, this holds the recovered hidden parameters.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    name : str\n",
    "        Tier identifier (copied from input TierData)\n",
    "    \n",
    "    mu : float\n",
    "        MLE estimate of population mean (mu_hat in LaTeX).\n",
    "        This is the TRUE average score of ALL applicants in this tier,\n",
    "        not just those who were admitted.\n",
    "    \n",
    "    sigma : float\n",
    "        MLE estimate of population standard deviation (sigma_hat).\n",
    "        This measures the spread of scores among ALL applicants.\n",
    "    \n",
    "    cutoff : float\n",
    "        Cutoff score (copied from input; c in LaTeX)\n",
    "    \n",
    "    fitted_mean : float\n",
    "        Truncated mean computed from fitted (mu_hat, sigma_hat).\n",
    "        Should match observed_mean if the fit is good.\n",
    "    \n",
    "    fitted_accept_rate : float\n",
    "        Acceptance probability computed from fitted parameters.\n",
    "        Should match target_accept_rate if the fit is good.\n",
    "    \n",
    "    selection_bias : float\n",
    "        Difference between observed_mean and mu_hat.\n",
    "        Quantifies how much truncation inflates the published average.\n",
    "        Larger bias indicates more severe truncation (cutoff far above mean).\n",
    "    \"\"\"\n",
    "    name: str\n",
    "    mu: float\n",
    "    sigma: float\n",
    "    cutoff: float\n",
    "    fitted_mean: float\n",
    "    fitted_accept_rate: float\n",
    "    selection_bias: float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 The MLE Fitting Function\n",
    "\n",
    "I recover $(\\mu, \\sigma)$ by minimizing a weighted loss function that combines two constraints:\n",
    "\n",
    "$$\\mathcal{L}(\\mu, \\sigma) = \\underbrace{\\left(\\mathbb{E}[X|X \\geq c; \\mu, \\sigma] - \\bar{X}_{\\text{obs}}\\right)^2}_{\\text{Constraint 1: Match truncated mean}} + \\lambda \\underbrace{\\left(P(X \\geq c; \\mu, \\sigma) - r\\right)^2}_{\\text{Constraint 2: Match acceptance rate}}$$\n",
    "\n",
    "where:\n",
    "- $\\bar{X}_{\\text{obs}}$ is the observed (truncated) mean from CPS data\n",
    "- $r = \\text{seats} / \\text{applicants}$ is the target acceptance rate\n",
    "- $\\lambda = 100$ is a weighting parameter\n",
    "\n",
    "**Why $\\lambda = 100$?** The two constraint terms have different scales:\n",
    "- Mean errors are typically $O(1)$ to $O(10)$ points, so squared errors are $O(1)$ to $O(100)$\n",
    "- Acceptance rate errors are typically $O(0.01)$ to $O(0.1)$, so squared errors are $O(0.0001)$ to $O(0.01)$\n",
    "\n",
    "Without weighting, the optimizer would prioritize the mean constraint and ignore the acceptance rate. Setting $\\lambda = 100$ brings both terms to comparable scales, ensuring both constraints influence the solution.\n",
    "\n",
    "**Optimization details:**\n",
    "- I use L-BFGS-B, a quasi-Newton method that supports box constraints\n",
    "- $\\mu$ is constrained to $[100, 890]$ (must be below the max score)\n",
    "- $\\sigma$ is constrained to $[5, 200]$ (prevents degenerate solutions)\n",
    "- Initial guesses are tier-specific: lower $\\mu$ for Tier 1, higher for Tier 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T10:39:43.730580Z",
     "start_time": "2025-11-29T10:39:43.726308Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# MAXIMUM LIKELIHOOD ESTIMATION FUNCTION\n",
    "# ==============================================================================\n",
    "# This function recovers the hidden parameters (mu, sigma) by minimizing a\n",
    "# weighted sum of squared constraint violations.\n",
    "#\n",
    "# Variables (LaTeX correspondence):\n",
    "#   mu        -> mu          : population mean (parameter to estimate)\n",
    "#   sigma     -> sigma       : population std dev (parameter to estimate)\n",
    "#   theor_mean -> E[X|X>=c]  : theoretical truncated mean given (mu, sigma)\n",
    "#   theor_accept -> P(X>=c)  : theoretical acceptance prob given (mu, sigma)\n",
    "#   mean_error -> (E[X|X>=c] - X_bar_obs)^2 : squared error for mean constraint\n",
    "#   accept_error -> (P(X>=c) - r)^2        : squared error for acceptance constraint\n",
    "#   accept_weight -> lambda  : weighting parameter (100)\n",
    "# ==============================================================================\n",
    "\n",
    "def fit_tier_mle(tier: TierData, \n",
    "                 use_accept_rate: bool = True,\n",
    "                 accept_weight: float = 100.0) -> FittedTier:\n",
    "    \"\"\"\n",
    "    Recover hidden population parameters (mu, sigma) via constrained optimization.\n",
    "    \n",
    "    The objective function is:\n",
    "        L(mu, sigma) = (E[X|X>=c] - X_obs)^2 + lambda * (P(X>=c) - r)^2\n",
    "    \n",
    "    where lambda = accept_weight balances the two constraints.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tier : TierData\n",
    "        Observed data for this tier (cutoff, mean, seats, applicants)\n",
    "    \n",
    "    use_accept_rate : bool, default=True\n",
    "        Whether to include the acceptance rate constraint.\n",
    "        If False, only the mean constraint is used (underidentified).\n",
    "    \n",
    "    accept_weight : float, default=100.0\n",
    "        Weight lambda on the acceptance rate constraint.\n",
    "        Chosen to balance the scales of mean errors (~O(1-10)) and\n",
    "        acceptance rate errors (~O(0.01-0.1)).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    FittedTier\n",
    "        MLE estimates (mu_hat, sigma_hat) and derived quantities.\n",
    "    \"\"\"\n",
    "    \n",
    "    def loss(params: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Objective function to minimize.\n",
    "        \n",
    "        L(mu, sigma) = mean_error + lambda * accept_error\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        params : ndarray of shape (2,)\n",
    "            params[0] = mu (population mean)\n",
    "            params[1] = sigma (population std dev)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            Total loss value (sum of squared constraint violations)\n",
    "        \"\"\"\n",
    "        mu, sigma = params\n",
    "        \n",
    "        # Reject invalid parameter values with a large penalty\n",
    "        # sigma must be positive; mu must be in a reasonable range\n",
    "        if sigma <= 0 or mu <= 0 or mu >= MAX_SCORE:\n",
    "            return 1e10\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        \n",
    "        # ---------------------------------------------------------------------\n",
    "        # CONSTRAINT 1: Truncated mean must match observed mean\n",
    "        # ---------------------------------------------------------------------\n",
    "        # The truncated mean E[X|X>=c] depends on (mu, sigma) and the cutoff c.\n",
    "        # We want to find (mu, sigma) such that this matches the published average.\n",
    "        if tier.observed_mean is not None:\n",
    "            # Compute E[X | X >= c] using the formula from Section 2.3\n",
    "            theor_mean = truncated_mean(mu, sigma, tier.cutoff)\n",
    "            \n",
    "            # Handle numerical issues (e.g., if cutoff is way above mu)\n",
    "            if np.isnan(theor_mean):\n",
    "                return 1e10\n",
    "            \n",
    "            # Squared error: (E[X|X>=c] - X_bar_obs)^2\n",
    "            mean_error = (theor_mean - tier.observed_mean) ** 2\n",
    "            total_loss += mean_error\n",
    "        \n",
    "        # ---------------------------------------------------------------------\n",
    "        # CONSTRAINT 2: Acceptance rate must match target\n",
    "        # ---------------------------------------------------------------------\n",
    "        # P(X >= c) = 1 - Phi((c - mu)/sigma) should equal seats/applicants\n",
    "        if use_accept_rate:\n",
    "            # Compute P(X >= c)\n",
    "            theor_accept = acceptance_prob(mu, sigma, tier.cutoff)\n",
    "            \n",
    "            # Squared error: (P(X>=c) - r)^2\n",
    "            accept_error = (theor_accept - tier.target_accept_rate) ** 2\n",
    "            \n",
    "            # Apply weighting to balance scales\n",
    "            # lambda = 100 makes accept_error comparable to mean_error\n",
    "            total_loss += accept_weight * accept_error\n",
    "        \n",
    "        return total_loss\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # INITIAL GUESSES (tier-specific to improve convergence)\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Tier 1 (disadvantaged): Expect lower mean, wider spread\n",
    "    # Tier 4 (affluent): Expect higher mean, tighter spread\n",
    "    # These are rough guesses; the optimizer will refine them.\n",
    "    if \"1\" in tier.name:\n",
    "        start_mu, start_sigma = 600, 100\n",
    "    elif \"4\" in tier.name:\n",
    "        start_mu, start_sigma = 820, 50\n",
    "    else:\n",
    "        start_mu, start_sigma = 700, 70\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # RUN OPTIMIZATION\n",
    "    # -------------------------------------------------------------------------\n",
    "    # L-BFGS-B is a quasi-Newton method that supports box constraints.\n",
    "    # It approximates the Hessian using gradient information.\n",
    "    result = optimize.minimize(\n",
    "        loss,\n",
    "        x0=[start_mu, start_sigma],     # Starting point\n",
    "        method='L-BFGS-B',              # Optimizer choice\n",
    "        bounds=[(100, 890), (5, 200)]   # Box constraints on (mu, sigma)\n",
    "    )\n",
    "    \n",
    "    # Extract the MLE estimates\n",
    "    mu_hat, sigma_hat = result.x\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # COMPUTE DERIVED QUANTITIES FOR VALIDATION\n",
    "    # -------------------------------------------------------------------------\n",
    "    # These allow us to verify the fit quality\n",
    "    fitted_mean = truncated_mean(mu_hat, sigma_hat, tier.cutoff)\n",
    "    fitted_accept = acceptance_prob(mu_hat, sigma_hat, tier.cutoff)\n",
    "    \n",
    "    # Selection bias: how much higher the observed mean is than the true mean\n",
    "    # This is the key quantity we are recovering\n",
    "    if tier.observed_mean is not None:\n",
    "        selection_bias = tier.observed_mean - mu_hat\n",
    "    else:\n",
    "        selection_bias = fitted_mean - mu_hat\n",
    "    \n",
    "    return FittedTier(\n",
    "        name=tier.name,\n",
    "        mu=mu_hat,\n",
    "        sigma=sigma_hat,\n",
    "        cutoff=tier.cutoff,\n",
    "        fitted_mean=fitted_mean,\n",
    "        fitted_accept_rate=fitted_accept,\n",
    "        selection_bias=selection_bias\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. MLE Analysis: All 11 SEHS Schools\n",
    "\n",
    "### 4.1 Data from CPS 2024-2025 Report\n",
    "\n",
    "The following data comes from the official CPS document *\"Initial Offer Point Totals for Selective Enrollment High Schools 2025-2026\"*, released March 14, 2025. For each school and tier, I extracted:\n",
    "- **Cutoff** ($c$): Minimum score for admission (the \"Min Point Total\" column)\n",
    "- **Average** ($\\bar{X}_{\\text{obs}}$): Mean score of admitted students (the \"Average Point Total\" column)\n",
    "\n",
    "**Assumptions about applicant counts:**\n",
    "\n",
    "CPS does not publish tier-specific applicant counts. I estimate these as follows:\n",
    "1. **Total applicants**: I use historical enrollment data and reported application volumes. For highly competitive schools (Payton, Lane Tech), applicant counts are much higher relative to seat counts.\n",
    "2. **Per-tier distribution**: I assume applicants are uniformly distributed across tiers (25% each). This is a simplification; in reality, Tier 4 may be over-represented at elite North Side schools.\n",
    "\n",
    "These estimates affect the acceptance rate constraint but not the truncated mean constraint. Sensitivity analysis shows the MLE results are robust to $\\pm 20\\%$ variations in applicant estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T10:39:50.788888Z",
     "start_time": "2025-11-29T10:39:50.782892Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CPS 2024-2025 OFFICIAL DATA\n",
    "# ==============================================================================\n",
    "# Source: \"Initial Offer Point Totals for Selective Enrollment High Schools 2025-2026\"\n",
    "#         Published by Chicago Public Schools, released March 14, 2025\n",
    "#\n",
    "# Data structure for each school:\n",
    "#   seats           : Total freshmen seats at the school\n",
    "#   total_applicants: Estimated total applicants (CPS does not publish this directly)\n",
    "#   tiers           : Dict mapping tier number (1-4) to {cutoff, avg}\n",
    "#       cutoff = \"Min Point Total\" from CPS report (admission threshold c)\n",
    "#       avg    = \"Average Point Total\" from CPS report (truncated mean X_bar_obs)\n",
    "#\n",
    "# Schools are grouped by selectivity:\n",
    "#   ELITE (North Side / Loop): Payton, Northside, Whitney Young, Jones, Lane Tech\n",
    "#   REGIONAL (South Side / West Side): Hancock, Lindblom, Brooks, Westinghouse, King, South Shore\n",
    "# ==============================================================================\n",
    "\n",
    "SCHOOL_DATA = {\n",
    "    # =========================================================================\n",
    "    # ELITE SCHOOLS (North Side / Loop)\n",
    "    # These schools have the highest cutoffs and most competitive T4 pools.\n",
    "    # T4 applicants at these schools often score 850-900.\n",
    "    # =========================================================================\n",
    "    \n",
    "    'Lane Tech': {\n",
    "        # Largest SEHS (1200 seats). Strong demand from North Side T3/T4.\n",
    "        # Lane has relatively balanced tier demand due to broad geographic draw.\n",
    "        'seats': 1200,\n",
    "        'total_applicants': 13000,  # High volume due to prestige + large class\n",
    "        'tiers': {\n",
    "            1: {'cutoff': 712, 'avg': 758.2},   # T1 cutoff ~800s at elite schools\n",
    "            2: {'cutoff': 780, 'avg': 814.5},\n",
    "            3: {'cutoff': 817.5, 'avg': 843.1},\n",
    "            4: {'cutoff': 859, 'avg': 867.1},   # T4 very competitive\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'Walter Payton': {\n",
    "        # Most competitive SEHS. T4 cutoff often approaches 900.\n",
    "        # Small class (350 seats) intensifies competition.\n",
    "        'seats': 350,\n",
    "        'total_applicants': 9000,  # Very high applications despite small size\n",
    "        'tiers': {\n",
    "            1: {'cutoff': 796, 'avg': 841.3},   # Even T1 requires ~800\n",
    "            2: {'cutoff': 864, 'avg': 885.5},\n",
    "            3: {'cutoff': 873, 'avg': 887.5},\n",
    "            4: {'cutoff': 898, 'avg': 899.7},   # Near-perfect scores required\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'Northside': {\n",
    "        # Second most competitive. Very tight T4 distribution.\n",
    "        # Strong preference from North Side families.\n",
    "        'seats': 300,\n",
    "        'total_applicants': 7000,\n",
    "        'tiers': {\n",
    "            1: {'cutoff': 706.5, 'avg': 768.5},\n",
    "            2: {'cutoff': 841, 'avg': 866.6},\n",
    "            3: {'cutoff': 861, 'avg': 879.9},\n",
    "            4: {'cutoff': 893, 'avg': 894.3},   # Extremely tight; avg only 1 point above cutoff\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'Whitney Young': {\n",
    "        # Downtown location draws from all regions.\n",
    "        # More diverse applicant pool geographically.\n",
    "        'seats': 350,\n",
    "        'total_applicants': 8000,\n",
    "        'tiers': {\n",
    "            1: {'cutoff': 807, 'avg': 846.0},\n",
    "            2: {'cutoff': 832, 'avg': 861.2},\n",
    "            3: {'cutoff': 861, 'avg': 875.2},\n",
    "            4: {'cutoff': 880, 'avg': 887.4},\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'Jones': {\n",
    "        # Loop location. Pre-engineering and pre-law tracks attract specific applicants.\n",
    "        # Generally similar to Whitney Young in competitiveness.\n",
    "        'seats': 375,\n",
    "        'total_applicants': 7500,\n",
    "        'tiers': {\n",
    "            1: {'cutoff': 775, 'avg': 815.7},\n",
    "            2: {'cutoff': 825, 'avg': 846.0},\n",
    "            3: {'cutoff': 834, 'avg': 852.7},\n",
    "            4: {'cutoff': 864, 'avg': 871.1},\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # =========================================================================\n",
    "    # REGIONAL SCHOOLS (South Side / West Side)\n",
    "    # Lower cutoffs reflect different applicant pools. Many of these schools\n",
    "    # draw primarily from their local community. Cutoffs can be 100-300 points\n",
    "    # lower than elite schools.\n",
    "    # =========================================================================\n",
    "    \n",
    "    'Hancock': {\n",
    "        # Northeast location (Bridgeport area). Draws from South Side T4.\n",
    "        # Note: T4 cutoff < T3 cutoff (unusual pattern due to applicant pool composition)\n",
    "        'seats': 250,\n",
    "        'total_applicants': 4000,\n",
    "        'tiers': {\n",
    "            1: {'cutoff': 746, 'avg': 779.3},\n",
    "            2: {'cutoff': 791, 'avg': 813.2},\n",
    "            3: {'cutoff': 805, 'avg': 821.7},\n",
    "            4: {'cutoff': 773, 'avg': 807.9},   # T4 < T3: high-scoring T4 go to elite schools\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'Lindblom': {\n",
    "        # South Side (Englewood). Has Academic Center feeding program.\n",
    "        # T4 cutoff is notably low, reflecting South Side T4 pool dynamics.\n",
    "        'seats': 300,\n",
    "        'total_applicants': 4500,\n",
    "        'tiers': {\n",
    "            1: {'cutoff': 691, 'avg': 720.1},\n",
    "            2: {'cutoff': 707, 'avg': 728.5},\n",
    "            3: {'cutoff': 725, 'avg': 745.4},\n",
    "            4: {'cutoff': 600.5, 'avg': 667.4},  # Very low T4 cutoff\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'Brooks': {\n",
    "        # Far South Side (Roseland). Similar dynamics to Lindblom.\n",
    "        # T4 cutoff again below T3, consistent with elite school siphoning.\n",
    "        'seats': 350,\n",
    "        'total_applicants': 4000,\n",
    "        'tiers': {\n",
    "            1: {'cutoff': 689.5, 'avg': 729.0},\n",
    "            2: {'cutoff': 737, 'avg': 764.7},\n",
    "            3: {'cutoff': 761, 'avg': 782.1},\n",
    "            4: {'cutoff': 706.5, 'avg': 747.7},\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'Westinghouse': {\n",
    "        # West Side (East Garfield Park). Draws primarily from West Side.\n",
    "        # T4 cutoff reflects West Side T4 pool (higher than South Side T4).\n",
    "        'seats': 300,\n",
    "        'total_applicants': 3500,\n",
    "        'tiers': {\n",
    "            1: {'cutoff': 662.5, 'avg': 700.2},\n",
    "            2: {'cutoff': 699.5, 'avg': 730.7},\n",
    "            3: {'cutoff': 689.5, 'avg': 726.9},  # T3 < T2 (unusual)\n",
    "            4: {'cutoff': 635.5, 'avg': 703.6},\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'King': {\n",
    "        # South Side (Bronzeville). Has the lowest cutoffs in the system.\n",
    "        # Reflects the socioeconomic challenges of the surrounding community.\n",
    "        'seats': 250,\n",
    "        'total_applicants': 3000,\n",
    "        'tiers': {\n",
    "            1: {'cutoff': 507, 'avg': 567.0},   # Lowest T1 cutoff\n",
    "            2: {'cutoff': 518, 'avg': 569.0},\n",
    "            3: {'cutoff': 514.5, 'avg': 577.5},\n",
    "            4: {'cutoff': 507.5, 'avg': 573.1}, # T4 essentially same as T1\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'South Shore': {\n",
    "        # Far South Side. Second lowest cutoffs after King.\n",
    "        # Small class size (200 seats).\n",
    "        'seats': 200,\n",
    "        'total_applicants': 2500,\n",
    "        'tiers': {\n",
    "            1: {'cutoff': 530, 'avg': 587.9},\n",
    "            2: {'cutoff': 536.5, 'avg': 583.6},  # T2 avg < T1 avg (unusual)\n",
    "            3: {'cutoff': 525.5, 'avg': 586.6},\n",
    "            4: {'cutoff': 503.5, 'avg': 568.1},\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "print(f\"Loaded data for {len(SCHOOL_DATA)} SEHS schools.\")\n",
    "print(f\"Total seats across all schools: {sum(s['seats'] for s in SCHOOL_DATA.values()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T10:39:56.871299Z",
     "start_time": "2025-11-29T10:39:56.492783Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# RUN MLE FOR ALL SCHOOLS\n",
    "# ==============================================================================\n",
    "# This function applies the MLE procedure to all four tiers of a school.\n",
    "#\n",
    "# Variables:\n",
    "#   school_name     : Name of the school (string key into SCHOOL_DATA)\n",
    "#   school_info     : Dict with seats, total_applicants, tiers\n",
    "#   tier_seats      : Number of seats allocated to each tier (17.5% of total)\n",
    "#   tier_applicants : Estimated applicants per tier (total / 4, assuming uniform)\n",
    "#   tier_data       : TierData object constructed from CPS published numbers\n",
    "#   results         : Dict mapping tier number (1-4) to FittedTier objects\n",
    "# ==============================================================================\n",
    "\n",
    "def run_mle_for_school(school_name: str, school_info: dict) -> Dict[int, FittedTier]:\n",
    "    \"\"\"\n",
    "    Run MLE analysis for all four tiers of a single school.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    school_name : str\n",
    "        Name of the school (used for logging only)\n",
    "    school_info : dict\n",
    "        Must contain:\n",
    "        - 'seats': Total seats at the school\n",
    "        - 'total_applicants': Estimated total applicants\n",
    "        - 'tiers': Dict mapping tier (1-4) to {'cutoff': c, 'avg': X_bar_obs}\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Dict[int, FittedTier]\n",
    "        Mapping from tier number to fitted MLE results.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # COMPUTE SEAT AND APPLICANT ALLOCATIONS\n",
    "    # -------------------------------------------------------------------------\n",
    "    # CPS allocates 17.5% of seats to each tier (70% total / 4 tiers)\n",
    "    # The remaining 30% goes to rank-based admission (top scorers citywide)\n",
    "    tier_seats = school_info['seats'] * 0.175\n",
    "    \n",
    "    # Assume applicants are uniformly distributed across tiers\n",
    "    # This is a simplification; reality is more complex (see Section 4.1)\n",
    "    tier_applicants = school_info['total_applicants'] / 4\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # FIT MLE FOR EACH TIER\n",
    "    # -------------------------------------------------------------------------\n",
    "    for tier_num, tier_info in school_info['tiers'].items():\n",
    "        # Construct TierData object from CPS published numbers\n",
    "        # cutoff = c (minimum score for admission)\n",
    "        # observed_mean = X_bar_obs (average of admitted students)\n",
    "        tier_data = TierData(\n",
    "            name=f\"Tier {tier_num}\",\n",
    "            cutoff=tier_info['cutoff'],          # c from CPS report\n",
    "            observed_mean=tier_info['avg'],      # X_bar_obs from CPS report\n",
    "            seats=tier_seats,                    # 17.5% of total seats\n",
    "            applicants=tier_applicants           # ~25% of total applicants\n",
    "        )\n",
    "        \n",
    "        # Run the MLE optimization\n",
    "        # This returns estimates (mu_hat, sigma_hat) for this tier\n",
    "        results[tier_num] = fit_tier_mle(tier_data)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# EXECUTE MLE FOR ALL 11 SCHOOLS\n",
    "# ==============================================================================\n",
    "# Store results in a dictionary: school_name -> {tier: FittedTier}\n",
    "ALL_MLE_RESULTS = {}\n",
    "\n",
    "for school_name, school_info in SCHOOL_DATA.items():\n",
    "    ALL_MLE_RESULTS[school_name] = run_mle_for_school(school_name, school_info)\n",
    "\n",
    "print(\"MLE analysis complete for all schools.\")\n",
    "print(f\"Total tier-level estimates: {sum(len(r) for r in ALL_MLE_RESULTS.values())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Results Summary\n",
    "\n",
    "The table below shows the recovered hidden parameters for **Tier 4** across all schools, sorted by estimated population mean $\\hat{\\mu}$. I focus on T4 because it reveals the most striking differences between elite and regional schools.\n",
    "\n",
    "**Key observations:**\n",
    "\n",
    "1. **Elite schools have extremely tight T4 distributions.** Northside has $\\hat{\\sigma} < 5$, meaning virtually all T4 applicants who rank Northside score in a narrow 10-15 point band near 890-900. This reflects both extreme competition and the 900-point ceiling.\n",
    "\n",
    "2. **Regional schools have much wider T4 spreads.** King and South Shore have $\\hat{\\sigma} > 60$, indicating heterogeneous T4 applicant pools with scores spanning 200+ points.\n",
    "\n",
    "3. **The $\\hat{\\mu}$ gap between elite and regional schools is enormous.** Elite T4 $\\hat{\\mu}$ ranges from 830-890; regional T4 $\\hat{\\mu}$ ranges from 590-720. This 200+ point gap reflects the fundamental bifurcation in Chicago's school system.\n",
    "\n",
    "4. **Some schools hit optimization bounds.** When $\\hat{\\sigma}$ equals exactly 5 or 200, it suggests the true distribution may deviate from normality (e.g., bimodal or heavily skewed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T10:40:06.122466Z",
     "start_time": "2025-11-29T10:40:06.115941Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CREATE SUMMARY TABLE OF MLE RESULTS\n",
    "# ==============================================================================\n",
    "# This cell compiles all tier-level MLE results into a pandas DataFrame\n",
    "# for easier analysis and display.\n",
    "#\n",
    "# Variables:\n",
    "#   summary_rows   : List of dicts, each representing one tier at one school\n",
    "#   mle_summary    : DataFrame with all tier-level results\n",
    "#   t4_summary     : DataFrame filtered to Tier 4, sorted by Hidden_mu\n",
    "#\n",
    "# Columns in the summary:\n",
    "#   School         : School name\n",
    "#   Tier           : Tier number (1-4)\n",
    "#   Hidden_mu      : MLE estimate of population mean (mu_hat)\n",
    "#   Hidden_sigma   : MLE estimate of population std dev (sigma_hat)\n",
    "#   Cutoff         : Published admission cutoff (c)\n",
    "#   Accept_Rate    : Implied acceptance rate P(X >= c) from fitted parameters\n",
    "#   Selection_Bias : Observed mean - Hidden_mu (truncation bias)\n",
    "# ==============================================================================\n",
    "\n",
    "# Compile all tier-level results into a list of dictionaries\n",
    "summary_rows = []\n",
    "for school_name, results in ALL_MLE_RESULTS.items():\n",
    "    for tier_num, fitted in results.items():\n",
    "        summary_rows.append({\n",
    "            'School': school_name,\n",
    "            'Tier': tier_num,\n",
    "            'Hidden_mu': fitted.mu,              # mu_hat: recovered population mean\n",
    "            'Hidden_sigma': fitted.sigma,        # sigma_hat: recovered population std dev\n",
    "            'Cutoff': fitted.cutoff,             # c: published cutoff\n",
    "            'Accept_Rate': fitted.fitted_accept_rate,  # P(X >= c) from fitted params\n",
    "            'Selection_Bias': fitted.selection_bias,   # X_bar_obs - mu_hat\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "mle_summary = pd.DataFrame(summary_rows)\n",
    "\n",
    "# Filter to Tier 4 and sort by hidden mean (most competitive schools first)\n",
    "t4_summary = mle_summary[mle_summary['Tier'] == 4].sort_values('Hidden_mu', ascending=False)\n",
    "\n",
    "# Display formatted table\n",
    "print(\"=\" * 80)\n",
    "print(\"TIER 4 MLE RESULTS - Sorted by Hidden Population Mean (mu_hat)\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(f\"{'School':<20} {'mu_hat':>10} {'sigma_hat':>12} {'Cutoff':>10} {'Selection Bias':>15}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for _, row in t4_summary.iterrows():\n",
    "    print(f\"{row['School']:<20} {row['Hidden_mu']:>10.1f} {row['Hidden_sigma']:>12.1f} \"\n",
    "          f\"{row['Cutoff']:>10.1f} {row['Selection_Bias']:>15.1f}\")\n",
    "\n",
    "print()\n",
    "print(\"INTERPRETATION:\")\n",
    "print(\"  - Small sigma_hat (< 30): Extremely competitive tier; scores tightly clustered\")\n",
    "print(\"  - Large sigma_hat (> 60): Heterogeneous applicant pool; wide score range\")\n",
    "print(\"  - Selection Bias: How much truncation inflates the published average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization: MLE Analysis\n",
    "\n",
    "### 5.1 Individual School Plots\n",
    "\n",
    "For each school, I generate a 6-panel visualization to communicate the MLE results:\n",
    "\n",
    "| Panel | Content | Purpose |\n",
    "|-------|---------|---------|\n",
    "| (0,0) | All tier distributions | Overlaid PDFs of $\\mathcal{N}(\\hat{\\mu}, \\hat{\\sigma}^2)$ for each tier, with cutoff lines |\n",
    "| (0,1) | Selection bias by tier | Bar chart of $\\bar{X}_{\\text{obs}} - \\hat{\\mu}$ |\n",
    "| (0,2) | Acceptance regions | T1 vs T4 distributions with admitted regions shaded |\n",
    "| (1,0) | Joint constraint curves | Contour plot showing how mean and acceptance rate constraints intersect |\n",
    "| (1,1) | True mean vs cutoff | Side-by-side bars showing the gap between $\\hat{\\mu}$ and $c$ |\n",
    "| (1,2) | Parameter summary | Key numbers in text format |\n",
    "\n",
    "The joint constraint plot (panel 1,0) is particularly illuminating: it shows two curves in $(\\mu, \\sigma)$ space:\n",
    "- **Blue curve**: All $(\\mu, \\sigma)$ pairs that produce the observed truncated mean\n",
    "- **Red curve**: All $(\\mu, \\sigma)$ pairs that produce the target acceptance rate\n",
    "\n",
    "The MLE solution is the intersection of these curves. With only one curve (one constraint), the problem is underidentified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T10:40:38.122460Z",
     "start_time": "2025-11-29T10:40:38.110663Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# VISUALIZATION FUNCTION: INDIVIDUAL SCHOOL MLE PLOTS\n",
    "# ==============================================================================\n",
    "# This function generates a comprehensive 6-panel visualization for each school,\n",
    "# showing the MLE results and how the constraints identify the parameters.\n",
    "#\n",
    "# Variables (LaTeX correspondence):\n",
    "#   mu, sigma     -> mu_hat, sigma_hat : recovered population parameters\n",
    "#   cutoff        -> c                 : admission threshold\n",
    "#   t1, t4        -> FittedTier objects for Tier 1 and Tier 4\n",
    "#   x             -> domain for plotting PDFs (score values 300-920)\n",
    "#   y             -> f(x; mu, sigma) = normal PDF evaluated at x\n",
    "#   Z_mean        -> E[X|X>=c] surface over (mu, sigma) grid\n",
    "#   Z_accept      -> P(X>=c) surface over (mu, sigma) grid\n",
    "#   tier_colors   -> color palette: T1=red, T2=blue, T3=green, T4=purple\n",
    "# ==============================================================================\n",
    "\n",
    "def create_mle_visualization(school_name: str, \n",
    "                             results: Dict[int, FittedTier], \n",
    "                             school_info: dict) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Generate comprehensive 6-panel MLE visualization for a single school.\n",
    "    \n",
    "    Panel layout (2x3 grid):\n",
    "        [0,0] All tier distributions    [0,1] Selection bias bars    [0,2] Acceptance regions\n",
    "        [1,0] Joint constraints         [1,1] Mean vs cutoff         [1,2] Summary text\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    school_name : str\n",
    "        Name of the school (for plot titles)\n",
    "    results : Dict[int, FittedTier]\n",
    "        MLE results by tier (keys: 1, 2, 3, 4)\n",
    "    school_info : dict\n",
    "        Original school data (used for constraint curve plotting)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The generated 6-panel figure\n",
    "    \"\"\"\n",
    "    # Create 2x3 subplot grid\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    \n",
    "    # Color palette for tiers (colorblind-friendly)\n",
    "    # T1: Red (disadvantaged), T4: Purple (affluent)\n",
    "    tier_colors = {1: '#e41a1c', 2: '#377eb8', 3: '#4daf4a', 4: '#984ea3'}\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PANEL [0,0]: All tier distributions overlaid\n",
    "    # =========================================================================\n",
    "    # Shows the recovered N(mu_hat, sigma_hat^2) for each tier.\n",
    "    # Vertical dashed lines indicate cutoffs.\n",
    "    ax = axes[0, 0]\n",
    "    x = np.linspace(300, 920, 500)  # Score domain for PDF plotting\n",
    "    \n",
    "    for tier in [1, 2, 3, 4]:\n",
    "        t = results[tier]\n",
    "        # Compute normal PDF: f(x) = phi((x - mu) / sigma) / sigma\n",
    "        y = stats.norm.pdf(x, t.mu, t.sigma)\n",
    "        ax.plot(x, y, color=tier_colors[tier], linewidth=2, \n",
    "                label=f'T{tier}: mu={t.mu:.0f}, sigma={t.sigma:.0f}')\n",
    "        # Vertical line at cutoff c\n",
    "        ax.axvline(t.cutoff, color=tier_colors[tier], linestyle='--', alpha=0.5)\n",
    "    \n",
    "    ax.set_xlabel('Score')\n",
    "    ax.set_ylabel('Probability Density')\n",
    "    ax.set_title(f'{school_name}: Recovered Population Distributions', fontweight='bold')\n",
    "    ax.legend(loc='upper left', fontsize=8)\n",
    "    ax.set_xlim(300, 920)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PANEL [0,1]: Selection bias by tier\n",
    "    # =========================================================================\n",
    "    # Bar chart showing (X_bar_obs - mu_hat) for each tier.\n",
    "    # Larger bars indicate more severe truncation (cutoff far above mean).\n",
    "    ax = axes[0, 1]\n",
    "    tiers = [1, 2, 3, 4]\n",
    "    biases = [results[t].selection_bias for t in tiers]\n",
    "    \n",
    "    bars = ax.bar(range(4), biases, color=[tier_colors[t] for t in tiers])\n",
    "    ax.set_xticks(range(4))\n",
    "    ax.set_xticklabels(['Tier 1', 'Tier 2', 'Tier 3', 'Tier 4'])\n",
    "    ax.set_ylabel('Selection Bias (points)')\n",
    "    ax.set_title('Selection Bias by Tier\\n(Observed Mean - True Mean)', fontweight='bold')\n",
    "    \n",
    "    # Add value labels on top of bars\n",
    "    for bar, bias in zip(bars, biases):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "                f'{bias:.0f}', ha='center', fontweight='bold', fontsize=9)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PANEL [0,2]: Acceptance regions (T1 vs T4)\n",
    "    # =========================================================================\n",
    "    # Compares the full distribution (light shading) with the admitted region\n",
    "    # (dark shading, X >= c). Illustrates how truncation affects each tier differently.\n",
    "    ax = axes[0, 2]\n",
    "    x = np.linspace(300, 920, 500)\n",
    "    \n",
    "    t1, t4 = results[1], results[4]\n",
    "    y1 = stats.norm.pdf(x, t1.mu, t1.sigma)\n",
    "    y4 = stats.norm.pdf(x, t4.mu, t4.sigma)\n",
    "    \n",
    "    # Full distribution (light shading)\n",
    "    ax.fill_between(x, y1, alpha=0.2, color=tier_colors[1])\n",
    "    ax.fill_between(x, y4, alpha=0.2, color=tier_colors[4])\n",
    "    \n",
    "    # Admitted region only (dark shading): X >= cutoff\n",
    "    mask1 = x >= t1.cutoff\n",
    "    mask4 = x >= t4.cutoff\n",
    "    ax.fill_between(x[mask1], y1[mask1], alpha=0.6, color=tier_colors[1], label='T1 admitted')\n",
    "    ax.fill_between(x[mask4], y4[mask4], alpha=0.6, color=tier_colors[4], label='T4 admitted')\n",
    "    \n",
    "    ax.set_xlabel('Score')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title('Who Gets Admitted?\\nLight = Full Population, Dark = Admitted', fontweight='bold')\n",
    "    ax.legend()\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PANEL [1,0]: Joint constraint curves for T1\n",
    "    # =========================================================================\n",
    "    # This panel shows the identification strategy. Two curves in (mu, sigma) space:\n",
    "    #   Blue: All (mu, sigma) pairs giving the observed truncated mean\n",
    "    #   Red:  All (mu, sigma) pairs giving the target acceptance rate\n",
    "    # The MLE solution is their intersection.\n",
    "    ax = axes[1, 0]\n",
    "    \n",
    "    # Create grid over (mu, sigma) parameter space\n",
    "    mu_range = np.linspace(300, 800, 80)\n",
    "    sigma_range = np.linspace(30, 200, 80)\n",
    "    MU, SIGMA = np.meshgrid(mu_range, sigma_range)\n",
    "    \n",
    "    # Get T1 data for constraint computation\n",
    "    t1_data = school_info['tiers'][1]\n",
    "    tier_applicants = school_info['total_applicants'] / 4\n",
    "    tier_seats = school_info['seats'] * 0.175\n",
    "    target_accept = tier_seats / tier_applicants  # r = seats / applicants\n",
    "    \n",
    "    # Compute constraint surfaces over the grid\n",
    "    # Z_mean[i,j] = E[X|X>=c] for (mu, sigma) = (MU[i,j], SIGMA[i,j])\n",
    "    # Z_accept[i,j] = P(X>=c) for (mu, sigma) = (MU[i,j], SIGMA[i,j])\n",
    "    Z_mean = np.zeros_like(MU)\n",
    "    Z_accept = np.zeros_like(MU)\n",
    "    \n",
    "    for i in range(MU.shape[0]):\n",
    "        for j in range(MU.shape[1]):\n",
    "            Z_mean[i,j] = truncated_mean(MU[i,j], SIGMA[i,j], t1_data['cutoff'])\n",
    "            Z_accept[i,j] = acceptance_prob(MU[i,j], SIGMA[i,j], t1_data['cutoff'])\n",
    "    \n",
    "    # Plot constraint contours\n",
    "    # Blue: mean constraint (E[X|X>=c] = X_bar_obs)\n",
    "    ax.contour(MU, SIGMA, Z_mean, levels=[t1_data['avg']], colors='blue', linewidths=2)\n",
    "    # Red: acceptance rate constraint (P(X>=c) = r)\n",
    "    ax.contour(MU, SIGMA, Z_accept, levels=[target_accept], colors='red', linewidths=2)\n",
    "    \n",
    "    # Mark the MLE solution (intersection point)\n",
    "    t1_fit = results[1]\n",
    "    ax.scatter([t1_fit.mu], [t1_fit.sigma], color='purple', s=100, zorder=5, marker='*')\n",
    "    ax.annotate(f'MLE\\n({t1_fit.mu:.0f}, {t1_fit.sigma:.0f})', \n",
    "                (t1_fit.mu, t1_fit.sigma), \n",
    "                textcoords='offset points', xytext=(10, 10), \n",
    "                fontweight='bold', color='purple')\n",
    "    \n",
    "    ax.set_xlabel('Hidden Mean (mu)')\n",
    "    ax.set_ylabel('Hidden Std Dev (sigma)')\n",
    "    ax.set_title(f'T1 Joint Constraints\\nBlue: Mean={t1_data[\"avg\"]:.0f}, Red: Accept={target_accept:.1%}', \n",
    "                 fontweight='bold')\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PANEL [1,1]: True mean vs cutoff comparison\n",
    "    # =========================================================================\n",
    "    # Side-by-side bars showing mu_hat (what we recovered) vs c (published cutoff).\n",
    "    # The gap between them is the \"headroom\" for admitted students.\n",
    "    ax = axes[1, 1]\n",
    "    \n",
    "    true_means = [results[t].mu for t in tiers]\n",
    "    cutoffs = [results[t].cutoff for t in tiers]\n",
    "    \n",
    "    x_pos = np.arange(4)\n",
    "    width = 0.35\n",
    "    \n",
    "    ax.bar(x_pos - width/2, true_means, width, label='True Mean (mu)', \n",
    "           color=[tier_colors[t] for t in tiers], alpha=0.8)\n",
    "    ax.bar(x_pos + width/2, cutoffs, width, label='Cutoff (c)', \n",
    "           color=[tier_colors[t] for t in tiers], alpha=0.3, hatch='//')\n",
    "    \n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(['Tier 1', 'Tier 2', 'Tier 3', 'Tier 4'])\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_title('True Population Means vs Cutoffs by Tier', fontweight='bold')\n",
    "    ax.legend()\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PANEL [1,2]: Summary statistics (text box)\n",
    "    # =========================================================================\n",
    "    ax = axes[1, 2]\n",
    "    ax.axis('off')\n",
    "    \n",
    "    summary_text = f\"\"\"\n",
    "    {school_name.upper()}\n",
    "    {'=' * 35}\n",
    "    \n",
    "    Tier 1:  mu = {results[1].mu:6.0f},  sigma = {results[1].sigma:5.0f}\n",
    "    Tier 2:  mu = {results[2].mu:6.0f},  sigma = {results[2].sigma:5.0f}\n",
    "    Tier 3:  mu = {results[3].mu:6.0f},  sigma = {results[3].sigma:5.0f}\n",
    "    Tier 4:  mu = {results[4].mu:6.0f},  sigma = {results[4].sigma:5.0f}\n",
    "    \n",
    "    {'=' * 35}\n",
    "    KEY INSIGHTS:\n",
    "    \n",
    "    T4-T1 mean gap: {results[4].mu - results[1].mu:.0f} pts\n",
    "    T1 selection bias: {results[1].selection_bias:.0f} pts\n",
    "    T4 selection bias: {results[4].selection_bias:.0f} pts\n",
    "    T4 sigma = {results[4].sigma:.0f} (smaller = more competitive)\n",
    "    \"\"\"\n",
    "    \n",
    "    ax.text(0.1, 0.9, summary_text, transform=ax.transAxes, \n",
    "            fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T10:41:02.569913Z",
     "start_time": "2025-11-29T10:40:58.494661Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# GENERATE MLE PLOTS FOR SELECTED SCHOOLS\n",
    "# ==============================================================================\n",
    "# I generate detailed plots for a representative sample of schools:\n",
    "#   - 2 elite schools (Lane Tech, Payton) to show tight T4 distributions\n",
    "#   - 2 regional schools (Northside, South Shore) to show wider distributions\n",
    "#\n",
    "# Generating plots for all 11 schools would be redundant; these four capture\n",
    "# the key patterns in the data.\n",
    "# ==============================================================================\n",
    "\n",
    "# Select representative schools spanning the competitiveness spectrum\n",
    "schools_to_plot = ['Lane Tech', 'Walter Payton', 'Northside', 'South Shore']\n",
    "\n",
    "for school_name in schools_to_plot:\n",
    "    print(f\"Generating MLE visualization for {school_name}...\")\n",
    "    \n",
    "    # Create the 6-panel figure\n",
    "    fig = create_mle_visualization(\n",
    "        school_name, \n",
    "        ALL_MLE_RESULTS[school_name], \n",
    "        SCHOOL_DATA[school_name]\n",
    "    )\n",
    "    \n",
    "    plt.show()\n",
    "    print()  # Blank line between figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Combined Density Plots: All Schools\n",
    "\n",
    "The following visualization shows the recovered population distributions for all 11 schools on a single page, arranged by competitiveness (T4 cutoff descending). This reveals the fundamental **bifurcation** in the SEHS system:\n",
    "\n",
    "- **Elite schools** (Payton, Northside, Young, Jones, Lane): High $\\hat{\\mu}$, tight $\\hat{\\sigma}$, cutoffs near or above 850\n",
    "- **Regional schools** (Hancock through South Shore): Lower $\\hat{\\mu}$, wider $\\hat{\\sigma}$, cutoffs spanning 500-800\n",
    "\n",
    "The visual contrast is striking: elite school distributions are narrow peaks concentrated near 900, while regional school distributions are broad curves spanning hundreds of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T10:41:49.233490Z",
     "start_time": "2025-11-29T10:41:48.491523Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# COMBINED DENSITY PLOT: ALL 11 SCHOOLS\n",
    "# ==============================================================================\n",
    "# This function creates a grid of density plots showing all schools on one page.\n",
    "# Schools are sorted by T4 cutoff (most competitive first).\n",
    "#\n",
    "# Variables:\n",
    "#   school_order   : List of school names sorted by T4 cutoff (descending)\n",
    "#   tier_colors    : Color palette for tiers\n",
    "#   x              : Score domain for PDF evaluation\n",
    "#   y              : Normal PDF values at x\n",
    "# ==============================================================================\n",
    "\n",
    "def create_combined_density_plot() -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Create a 3x4 grid of density plots for all 11 schools.\n",
    "    \n",
    "    Each subplot shows the recovered N(mu_hat, sigma_hat^2) distributions\n",
    "    for all four tiers, with cutoff lines overlaid.\n",
    "    \n",
    "    Schools are sorted by T4 cutoff (most competitive first), so elite\n",
    "    schools appear in the top rows and regional schools in the bottom.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The combined figure with 11 subplots (12th cell empty)\n",
    "    \"\"\"\n",
    "    # Sort schools by T4 cutoff (descending = most competitive first)\n",
    "    school_order = sorted(\n",
    "        SCHOOL_DATA.keys(), \n",
    "        key=lambda s: SCHOOL_DATA[s]['tiers'][4]['cutoff'], \n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    # Create 3x4 grid (11 schools + 1 empty cell)\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(20, 15))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Color scheme for tiers\n",
    "    tier_colors = {1: '#e41a1c', 2: '#377eb8', 3: '#4daf4a', 4: '#984ea3'}\n",
    "    \n",
    "    # Score domain for PDF plotting\n",
    "    x = np.linspace(300, 920, 500)\n",
    "    \n",
    "    for idx, school_name in enumerate(school_order):\n",
    "        ax = axes[idx]\n",
    "        results = ALL_MLE_RESULTS[school_name]\n",
    "        \n",
    "        # Plot each tier's recovered distribution\n",
    "        for tier in [1, 2, 3, 4]:\n",
    "            t = results[tier]\n",
    "            # Normal PDF: f(x; mu, sigma)\n",
    "            y = stats.norm.pdf(x, t.mu, t.sigma)\n",
    "            # Filled area under curve\n",
    "            ax.fill_between(x, y, alpha=0.3, color=tier_colors[tier])\n",
    "            # Outline\n",
    "            ax.plot(x, y, color=tier_colors[tier], linewidth=1.5, label=f'T{tier}')\n",
    "            # Cutoff line\n",
    "            ax.axvline(t.cutoff, color=tier_colors[tier], linestyle='--', alpha=0.5, linewidth=1)\n",
    "        \n",
    "        ax.set_title(school_name, fontweight='bold', fontsize=11)\n",
    "        ax.set_xlim(300, 920)\n",
    "        ax.set_xlabel('Score', fontsize=9)\n",
    "        ax.set_ylabel('Density', fontsize=9)\n",
    "        \n",
    "        # Add legend only to first subplot (to avoid clutter)\n",
    "        if idx == 0:\n",
    "            ax.legend(loc='upper left', fontsize=8)\n",
    "    \n",
    "    # Hide the unused 12th subplot\n",
    "    axes[-1].axis('off')\n",
    "    \n",
    "    plt.suptitle(\n",
    "        'MLE-Recovered Population Distributions for All SEHS Schools\\n'\n",
    "        '(Sorted by T4 cutoff; dashed lines indicate cutoffs)', \n",
    "        fontsize=14, fontweight='bold', y=1.02\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Generate and display the combined plot\n",
    "fig = create_combined_density_plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T10:42:15.972198Z",
     "start_time": "2025-11-29T10:42:15.795845Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TIER 4 COMPARISON: ELITE VS REGIONAL SCHOOLS\n",
    "# ==============================================================================\n",
    "# This visualization directly compares T4 distributions between school groups.\n",
    "# The contrast reveals the bifurcation in the SEHS system.\n",
    "#\n",
    "# Left panel:  Elite schools (Payton, Northside, Young, Jones, Lane)\n",
    "#              - sigma_hat typically 10-30 (very tight)\n",
    "#              - mu_hat typically 830-890 (near ceiling)\n",
    "#\n",
    "# Right panel: Regional schools (Hancock, Lindblom, Brooks, Westinghouse, King, South Shore)\n",
    "#              - sigma_hat typically 60-100 (wide spread)\n",
    "#              - mu_hat typically 590-720 (much lower)\n",
    "# ==============================================================================\n",
    "\n",
    "def create_tier_comparison_plot() -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Compare T4 distributions between elite and regional schools.\n",
    "    \n",
    "    This visualization highlights the fundamental difference in T4 competition:\n",
    "    - Elite schools: sigma ~ 10-30 (extreme competition, ceiling effects)\n",
    "    - Regional schools: sigma ~ 60-100 (more heterogeneous applicant pools)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        Two-panel figure comparing T4 distributions\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Define school groups based on competitiveness\n",
    "    elite_schools = ['Walter Payton', 'Northside', 'Whitney Young', 'Jones', 'Lane Tech']\n",
    "    regional_schools = ['Lindblom', 'Hancock', 'Brooks', 'King', 'Westinghouse', 'South Shore']\n",
    "    \n",
    "    # Score domain for PDF plotting\n",
    "    x = np.linspace(400, 920, 500)\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # LEFT PANEL: Elite schools T4\n",
    "    # -------------------------------------------------------------------------\n",
    "    ax = axes[0]\n",
    "    # Use a blue color gradient (light to dark)\n",
    "    colors = plt.cm.Blues(np.linspace(0.3, 0.9, len(elite_schools)))\n",
    "    \n",
    "    for i, school in enumerate(elite_schools):\n",
    "        t = ALL_MLE_RESULTS[school][4]  # Get T4 results\n",
    "        y = stats.norm.pdf(x, t.mu, t.sigma)\n",
    "        ax.plot(x, y, color=colors[i], linewidth=2, \n",
    "                label=f'{school} (mu={t.mu:.0f}, sigma={t.sigma:.0f})')\n",
    "        # Cutoff line\n",
    "        ax.axvline(t.cutoff, color=colors[i], linestyle='--', alpha=0.5)\n",
    "    \n",
    "    ax.set_xlabel('Score', fontsize=11)\n",
    "    ax.set_ylabel('Density', fontsize=11)\n",
    "    ax.set_title('Tier 4 Distributions: Elite Schools\\n(Tight sigma indicates extreme competition)', \n",
    "                 fontweight='bold')\n",
    "    ax.legend(loc='upper left', fontsize=9)\n",
    "    ax.set_xlim(600, 920)\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # RIGHT PANEL: Regional schools T4\n",
    "    # -------------------------------------------------------------------------\n",
    "    ax = axes[1]\n",
    "    # Use a red color gradient (light to dark)\n",
    "    colors = plt.cm.Reds(np.linspace(0.3, 0.9, len(regional_schools)))\n",
    "    \n",
    "    for i, school in enumerate(regional_schools):\n",
    "        t = ALL_MLE_RESULTS[school][4]  # Get T4 results\n",
    "        y = stats.norm.pdf(x, t.mu, t.sigma)\n",
    "        ax.plot(x, y, color=colors[i], linewidth=2, \n",
    "                label=f'{school} (mu={t.mu:.0f}, sigma={t.sigma:.0f})')\n",
    "        # Cutoff line\n",
    "        ax.axvline(t.cutoff, color=colors[i], linestyle='--', alpha=0.5)\n",
    "    \n",
    "    ax.set_xlabel('Score', fontsize=11)\n",
    "    ax.set_ylabel('Density', fontsize=11)\n",
    "    ax.set_title('Tier 4 Distributions: Regional Schools\\n(Wide sigma reflects heterogeneous pools)', \n",
    "                 fontweight='bold')\n",
    "    ax.legend(loc='upper left', fontsize=9)\n",
    "    ax.set_xlim(400, 900)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Generate and display the comparison plot\n",
    "fig = create_tier_comparison_plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Physics-Based Monte Carlo Simulation (v13)\n",
    "\n",
    "### 6.1 Motivation and Approach\n",
    "\n",
    "The MLE analysis recovers population-level parameters $(\\hat{\\mu}, \\hat{\\sigma})$ for each school-tier combination, but it does not model the **behavioral dynamics** of how students choose schools. To simulate the full admissions process and predict cutoffs, I need:\n",
    "\n",
    "1. A model of how students form **preferences** over schools\n",
    "2. A mechanism for generating **realistic score distributions** by region and tier\n",
    "3. An implementation of the **serial dictatorship matching algorithm**\n",
    "\n",
    "I call this a \"physics-based\" simulation because it models students as agents with utility functions, analogous to particles in a potential field. Each student-school pair has an associated utility, and students rank schools by utility (highest to lowest).\n",
    "\n",
    "### 6.2 Model Components\n",
    "\n",
    "**Utility function**: For student $i$ considering school $j$:\n",
    "\n",
    "$$U_{ij} = P_j - d_{ij} \\cdot f(t_i, s_i) - \\mathbb{1}[r_i \\neq r_j] \\cdot \\gamma(r_i, r_j, s_i) + \\delta_j(t_i, s_i, r_i)$$\n",
    "\n",
    "| Term | Meaning |\n",
    "|------|---------|\n",
    "| $P_j$ | Prestige of school $j$ (0-100 scale, based on cutoffs and reputation) |\n",
    "| $d_{ij}$ | Distance in miles from student $i$'s home to school $j$ |\n",
    "| $f(t_i, s_i)$ | Friction coefficient (varies by tier $t_i$ and score $s_i$; high scorers travel more) |\n",
    "| $\\gamma(r_i, r_j, s_i)$ | Cross-region penalty (students prefer local schools; penalty depends on region pair) |\n",
    "| $\\delta_j(\\cdot)$ | School-specific demand modifier (tuned via Optuna to match observed cutoffs) |\n",
    "\n",
    "**Score generation**: I use skewed normal distributions:\n",
    "\n",
    "$$X_{r,t} \\sim \\text{SkewNorm}(\\alpha_{r,t}, \\mu_{r,t}, \\sigma_{r,t})$$\n",
    "\n",
    "where parameters vary by region $r \\in \\{\\text{north}, \\text{loop}, \\text{west}, \\text{south}\\}$ and tier $t \\in \\{1,2,3,4\\}$.\n",
    "\n",
    "**Justification for skewed distributions**: The pure normal assumption from MLE is a simplification. Empirically, score distributions exhibit:\n",
    "- **Positive skew in lower tiers**: Long right tail of high achievers who beat the odds\n",
    "- **Negative skew in higher tiers**: Compression against the 900 ceiling\n",
    "\n",
    "The skewnorm distribution captures this asymmetry with a single additional parameter $\\alpha$ (skewness)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T10:42:34.532007Z",
     "start_time": "2025-11-29T10:42:34.529637Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# IMPORT CENTRALIZED DATA FROM sehs_data.py\n",
    "# ==============================================================================\n",
    "# The sehs_data.py module contains all school configurations, geographic data,\n",
    "# and historical cutoffs. This separation keeps the simulation code clean and\n",
    "# allows easy updates when new data becomes available.\n",
    "#\n",
    "# Key imports:\n",
    "#   SCHOOLS                  : Dict of School objects (prestige, location, seats)\n",
    "#   REGIONS                  : Geographic region definitions (center, spread)\n",
    "#   TIER_BY_REGION           : Probability of each tier in each region\n",
    "#   ADMISSIONS               : Seat allocation rules (30% rank, 70% tier)\n",
    "#   ELITE_SCHOOLS            : List of top 5 schools by prestige\n",
    "#   CUTOFFS_2024_CALIBRATION : Actual cutoffs for model validation\n",
    "#   distance_miles           : Haversine distance function\n",
    "# ==============================================================================\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/andrewhood/Tutoring/School Modeling')\n",
    "\n",
    "from sehs_data import (\n",
    "    SCHOOLS,                    # School objects with prestige, location, seats\n",
    "    REGIONS,                    # Geographic region definitions\n",
    "    TIER_BY_REGION,            # Distribution of tiers across regions\n",
    "    ADMISSIONS,                # Seat allocation rules (30/70 split)\n",
    "    ELITE_SCHOOLS,             # List of top 5 schools\n",
    "    CUTOFFS_2024_CALIBRATION,  # Actual cutoffs for validation\n",
    "    distance_miles             # Haversine distance calculation\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(SCHOOLS)} schools from sehs_data.py\")\n",
    "print(f\"Elite schools: {', '.join(ELITE_SCHOOLS)}\")\n",
    "print(f\"Regions: {', '.join(REGIONS.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T10:42:38.858163Z",
     "start_time": "2025-11-29T10:42:38.852027Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# V13 MODEL PARAMETERS (OPTUNA-TUNED)\n",
    "# ==============================================================================\n",
    "# These parameters were optimized via 500 trials of Bayesian hyperparameter\n",
    "# tuning using the Optuna framework (Tree-structured Parzen Estimator sampler).\n",
    "#\n",
    "# Objective: Minimize MAE between simulated and actual cutoffs, subject to:\n",
    "#   - Max error < 80 points (any single tier at any school)\n",
    "#   - Max school MAE < 25 points (worst school's average error)\n",
    "#\n",
    "# Best trial: #353\n",
    "#   MAE = 22.79, Max Error = 84.4, Max School MAE = 30.0\n",
    "#\n",
    "# Variables (LaTeX correspondence):\n",
    "#   loc   -> mu_{r,t}    : location parameter of skewnorm (related to mean)\n",
    "#   scale -> sigma_{r,t} : scale parameter of skewnorm (related to std dev)\n",
    "#   skew  -> alpha_{r,t} : shape parameter (>0 right skew, <0 left skew)\n",
    "# ==============================================================================\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# SCORE DISTRIBUTIONS BY REGION AND TIER\n",
    "# -----------------------------------------------------------------------------\n",
    "# These define the generative model for student scores.\n",
    "# Parameters are for scipy.stats.skewnorm(a, loc, scale):\n",
    "#   a (skew): Shape parameter controlling asymmetry\n",
    "#   loc:      Location parameter (shifts the distribution)\n",
    "#   scale:    Scale parameter (stretches the distribution)\n",
    "#\n",
    "# North/Loop: High scores, left-skewed T4 (ceiling effects)\n",
    "# West/South: Lower scores, right-skewed (long tail of high achievers)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "V13_SCORE_DISTRIBUTIONS = {\n",
    "    # North Side: Serves elite schools (Payton, Northside, Lane Tech)\n",
    "    # T4 is tightly concentrated near 870 because Northside/Payton T4 cutoffs are 893-898\n",
    "    'north': {\n",
    "        1: {'loc': 620, 'scale': 100, 'skew': 3.0},   # Right-skewed: long tail of high achievers\n",
    "        2: {'loc': 720, 'scale': 80, 'skew': 1.5},    # Moderate right skew\n",
    "        3: {'loc': 830, 'scale': 45, 'skew': -2.0},   # Left-skewed: ceiling effects\n",
    "        4: {'loc': 870, 'scale': 22, 'skew': -3.5},   # Very tight, left-skewed (near 900 ceiling)\n",
    "    },\n",
    "    \n",
    "    # Loop (Downtown): Similar to North, serves Whitney Young, Jones\n",
    "    # Slightly higher T1 due to magnet school feeder effects\n",
    "    'loop': {\n",
    "        1: {'loc': 700, 'scale': 90, 'skew': 2.5},\n",
    "        2: {'loc': 755, 'scale': 75, 'skew': 1.0},\n",
    "        3: {'loc': 835, 'scale': 40, 'skew': -2.0},\n",
    "        4: {'loc': 872, 'scale': 20, 'skew': -3.5},\n",
    "    },\n",
    "    \n",
    "    # West Side: Lower scores, serves Westinghouse primarily\n",
    "    # OPTUNA-TUNED (500 trials, trial 353, MAE 22.79)\n",
    "    # These values were found via Bayesian optimization\n",
    "    'west': {\n",
    "        1: {'loc': 453, 'scale': 113, 'skew': 4.77},  # Strong right skew (few high achievers)\n",
    "        2: {'loc': 558, 'scale': 90, 'skew': 2.20},\n",
    "        3: {'loc': 592, 'scale': 71, 'skew': 2.13},\n",
    "        4: {'loc': 689, 'scale': 51, 'skew': 1.32},   # Still right-skewed (unlike North T4)\n",
    "    },\n",
    "    \n",
    "    # South Side: Lower scores, serves King/Brooks/South Shore/Lindblom/Hancock\n",
    "    # OPTUNA-TUNED (500 trials, trial 353, MAE 22.79)\n",
    "    'south': {\n",
    "        1: {'loc': 457, 'scale': 100, 'skew': 4.04},\n",
    "        2: {'loc': 541, 'scale': 87, 'skew': 3.31},\n",
    "        3: {'loc': 612, 'scale': 79, 'skew': 0.58},   # Nearly symmetric\n",
    "        4: {'loc': 724, 'scale': 47, 'skew': 0.96},   # Slight right skew\n",
    "    },\n",
    "}\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# BEHAVIORAL PARAMETERS\n",
    "# -----------------------------------------------------------------------------\n",
    "# These control how students form preferences and make decisions.\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "PARAMS = {\n",
    "    # Total number of students to generate (approximate SEHS applicant pool)\n",
    "    'n_students': 22000,\n",
    "    \n",
    "    # Distance friction by tier: utility cost per mile\n",
    "    # Lower tiers are more distance-sensitive (less willing to commute far)\n",
    "    # Rationale: T1 families may have less flexible transportation\n",
    "    'base_friction': {1: 3.0, 2: 2.2, 3: 1.5, 4: 1.0},\n",
    "    \n",
    "    # Score-based mobility: high scorers are more willing to travel\n",
    "    # This captures the observation that top students target elite schools\n",
    "    # regardless of distance (they know they can get in anywhere)\n",
    "    'score_mobility': {\n",
    "        'threshold_high': 850,    # Above 850: very mobile\n",
    "        'threshold_mid': 750,     # 750-850: moderately mobile\n",
    "        'multiplier_high': 0.3,   # 70% friction reduction for 850+ scorers\n",
    "        'multiplier_mid': 0.6,    # 40% friction reduction for 750-849 scorers\n",
    "        'multiplier_low': 1.0,    # No reduction for <750 scorers\n",
    "    },\n",
    "    \n",
    "    # Cross-region penalties (asymmetric by region pair)\n",
    "    # Students generally prefer schools in their home region\n",
    "    # North-to-South penalty is highest (affluent families avoid South Side)\n",
    "    # South-to-North penalty is lower (elite schools are worth the commute)\n",
    "    'cross_region_base': {\n",
    "        ('north', 'south'): 50,   # North students strongly avoid South schools\n",
    "        ('north', 'west'): 35,\n",
    "        ('south', 'north'): 25,   # South students less penalty (elite schools worth it)\n",
    "        ('south', 'west'): 20,\n",
    "        ('south', 'loop'): 5,     # Loop accessible from South via CTA\n",
    "        ('west', 'north'): 30,\n",
    "        ('west', 'south'): 25,\n",
    "        ('west', 'loop'): 10,\n",
    "        ('loop', 'south'): 15,\n",
    "        ('loop', 'north'): 8,\n",
    "        ('loop', 'west'): 12,\n",
    "    },\n",
    "    \n",
    "    # Private school exit: high-scoring T4 students leave the CPS pool\n",
    "    # Models families who choose private schools or move to suburbs\n",
    "    # Higher exit rates in West/South reflect \"brain drain\" to private schools\n",
    "    'exit_threshold': {'north': 892, 'loop': 894, 'west': 820, 'south': 800},\n",
    "    'exit_prob': {'north': 0.18, 'loop': 0.22, 'west': 0.35, 'south': 0.40},\n",
    "    \n",
    "    # Maximum distance a student will consider (miles)\n",
    "    # Beyond this, utility drops to -infinity (school not ranked)\n",
    "    'distance_cap': 15.0,\n",
    "}\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# SCHOOL-SPECIFIC DEMAND MODIFIERS (OPTUNA-TUNED)\n",
    "# -----------------------------------------------------------------------------\n",
    "# These adjust utility for specific schools to match observed demand patterns.\n",
    "# Negative values reduce demand (fewer students rank the school highly).\n",
    "# Tuned via Optuna to minimize prediction error.\n",
    "#\n",
    "# Key patterns:\n",
    "#   - King, Hancock, Brooks T4 have large negative penalties (-24, -24, -3)\n",
    "#     because high-scoring T4 students prefer elite schools\n",
    "#   - Westinghouse has -36 penalty for non-West students (very local draw)\n",
    "#   - Lindblom T4 has small penalty (-3) because it competes with South schools\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "DEMAND_PENALTIES = {\n",
    "    'king_t4': -24,           # King T4 has low demand (elite school competition)\n",
    "    'king_other': -12,        # Other tiers also reduced\n",
    "    'hancock_t4': -24,        # Hancock T4 similar pattern\n",
    "    'hancock_other': 5,       # But T1-T3 have slight boost (local preference)\n",
    "    'brooks_t4': -3,          # Brooks T4 less penalized\n",
    "    'brooks_other': -12,\n",
    "    'westinghouse_non_west': -36,  # Non-West students rarely apply\n",
    "    'westinghouse_t34': -4,\n",
    "    'south_shore_t4': -10,\n",
    "    'south_shore_other': -9,\n",
    "    'lindblom_t4': -3,\n",
    "}\n",
    "\n",
    "print(\"v13 model parameters loaded.\")\n",
    "print(f\"Student population: {PARAMS['n_students']:,}\")\n",
    "print(f\"Regions: North, Loop, West, South\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T10:42:43.722348Z",
     "start_time": "2025-11-29T10:42:43.701392Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STUDENT GENERATION FUNCTION\n",
    "# ==============================================================================\n",
    "# This function creates a synthetic population of ~22,000 students with:\n",
    "#   - Tier assignment (1-4) based on citywide tier composition\n",
    "#   - Region assignment based on tier-specific regional probabilities\n",
    "#   - Geographic location (lat, lon) drawn from region-specific Gaussian\n",
    "#   - Score drawn from region x tier-specific skewed normal distribution\n",
    "#   - Private school exit applied to high-scoring T4 students\n",
    "#\n",
    "# Variables (LaTeX correspondence):\n",
    "#   n         -> N              : total number of students to generate\n",
    "#   tiers     -> t_i            : tier assignment for student i\n",
    "#   regions   -> r_i            : region assignment for student i\n",
    "#   scores    -> s_i            : composite score for student i\n",
    "#   lats/lons -> (lat_i, lon_i) : geographic coordinates for student i\n",
    "#\n",
    "# The generation follows a hierarchical model:\n",
    "#   1. t_i ~ Categorical(0.25, 0.25, 0.25, 0.25)  [uniform tier assignment]\n",
    "#   2. r_i | t_i ~ Categorical(p_{t_i})           [tier-dependent region]\n",
    "#   3. (lat_i, lon_i) | r_i ~ N(center_{r_i}, Sigma_{r_i})\n",
    "#   4. s_i | r_i, t_i ~ SkewNorm(alpha_{r,t}, mu_{r,t}, sigma_{r,t})\n",
    "# ==============================================================================\n",
    "\n",
    "def generate_students(n: int = 22000, seed: int = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate a synthetic student population with realistic characteristics.\n",
    "    \n",
    "    The generation process:\n",
    "    1. Assign tier (1-4) uniformly (CPS assigns based on census tract)\n",
    "    2. Assign region based on tier-specific probabilities (T4 more in North)\n",
    "    3. Generate location from region-specific bivariate Gaussian\n",
    "    4. Generate score from region x tier skewed normal distribution\n",
    "    5. Apply private school exit (remove some high-scoring T4 students)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int, default=22000\n",
    "        Number of students to generate (approximate SEHS applicant pool size)\n",
    "    seed : int or None\n",
    "        Random seed for reproducibility. If None, uses current RNG state.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with columns:\n",
    "        - Tier: int (1-4)\n",
    "        - Region: str ('north', 'loop', 'west', 'south')\n",
    "        - Score: float (400-900, clipped)\n",
    "        - Lat, Lon: float (geographic coordinates)\n",
    "        - TieBreaker: float (for breaking score ties in matching)\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # STEP 1: Assign tiers uniformly\n",
    "    # -------------------------------------------------------------------------\n",
    "    # CPS assigns tiers based on census tract socioeconomic characteristics.\n",
    "    # I assume approximately equal citywide representation in each tier.\n",
    "    # This is a simplification; in reality, tier sizes may differ slightly.\n",
    "    tiers = np.random.choice([1, 2, 3, 4], size=n, p=[0.25, 0.25, 0.25, 0.25])\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # STEP 2: Assign regions based on tier\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Higher tiers (T3, T4) are more concentrated in North/Loop (affluent areas).\n",
    "    # Lower tiers (T1, T2) are more concentrated in West/South (lower-income areas).\n",
    "    # TIER_BY_REGION contains these conditional probabilities P(region | tier).\n",
    "    regions = np.empty(n, dtype='<U10')\n",
    "    \n",
    "    for tier in [1, 2, 3, 4]:\n",
    "        tier_mask = (tiers == tier)\n",
    "        n_tier = np.sum(tier_mask)\n",
    "        \n",
    "        # Get conditional distribution P(region | tier)\n",
    "        region_probs = TIER_BY_REGION[tier]\n",
    "        region_names = list(region_probs.keys())\n",
    "        region_weights = [region_probs[r] for r in region_names]\n",
    "        \n",
    "        # Sample regions for this tier\n",
    "        regions[tier_mask] = np.random.choice(\n",
    "            region_names, size=n_tier, p=region_weights\n",
    "        )\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # STEP 3: Generate geographic locations\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Each region has a center (lat_center, lon_center) and spread (lat_std, lon_std).\n",
    "    # Student locations are drawn from a bivariate Gaussian centered on the region.\n",
    "    lats = np.zeros(n)\n",
    "    lons = np.zeros(n)\n",
    "    \n",
    "    for region_name, region_data in REGIONS.items():\n",
    "        mask = (regions == region_name)\n",
    "        n_region = np.sum(mask)\n",
    "        \n",
    "        if n_region > 0:\n",
    "            # Draw from N(center, std^2) independently for lat and lon\n",
    "            lats[mask] = np.random.normal(\n",
    "                region_data['lat_center'], \n",
    "                region_data['lat_std'], \n",
    "                n_region\n",
    "            )\n",
    "            lons[mask] = np.random.normal(\n",
    "                region_data['lon_center'], \n",
    "                region_data['lon_std'], \n",
    "                n_region\n",
    "            )\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # STEP 4: Generate scores using skewed normal distributions\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Scores depend on both region and tier, reflecting:\n",
    "    #   - Higher scores in North/Loop (better-resourced schools)\n",
    "    #   - Higher scores in higher tiers (socioeconomic advantage)\n",
    "    # I use skewed normal to capture asymmetry (right skew in T1, left skew in T4).\n",
    "    scores = np.zeros(n)\n",
    "    \n",
    "    for region_name in REGIONS.keys():\n",
    "        for tier in [1, 2, 3, 4]:\n",
    "            mask = (regions == region_name) & (tiers == tier)\n",
    "            n_group = np.sum(mask)\n",
    "            \n",
    "            if n_group > 0:\n",
    "                # Get distribution parameters for this region x tier\n",
    "                dist_params = V13_SCORE_DISTRIBUTIONS[region_name][tier]\n",
    "                \n",
    "                # Draw from SkewNorm(a=skew, loc=loc, scale=scale)\n",
    "                # a > 0: right skew (long right tail)\n",
    "                # a < 0: left skew (long left tail, ceiling effects)\n",
    "                scores[mask] = skewnorm.rvs(\n",
    "                    a=dist_params['skew'],      # Shape (skewness) parameter alpha\n",
    "                    loc=dist_params['loc'],     # Location parameter mu\n",
    "                    scale=dist_params['scale'], # Scale parameter sigma\n",
    "                    size=n_group\n",
    "                )\n",
    "    \n",
    "    # Add small noise (measurement error) and clip to valid range [400, 900]\n",
    "    # The 400 lower bound represents the practical minimum composite score\n",
    "    scores = np.clip(scores + np.random.normal(0, 3, n), 400, 900)\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # CREATE DATAFRAME\n",
    "    # -------------------------------------------------------------------------\n",
    "    df = pd.DataFrame({\n",
    "        'Tier': tiers,\n",
    "        'Region': regions,\n",
    "        'Score': scores,\n",
    "        'Lat': lats,\n",
    "        'Lon': lons,\n",
    "    })\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # STEP 5: Apply private school exit\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Very high-scoring T4 students may opt out of CPS entirely:\n",
    "    #   - Choose private high schools (Latin, Lab, Parker, etc.)\n",
    "    #   - Move to high-performing suburban districts\n",
    "    # This is modeled as probabilistic removal above a threshold.\n",
    "    # Exit rates are higher in West/South (brain drain to private schools).\n",
    "    for region in REGIONS.keys():\n",
    "        threshold = PARAMS['exit_threshold'].get(region, 850)\n",
    "        prob = PARAMS['exit_prob'].get(region, 0.3)\n",
    "        \n",
    "        # Find high-scoring T4 students in this region\n",
    "        candidates = df[\n",
    "            (df['Region'] == region) & \n",
    "            (df['Tier'] == 4) & \n",
    "            (df['Score'] > threshold)\n",
    "        ].index\n",
    "        \n",
    "        if len(candidates) > 0:\n",
    "            # Remove a fraction of them (simulating private school choice)\n",
    "            n_drop = int(len(candidates) * prob)\n",
    "            drop_idx = np.random.choice(\n",
    "                candidates, \n",
    "                size=min(n_drop, len(candidates)), \n",
    "                replace=False\n",
    "            )\n",
    "            df = df.drop(drop_idx)\n",
    "    \n",
    "    # Add tiebreaker for matching (random lottery for equal scores)\n",
    "    df['TieBreaker'] = np.random.random(len(df))\n",
    "    \n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# GENERATE SAMPLE POPULATION\n",
    "# ==============================================================================\n",
    "students = generate_students(seed=42)\n",
    "\n",
    "print(f\"Generated {len(students):,} students (after private school exit)\")\n",
    "print()\n",
    "print(\"Distribution by region:\")\n",
    "print(students.groupby('Region')['Score'].agg(['count', 'mean', 'std']).round(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Visualizing Generated Score Distributions\n",
    "\n",
    "Before running the full simulation, I visualize the generated score distributions to verify they match the modeling assumptions. This serves as a sanity check that the skewnorm parameters produce reasonable score distributions.\n",
    "\n",
    "Key things to verify:\n",
    "1. **Tier ordering**: T4 scores should be highest, T1 lowest\n",
    "2. **Regional differences**: North/Loop should have higher scores than West/South\n",
    "3. **Skewness patterns**: T1 should be right-skewed, T4 should be left-skewed (for North/Loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T10:43:29.503905Z",
     "start_time": "2025-11-29T10:43:29.038895Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# VISUALIZATION: GENERATED SCORE DISTRIBUTIONS\n",
    "# ==============================================================================\n",
    "# This function creates a 2x2 grid of plots to visualize the generated student\n",
    "# population and verify the score distributions match modeling assumptions.\n",
    "#\n",
    "# Variables:\n",
    "#   students    : DataFrame of generated students\n",
    "#   tier_colors : Color palette for tiers (T1=red, T2=blue, T3=green, T4=purple)\n",
    "#   region_colors : Color palette for regions (north=blue, loop=orange, west=green, south=red)\n",
    "#   region_order : Canonical ordering of regions for consistent plotting\n",
    "# ==============================================================================\n",
    "\n",
    "def plot_score_distributions(students: pd.DataFrame) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Visualize generated score distributions by region and tier.\n",
    "    \n",
    "    Creates a 2x2 grid:\n",
    "    - [0,0] Histograms by tier (all regions combined)\n",
    "    - [0,1] Overlapping density estimates by tier\n",
    "    - [1,0] T4 distributions by region (critical for elite school calibration)\n",
    "    - [1,1] Boxplots by region (shows medians and spread)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    students : pd.DataFrame\n",
    "        Generated student data with columns: Tier, Region, Score\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The 2x2 visualization figure\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Color schemes\n",
    "    tier_colors = {1: '#e41a1c', 2: '#377eb8', 3: '#4daf4a', 4: '#984ea3'}\n",
    "    region_colors = {'north': '#1f77b4', 'loop': '#ff7f0e', 'west': '#2ca02c', 'south': '#d62728'}\n",
    "    region_order = ['north', 'loop', 'west', 'south']\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # PANEL [0,0]: Histograms by tier (all regions combined)\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Shows the overall score distribution for each tier, aggregating all regions.\n",
    "    # Expect: T4 highest, T1 lowest; all distributions should overlap substantially.\n",
    "    ax = axes[0, 0]\n",
    "    for tier in [1, 2, 3, 4]:\n",
    "        tier_scores = students[students['Tier'] == tier]['Score']\n",
    "        ax.hist(tier_scores, bins=50, alpha=0.5, label=f'Tier {tier}', \n",
    "                color=tier_colors[tier], density=True)\n",
    "    \n",
    "    ax.set_xlabel('Score')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title('Score Distributions by Tier (All Regions)', fontweight='bold')\n",
    "    ax.legend()\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # PANEL [0,1]: Overlapping density estimates\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Shows tier separation more clearly using filled area plots.\n",
    "    # Plot in reverse order (T4 first) so T1 appears on top.\n",
    "    ax = axes[0, 1]\n",
    "    bins = np.linspace(400, 900, 60)\n",
    "    \n",
    "    for tier in [4, 3, 2, 1]:  # Reverse order for visual layering\n",
    "        tier_scores = students[students['Tier'] == tier]['Score']\n",
    "        counts, bin_edges = np.histogram(tier_scores, bins=bins, density=True)\n",
    "        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "        ax.fill_between(bin_centers, counts, alpha=0.35, \n",
    "                        color=tier_colors[tier], label=f'Tier {tier}')\n",
    "        ax.plot(bin_centers, counts, color=tier_colors[tier], linewidth=1.5)\n",
    "    \n",
    "    ax.set_xlabel('Score')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title('Overlapping Tier Distributions', fontweight='bold')\n",
    "    ax.legend()\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # PANEL [1,0]: T4 distributions by region\n",
    "    # -------------------------------------------------------------------------\n",
    "    # This is critical for calibrating elite school cutoffs.\n",
    "    # North/Loop T4 should be tightly concentrated near 870.\n",
    "    # West/South T4 should be wider and lower.\n",
    "    ax = axes[1, 0]\n",
    "    t4_students = students[students['Tier'] == 4]\n",
    "    \n",
    "    for region in region_order:\n",
    "        region_scores = t4_students[t4_students['Region'] == region]['Score']\n",
    "        ax.hist(region_scores, bins=40, alpha=0.5, label=f'{region.title()} T4', \n",
    "                color=region_colors[region], density=True)\n",
    "    \n",
    "    ax.set_xlabel('Score')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title('Tier 4 Score Distributions by Region', fontweight='bold')\n",
    "    ax.legend()\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # PANEL [1,1]: Boxplots by region (all tiers)\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Shows medians, quartiles, and outliers for each region.\n",
    "    # Expect: North > Loop > South > West (approximately)\n",
    "    ax = axes[1, 1]\n",
    "    data_for_box = [students[students['Region'] == r]['Score'].values \n",
    "                    for r in region_order]\n",
    "    \n",
    "    bp = ax.boxplot(data_for_box, labels=[r.title() for r in region_order], \n",
    "                    patch_artist=True)\n",
    "    \n",
    "    # Color the boxes by region\n",
    "    for patch, region in zip(bp['boxes'], region_order):\n",
    "        patch.set_facecolor(region_colors[region])\n",
    "        patch.set_alpha(0.6)\n",
    "    \n",
    "    ax.set_xlabel('Region')\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_title('Score Distribution by Region (All Tiers)', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Generate and display the distribution plots\n",
    "fig = plot_score_distributions(students)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Running the Full v13 Simulation\n",
    "\n",
    "I now import and run the complete v13 simulation from `sehs_simulation_v13.py`. The simulation performs:\n",
    "\n",
    "1. **Student generation**: Creates ~22,000 students with scores, tiers, regions, and locations\n",
    "2. **Preference calculation**: Each student computes utility for each school and ranks them\n",
    "3. **Serial dictatorship matching**: Students processed in score order; each assigned to highest-ranked school with seats\n",
    "4. **Cutoff computation**: For each school-tier, record the score of the last admitted student\n",
    "5. **Error analysis**: Compare simulated cutoffs to actual 2024-2025 cutoffs\n",
    "\n",
    "The simulation is stochastic (random student generation), so I run multiple seeds to assess stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T10:43:36.441654Z",
     "start_time": "2025-11-29T10:43:35.805320Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# IMPORT AND RUN THE FULL V13 SIMULATION\n",
    "# ==============================================================================\n",
    "# The sehs_simulation_v13.py module contains the complete simulation:\n",
    "#   - generate_students(): Creates synthetic student population\n",
    "#   - compute_preferences(): Calculates utility-based school rankings\n",
    "#   - run_matching(): Implements serial dictatorship algorithm\n",
    "#   - compute_cutoffs(): Extracts cutoffs from matching results\n",
    "#   - compute_metrics(): Compares to actual cutoffs, computes MAE\n",
    "#\n",
    "# The run_simulation() function wraps all of these steps.\n",
    "# ==============================================================================\n",
    "\n",
    "from sehs_simulation_v13 import run_simulation, compute_cutoffs, compute_metrics\n",
    "\n",
    "print(\"Running v13 simulation with seed=42...\")\n",
    "print(\"This generates ~22,000 students and matches them to 11 schools.\")\n",
    "print()\n",
    "\n",
    "# Run the full simulation pipeline\n",
    "# Returns:\n",
    "#   matched_students: DataFrame with student data and matched school\n",
    "#   results_df: DataFrame comparing simulated vs actual cutoffs\n",
    "#   metrics: Dict with MAE, max_error, school-level errors\n",
    "matched_students, results_df, metrics = run_simulation(seed=42, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T10:44:11.588327Z",
     "start_time": "2025-11-29T10:44:08.396268Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# MULTI-SEED VALIDATION\n",
    "# ==============================================================================\n",
    "# Run the simulation with multiple random seeds to assess stability.\n",
    "# A good model should produce consistent MAE across different random draws.\n",
    "#\n",
    "# I test 5 seeds: 42, 123, 456, 789, 1000\n",
    "# For each seed, I record MAE and max_error.\n",
    "# The mean and standard deviation of MAE across seeds indicates model robustness.\n",
    "#\n",
    "# If std(MAE) is small (< 2 points), the model is stable.\n",
    "# If std(MAE) is large, results depend heavily on the random draw.\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"MULTI-SEED VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Testing model stability across 5 random seeds...\")\n",
    "print()\n",
    "\n",
    "validation_results = []\n",
    "seeds_to_test = [42, 123, 456, 789, 1000]\n",
    "\n",
    "for seed in seeds_to_test:\n",
    "    # Run simulation with this seed (verbose=False to suppress output)\n",
    "    _, _, m = run_simulation(seed=seed, verbose=False)\n",
    "    \n",
    "    # Record key metrics\n",
    "    validation_results.append({\n",
    "        'seed': seed,\n",
    "        'mae': m['overall_mae'],\n",
    "        'max_error': m['max_error'],\n",
    "    })\n",
    "    print(f\"Seed {seed}: MAE = {m['overall_mae']:.1f}, Max Error = {m['max_error']:.0f}\")\n",
    "\n",
    "# Convert to DataFrame for analysis\n",
    "val_df = pd.DataFrame(validation_results)\n",
    "\n",
    "print()\n",
    "print(\"-\" * 60)\n",
    "print(\"SUMMARY STATISTICS:\")\n",
    "print(f\"  Mean MAE:       {val_df['mae'].mean():.1f} points\")\n",
    "print(f\"  Std Dev MAE:    {val_df['mae'].std():.1f} points\")\n",
    "print(f\"  MAE Range:      [{val_df['mae'].min():.1f}, {val_df['mae'].max():.1f}]\")\n",
    "print(f\"  Mean Max Error: {val_df['max_error'].mean():.0f} points\")\n",
    "print()\n",
    "print(\"INTERPRETATION:\")\n",
    "if val_df['mae'].std() < 2:\n",
    "    print(\"  Model is STABLE: MAE varies by < 2 points across seeds.\")\n",
    "else:\n",
    "    print(\"  Model shows VARIABILITY: MAE varies by > 2 points across seeds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Simulation Results Visualization\n",
    "\n",
    "I create a 4-panel visualization to analyze the simulation results:\n",
    "\n",
    "1. **Per-school MAE**: Which schools are hardest to predict?\n",
    "2. **Simulated vs actual T4 cutoffs**: How well do predictions match reality?\n",
    "3. **Admits by region**: Do students from each region attend expected schools?\n",
    "4. **Error distribution**: Are errors symmetric around zero (unbiased)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T10:44:18.872681Z",
     "start_time": "2025-11-29T10:44:18.544623Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# VISUALIZATION: SIMULATION RESULTS\n",
    "# ==============================================================================\n",
    "# This function creates a 2x2 grid analyzing simulation performance.\n",
    "#\n",
    "# Variables:\n",
    "#   metrics         : Dict containing overall_mae, max_error, school_errors\n",
    "#   matched_students: DataFrame with student data and matched school\n",
    "#   cutoffs         : Dict[school][tier] -> simulated cutoff score\n",
    "#   school_errors   : List of (school_name, mae, max_err) tuples\n",
    "#   errors          : List of (simulated - actual) for all school-tier combinations\n",
    "# ==============================================================================\n",
    "\n",
    "def plot_simulation_results(metrics: dict, matched_students: pd.DataFrame) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Visualize simulation results and comparison to actual cutoffs.\n",
    "    \n",
    "    Creates a 2x2 grid:\n",
    "    - [0,0] Per-school MAE (horizontal bar chart)\n",
    "    - [0,1] Simulated vs actual T4 cutoffs (scatter plot with identity line)\n",
    "    - [1,0] Admits by region (elite vs regional schools)\n",
    "    - [1,1] Distribution of prediction errors (histogram)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    metrics : dict\n",
    "        Output from compute_metrics(), containing:\n",
    "        - overall_mae: float\n",
    "        - max_error: float\n",
    "        - school_errors: Dict[school] -> {'mae': float, 'max_err': float}\n",
    "    matched_students : pd.DataFrame\n",
    "        Student data with 'Matched' column indicating assigned school\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The 2x2 results figure\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # PANEL [0,0]: Per-school MAE (horizontal bar chart)\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Shows which schools are hardest to predict.\n",
    "    # Elite schools (red) typically have lower MAE than regional schools (blue).\n",
    "    ax = axes[0, 0]\n",
    "    \n",
    "    # Extract school errors and sort by MAE (highest first)\n",
    "    school_errors = [(name, err['mae'], err['max_err']) \n",
    "                     for name, err in metrics['school_errors'].items()]\n",
    "    school_errors.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    schools = [s[0] for s in school_errors]\n",
    "    maes = [s[1] for s in school_errors]\n",
    "    \n",
    "    # Color elite schools differently\n",
    "    colors = ['#d62728' if s in ELITE_SCHOOLS else '#1f77b4' for s in schools]\n",
    "    \n",
    "    bars = ax.barh(schools, maes, color=colors, alpha=0.7)\n",
    "    ax.axvline(25, color='red', linestyle='--', linewidth=2, label='Target: MAE < 25')\n",
    "    ax.set_xlabel('Mean Absolute Error (points)')\n",
    "    ax.set_title('Per-School MAE\\n(Red = Elite Schools, Blue = Regional Schools)', fontweight='bold')\n",
    "    ax.legend(loc='lower right')\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # PANEL [0,1]: Simulated vs Actual T4 cutoffs (scatter plot)\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Points on the diagonal indicate perfect prediction.\n",
    "    # Deviations from diagonal show systematic over/under-prediction.\n",
    "    ax = axes[0, 1]\n",
    "    \n",
    "    # Compute cutoffs from matched students\n",
    "    cutoffs = compute_cutoffs(matched_students)\n",
    "    \n",
    "    sim_t4 = []\n",
    "    actual_t4 = []\n",
    "    school_names = []\n",
    "    \n",
    "    for school in SCHOOLS.keys():\n",
    "        if 4 in cutoffs.get(school, {}) and 4 in CUTOFFS_2024_CALIBRATION.get(school, {}):\n",
    "            sim_t4.append(cutoffs[school][4])\n",
    "            actual_t4.append(CUTOFFS_2024_CALIBRATION[school][4])\n",
    "            school_names.append(school)\n",
    "    \n",
    "    ax.scatter(actual_t4, sim_t4, s=100, alpha=0.7)\n",
    "    \n",
    "    # Add school name labels\n",
    "    for i, name in enumerate(school_names):\n",
    "        ax.annotate(name[:8], (actual_t4[i], sim_t4[i]), fontsize=8, alpha=0.7)\n",
    "    \n",
    "    # Add diagonal line (perfect prediction)\n",
    "    ax.plot([500, 900], [500, 900], 'r--', linewidth=2, label='Perfect fit')\n",
    "    ax.set_xlabel('Actual T4 Cutoff')\n",
    "    ax.set_ylabel('Simulated T4 Cutoff')\n",
    "    ax.set_title('Simulated vs Actual T4 Cutoffs', fontweight='bold')\n",
    "    ax.legend()\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # PANEL [1,0]: Admits by region (elite vs regional schools)\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Shows whether students from each region attend the expected schools.\n",
    "    # North/Loop students should dominate elite schools.\n",
    "    # West/South students should appear at regional schools.\n",
    "    ax = axes[1, 0]\n",
    "    \n",
    "    # Filter to matched students only\n",
    "    matched = matched_students[matched_students['Matched'].notna()]\n",
    "    \n",
    "    # Count admits by region and school\n",
    "    region_school_counts = matched.groupby(['Region', 'Matched']).size().unstack(fill_value=0)\n",
    "    \n",
    "    # Aggregate to elite vs regional schools\n",
    "    elite_cols = [s for s in ELITE_SCHOOLS if s in region_school_counts.columns]\n",
    "    other_cols = [s for s in region_school_counts.columns if s not in ELITE_SCHOOLS]\n",
    "    \n",
    "    elite_counts = region_school_counts[elite_cols].sum(axis=1) if elite_cols else pd.Series(0, index=region_school_counts.index)\n",
    "    other_counts = region_school_counts[other_cols].sum(axis=1) if other_cols else pd.Series(0, index=region_school_counts.index)\n",
    "    \n",
    "    regions = ['north', 'loop', 'west', 'south']\n",
    "    x = np.arange(len(regions))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax.bar(x - width/2, [elite_counts.get(r, 0) for r in regions], width, \n",
    "           label='Elite Schools', color='#1f77b4')\n",
    "    ax.bar(x + width/2, [other_counts.get(r, 0) for r in regions], width, \n",
    "           label='Regional Schools', color='#ff7f0e')\n",
    "    \n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([r.title() for r in regions])\n",
    "    ax.set_ylabel('Number of Admits')\n",
    "    ax.set_title('Admits by Home Region: Elite vs Regional Schools', fontweight='bold')\n",
    "    ax.legend()\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # PANEL [1,1]: Error distribution (histogram)\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Shows whether errors are symmetric around zero (unbiased model).\n",
    "    # A good model should have errors centered near zero.\n",
    "    ax = axes[1, 1]\n",
    "    \n",
    "    # Compute errors for all school-tier combinations\n",
    "    errors = []\n",
    "    for school in SCHOOLS.keys():\n",
    "        for tier in ['Rank', 1, 2, 3, 4]:\n",
    "            if tier in cutoffs.get(school, {}) and tier in CUTOFFS_2024_CALIBRATION.get(school, {}):\n",
    "                err = cutoffs[school][tier] - CUTOFFS_2024_CALIBRATION[school][tier]\n",
    "                errors.append(err)\n",
    "    \n",
    "    ax.hist(errors, bins=30, edgecolor='black', alpha=0.7)\n",
    "    ax.axvline(0, color='red', linestyle='--', linewidth=2, label='Zero error')\n",
    "    ax.axvline(np.mean(errors), color='green', linestyle='-', linewidth=2, \n",
    "               label=f'Mean: {np.mean(errors):.1f}')\n",
    "    ax.set_xlabel('Error (Simulated - Actual)')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('Distribution of Cutoff Prediction Errors', fontweight='bold')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Generate and display the results visualization\n",
    "fig = plot_simulation_results(metrics, matched_students)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Conclusions\n",
    "\n",
    "### 7.1 Key Findings from MLE Analysis\n",
    "\n",
    "1. **Selection bias is substantial and asymmetric across tiers.** For Tier 1 at elite schools, the observed mean exceeds the true population mean by 150-300 points. For Tier 4, the bias is only 10-30 points because truncation occurs closer to the population mean (the cutoff is not far above $\\mu$).\n",
    "\n",
    "2. **Elite schools exhibit extremely tight T4 distributions.** Northside has $\\hat{\\sigma} < 5$ for T4, implying virtually all admitted T4 students score 890+. This reflects both extreme competition and ceiling effects near the 900-point maximum.\n",
    "\n",
    "3. **Regional schools have fundamentally different applicant pools.** Schools like South Shore and King have $\\hat{\\sigma} > 60$ for T4, indicating heterogeneous applicant pools. This bifurcation suggests modeling elite and regional schools separately may improve accuracy.\n",
    "\n",
    "### 7.2 Simulation Performance\n",
    "\n",
    "The v13 model, with parameters tuned via 500 trials of Optuna Bayesian optimization, achieves:\n",
    "\n",
    "| Metric | Value | Target |\n",
    "|--------|-------|--------|\n",
    "| Overall MAE | ~23 points | - |\n",
    "| Max error | < 85 points | < 80 |\n",
    "| Max school MAE | ~30 points | < 25 |\n",
    "\n",
    "**Interpretation**: The model predicts cutoffs within 23 points on average, which is reasonable given the inherent stochasticity of the admissions process. However, some schools (particularly regional schools competing for overlapping applicant pools) remain challenging to predict.\n",
    "\n",
    "### 7.3 Limitations and Future Work\n",
    "\n",
    "1. **Unknown applicant counts**: I estimate tier-specific applicant numbers; actual counts are not published by CPS. More accurate applicant data would improve the acceptance rate constraint.\n",
    "\n",
    "2. **Normality assumption in MLE**: Score distributions may deviate from normality, especially for regional schools with potential bimodality (e.g., students from Academic Centers vs. general population).\n",
    "\n",
    "3. **Static preferences**: The model assumes preferences are fixed. In reality, students may update preferences strategically based on perceived admission chances.\n",
    "\n",
    "4. **No sibling/legacy effects**: The model does not account for sibling preferences or Academic Center feeder patterns, which affect demand at specific schools.\n",
    "\n",
    "5. **\"Whack-a-mole\" problem**: Regional schools (King, Brooks, Hancock, Lindblom) compete for overlapping applicant pools. Adjusting parameters to improve one school often worsens another. A future v14 model might separate elite and regional schools into distinct sub-models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T10:54:43.397522Z",
     "start_time": "2025-11-29T10:54:43.367933Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# FINAL SUMMARY\n",
    "# ==============================================================================\n",
    "# This cell prints a comprehensive summary of both the MLE analysis and simulation\n",
    "# performance, including detailed breakdowns by school type and tier.\n",
    "# ==============================================================================\n",
    "\n",
    "def mae_rating(mae):\n",
    "    \"\"\"Convert MAE to a qualitative rating.\"\"\"\n",
    "    if mae < 20:\n",
    "        return \"EXCELLENT\"\n",
    "    elif mae < 30:\n",
    "        return \"GOOD\"\n",
    "    elif mae < 40:\n",
    "        return \"FAIR\"\n",
    "    else:\n",
    "        return \"POOR\"\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"FINAL MODEL SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# MLE Analysis Summary\n",
    "print(\"MLE ANALYSIS (Section 4-5):\")\n",
    "print(f\"  Schools analyzed:        {len(ALL_MLE_RESULTS)}\")\n",
    "print(f\"  Tier-level estimates:    {sum(len(r) for r in ALL_MLE_RESULTS.values())}\")\n",
    "print(f\"  Data source:             CPS 2024-2025 Official Release (3/14/2025)\")\n",
    "print()\n",
    "\n",
    "# Key MLE insights\n",
    "elite_t4_sigmas = [ALL_MLE_RESULTS[s][4].sigma for s in ['Walter Payton', 'Northside', 'Whitney Young', 'Jones', 'Lane Tech']]\n",
    "regional_t4_sigmas = [ALL_MLE_RESULTS[s][4].sigma for s in ['King', 'South Shore', 'Westinghouse', 'Brooks', 'Hancock', 'Lindblom']]\n",
    "\n",
    "print(\"  KEY INSIGHT - T4 sigma bifurcation:\")\n",
    "print(f\"    Elite schools avg sigma:    {np.mean(elite_t4_sigmas):.1f}\")\n",
    "print(f\"    Regional schools avg sigma: {np.mean(regional_t4_sigmas):.1f}\")\n",
    "print()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# SIMULATION SUMMARY\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"SIMULATION (v13, Optuna-tuned, Section 6):\")\n",
    "print(f\"  Overall MAE:             {metrics['overall_mae']:.1f} points  [{mae_rating(metrics['overall_mae'])}]\")\n",
    "print(f\"  Max Error:               {metrics['max_error']:.0f} points\")\n",
    "print()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# DETAILED MAE BY SCHOOL TYPE\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"MAE BY SCHOOL TYPE:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Define school groups\n",
    "regional_schools_list = ['King', 'South Shore', 'Westinghouse', 'Brooks', 'Hancock', 'Lindblom']\n",
    "\n",
    "# Compute MAE for each group\n",
    "elite_maes = [metrics['school_errors'][s]['mae'] for s in ELITE_SCHOOLS if s in metrics['school_errors']]\n",
    "regional_maes = [metrics['school_errors'][s]['mae'] for s in regional_schools_list if s in metrics['school_errors']]\n",
    "\n",
    "elite_avg = np.mean(elite_maes)\n",
    "regional_avg = np.mean(regional_maes)\n",
    "\n",
    "print(f\"  Elite Schools:           {elite_avg:.1f} +/- {np.std(elite_maes):.1f}  [{mae_rating(elite_avg)}]\")\n",
    "for school in ELITE_SCHOOLS:\n",
    "    if school in metrics['school_errors']:\n",
    "        school_mae = metrics['school_errors'][school]['mae']\n",
    "        print(f\"    {school:<20} {school_mae:>5.1f}  [{mae_rating(school_mae)}]\")\n",
    "\n",
    "print()\n",
    "print(f\"  Regional Schools:        {regional_avg:.1f} +/- {np.std(regional_maes):.1f}  [{mae_rating(regional_avg)}]\")\n",
    "for school in regional_schools_list:\n",
    "    if school in metrics['school_errors']:\n",
    "        school_mae = metrics['school_errors'][school]['mae']\n",
    "        print(f\"    {school:<20} {school_mae:>5.1f}  [{mae_rating(school_mae)}]\")\n",
    "\n",
    "print()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# DETAILED MAE BY TIER\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"MAE BY TIER:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Compute cutoffs from matched students for tier-level analysis\n",
    "cutoffs = compute_cutoffs(matched_students)\n",
    "\n",
    "# Calculate errors by tier\n",
    "tier_errors = {tier: [] for tier in ['Rank', 1, 2, 3, 4]}\n",
    "\n",
    "for school in SCHOOLS.keys():\n",
    "    for tier in ['Rank', 1, 2, 3, 4]:\n",
    "        if tier in cutoffs.get(school, {}) and tier in CUTOFFS_2024_CALIBRATION.get(school, {}):\n",
    "            err = abs(cutoffs[school][tier] - CUTOFFS_2024_CALIBRATION[school][tier])\n",
    "            tier_errors[tier].append(err)\n",
    "\n",
    "for tier in ['Rank', 1, 2, 3, 4]:\n",
    "    if tier_errors[tier]:\n",
    "        tier_label = f\"Tier {tier}\" if tier != 'Rank' else \"Rank\"\n",
    "        mean_err = np.mean(tier_errors[tier])\n",
    "        std_err = np.std(tier_errors[tier])\n",
    "        print(f\"  {tier_label:<10} MAE: {mean_err:>5.1f} +/- {std_err:>5.1f}  [{mae_rating(mean_err)}]  (n={len(tier_errors[tier])})\")\n",
    "\n",
    "print()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# MAE BY TIER AND SCHOOL TYPE (CROSS-TABULATION)\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"MAE BY TIER AND SCHOOL TYPE:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Calculate errors by tier for each school type\n",
    "elite_tier_errors = {tier: [] for tier in ['Rank', 1, 2, 3, 4]}\n",
    "regional_tier_errors = {tier: [] for tier in ['Rank', 1, 2, 3, 4]}\n",
    "\n",
    "for school in SCHOOLS.keys():\n",
    "    is_elite = school in ELITE_SCHOOLS\n",
    "    target_dict = elite_tier_errors if is_elite else regional_tier_errors\n",
    "    \n",
    "    for tier in ['Rank', 1, 2, 3, 4]:\n",
    "        if tier in cutoffs.get(school, {}) and tier in CUTOFFS_2024_CALIBRATION.get(school, {}):\n",
    "            err = abs(cutoffs[school][tier] - CUTOFFS_2024_CALIBRATION[school][tier])\n",
    "            target_dict[tier].append(err)\n",
    "\n",
    "# Print cross-tabulation\n",
    "print(f\"  {'Tier':<10} {'Elite MAE':>15} {'Regional MAE':>18}\")\n",
    "print(f\"  {'-'*10} {'-'*15} {'-'*18}\")\n",
    "\n",
    "for tier in ['Rank', 1, 2, 3, 4]:\n",
    "    tier_label = f\"Tier {tier}\" if tier != 'Rank' else \"Rank\"\n",
    "    elite_mean = np.mean(elite_tier_errors[tier]) if elite_tier_errors[tier] else float('nan')\n",
    "    regional_mean = np.mean(regional_tier_errors[tier]) if regional_tier_errors[tier] else float('nan')\n",
    "    elite_rating = mae_rating(elite_mean) if not np.isnan(elite_mean) else \"N/A\"\n",
    "    regional_rating = mae_rating(regional_mean) if not np.isnan(regional_mean) else \"N/A\"\n",
    "    print(f\"  {tier_label:<10} {elite_mean:>6.1f} [{elite_rating:<9}] {regional_mean:>6.1f} [{regional_rating:<9}]\")\n",
    "\n",
    "print()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# VALIDATION SUMMARY\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"VALIDATION (5-seed stability test):\")\n",
    "print(f\"  MAE range:               [{val_df['mae'].min():.1f}, {val_df['mae'].max():.1f}]\")\n",
    "print(f\"  MAE mean +/- std:        {val_df['mae'].mean():.1f} +/- {val_df['mae'].std():.1f}\")\n",
    "print()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# TARGET CHECK\n",
    "# -----------------------------------------------------------------------------\n",
    "max_school_mae = max(metrics['school_errors'][s]['mae'] for s in SCHOOLS if s in metrics['school_errors'])\n",
    "\n",
    "print(\"ROBUSTNESS CHECK:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  Overall MAE:             {metrics['overall_mae']:.1f} points  [{mae_rating(metrics['overall_mae'])}]\")\n",
    "print(f\"  Elite Schools MAE:       {elite_avg:.1f} points  [{mae_rating(elite_avg)}]\")\n",
    "print(f\"  Regional Schools MAE:    {regional_avg:.1f} points  [{mae_rating(regional_avg)}]\")\n",
    "print(f\"  Max Single School MAE:   {max_school_mae:.1f} points  [{mae_rating(max_school_mae)}]\")\n",
    "print(f\"  Max Single Error:        {metrics['max_error']:.0f} points\")\n",
    "print()\n",
    "\n",
    "# Tier-level ratings\n",
    "print(\"  Tier-level performance:\")\n",
    "tier_ratings = {'EXCELLENT': 0, 'GOOD': 0, 'FAIR': 0, 'POOR': 0}\n",
    "for tier in [1, 2, 3, 4]:\n",
    "    tier_mae = np.mean(tier_errors[tier]) if tier_errors[tier] else float('nan')\n",
    "    rating = mae_rating(tier_mae)\n",
    "    tier_ratings[rating] += 1\n",
    "    print(f\"    Tier {tier}:               {tier_mae:>5.1f}  [{rating}]\")\n",
    "\n",
    "print()\n",
    "\n",
    "# School-type ratings\n",
    "print(\"  School-type performance:\")\n",
    "print(f\"    Elite Schools:         {elite_avg:>5.1f}  [{mae_rating(elite_avg)}]\")\n",
    "print(f\"    Regional Schools:      {regional_avg:>5.1f}  [{mae_rating(regional_avg)}]\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# INTERPRETATION\n",
    "# -----------------------------------------------------------------------------\n",
    "print()\n",
    "print(\"INTERPRETATION:\")\n",
    "print(\"-\" * 70)\n",
    "print()\n",
    "print(\"MAE Rating Scale:\")\n",
    "print(\"  EXCELLENT (< 20):  Predictions within ~2% of 900-point scale\")\n",
    "print(\"                     High confidence for admission decisions\")\n",
    "print(\"                     Student can reliably target schools at this level\")\n",
    "print()\n",
    "print(\"  GOOD (20-30):      Predictions within ~2-3% of scale\")\n",
    "print(\"                     Solid guidance for most students\")\n",
    "print(\"                     Add 20-point safety margin to predictions\")\n",
    "print()\n",
    "print(\"  FAIR (30-40):      Predictions within ~3-4% of scale\")\n",
    "print(\"                     Useful for general guidance, not precise targeting\")\n",
    "print(\"                     Add 30-point safety margin; consider backup schools\")\n",
    "print()\n",
    "print(\"  POOR (40+):        Predictions have >4% uncertainty\")\n",
    "print(\"                     Use only for rough estimates\")\n",
    "print(\"                     Wide confidence intervals needed\")\n",
    "print()\n",
    "\n",
    "# Count ratings\n",
    "print(\"Model Performance Summary:\")\n",
    "excellent_count = sum(1 for s in metrics['school_errors'].values() if s['mae'] < 20)\n",
    "good_count = sum(1 for s in metrics['school_errors'].values() if 20 <= s['mae'] < 30)\n",
    "fair_count = sum(1 for s in metrics['school_errors'].values() if 30 <= s['mae'] < 40)\n",
    "poor_count = sum(1 for s in metrics['school_errors'].values() if s['mae'] >= 40)\n",
    "\n",
    "print(f\"  Schools by rating:  {excellent_count} EXCELLENT, {good_count} GOOD, {fair_count} FAIR, {poor_count} POOR\")\n",
    "print(f\"  Tiers by rating:    {tier_ratings['EXCELLENT']} EXCELLENT, {tier_ratings['GOOD']} GOOD, {tier_ratings['FAIR']} FAIR, {tier_ratings['POOR']} POOR\")\n",
    "print()\n",
    "\n",
    "# Specific interpretations based on results\n",
    "print(\"Practical Implications:\")\n",
    "print()\n",
    "\n",
    "if elite_avg < regional_avg:\n",
    "    print(f\"  Elite Schools ({mae_rating(elite_avg)}, MAE {elite_avg:.1f}):\")\n",
    "    print(\"    Students targeting Payton, Northside, Lane Tech, etc. can rely on\")\n",
    "    print(\"    predictions with reasonable confidence. The model captures the\")\n",
    "    print(\"    predictable behavior of high-scoring North/Loop applicants.\")\n",
    "    print()\n",
    "    print(f\"  Regional Schools ({mae_rating(regional_avg)}, MAE {regional_avg:.1f}):\")\n",
    "    print(\"    Predictions for King, Brooks, South Shore, etc. have more uncertainty.\")\n",
    "    print(\"    These schools compete for overlapping West/South applicant pools,\")\n",
    "    print(\"    and student preferences are more variable. Use wider margins.\")\n",
    "else:\n",
    "    print(f\"  Regional Schools ({mae_rating(regional_avg)}, MAE {regional_avg:.1f}):\")\n",
    "    print(\"    Predictions for regional schools are as reliable as elite schools.\")\n",
    "    print()\n",
    "    print(f\"  Elite Schools ({mae_rating(elite_avg)}, MAE {elite_avg:.1f}):\")\n",
    "    print(\"    Elite school predictions may have more uncertainty due to\")\n",
    "    print(\"    extreme competition at the 900-point ceiling.\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Identify best and worst predicted tiers\n",
    "tier_mae_list = [(tier, np.mean(tier_errors[tier])) for tier in [1, 2, 3, 4] if tier_errors[tier]]\n",
    "best_tier = min(tier_mae_list, key=lambda x: x[1])\n",
    "worst_tier = max(tier_mae_list, key=lambda x: x[1])\n",
    "\n",
    "print(\"Tier-Level Guidance:\")\n",
    "print(f\"  Best predicted:  Tier {best_tier[0]} ({mae_rating(best_tier[1])}, MAE {best_tier[1]:.1f})\")\n",
    "print(f\"  Worst predicted: Tier {worst_tier[0]} ({mae_rating(worst_tier[1])}, MAE {worst_tier[1]:.1f})\")\n",
    "print()\n",
    "\n",
    "if worst_tier[0] == 4:\n",
    "    print(\"  Tier 4 (affluent areas) is hardest to predict because high-scoring\")\n",
    "    print(\"  students have many options and may choose private schools or suburbs.\")\n",
    "elif worst_tier[0] == 1:\n",
    "    print(\"  Tier 1 (disadvantaged areas) is hardest to predict due to wider\")\n",
    "    print(\"  score distributions and more variable application behavior.\")\n",
    "elif worst_tier[0] in [2, 3]:\n",
    "    print(f\"  Tier {worst_tier[0]} shows moderate prediction difficulty, likely due to\")\n",
    "    print(\"  students in this tier having diverse school preferences.\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Overall assessment\n",
    "overall_rating = mae_rating(metrics['overall_mae'])\n",
    "print(\"Overall Assessment:\")\n",
    "print(f\"  Model Rating: {overall_rating} (Overall MAE: {metrics['overall_mae']:.1f})\")\n",
    "print()\n",
    "\n",
    "if overall_rating == \"EXCELLENT\":\n",
    "    print(\"  This model provides highly reliable predictions across all schools\")\n",
    "    print(\"  and tiers. Students can use these predictions with high confidence\")\n",
    "    print(\"  for admission planning.\")\n",
    "elif overall_rating == \"GOOD\":\n",
    "    print(\"  This model provides solid predictions suitable for most students.\")\n",
    "    print(\"  Recommended use:\")\n",
    "    print(\"    - Students 30+ points above predicted cutoff: Likely admission\")\n",
    "    print(\"    - Students within 30 points: Competitive, include backup options\")\n",
    "    print(\"    - Students 30+ points below: Consider this a reach school\")\n",
    "elif overall_rating == \"FAIR\":\n",
    "    print(\"  This model provides useful guidance but with notable uncertainty.\")\n",
    "    print(\"  Recommended use:\")\n",
    "    print(\"    - Use predictions as rough estimates, not precise targets\")\n",
    "    print(\"    - Always include 2-3 backup schools at lower cutoff levels\")\n",
    "    print(\"    - Consider year-to-year variation in actual cutoffs\")\n",
    "else:\n",
    "    print(\"  This model has significant prediction uncertainty.\")\n",
    "    print(\"  Use predictions only for general orientation, not decision-making.\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Admission Probability Simulator\n",
    "\n",
    "This tool estimates your probability of admission to **each** of the 11 Selective Enrollment High Schools based on your score and tier.\n",
    "\n",
    "## How It Works\n",
    "\n",
    "1. **Enter your profile**: Composite score (400-900) and tier (1-4)\n",
    "2. **Simulation**: For each school, we run 100 simulations where that school is your #1 choice\n",
    "3. **Competition**: Each simulation includes ~2,000 students with realistic score distributions competing for scaled seat counts\n",
    "\n",
    "The matching algorithm replicates the actual CPS process:\n",
    "- **Phase 1 (30% of seats)**: Rank-based matching - highest scores get first pick regardless of tier\n",
    "- **Phase 2 (70% of seats)**: Tier-based matching - seats allocated within each tier by score\n",
    "\n",
    "## Output\n",
    "\n",
    "For each school, you'll see:\n",
    "- **Probability**: Percentage of simulations where you were admitted (if that school was your #1 choice)\n",
    "- **Assessment**: Qualitative rating based on probability\n",
    "\n",
    "| Probability | Assessment |\n",
    "|-------------|------------|\n",
    "| 95%+ | VIRTUALLY CERTAIN |\n",
    "| 90-94% | EXTREMELY LIKELY |\n",
    "| 85-89% | VERY LIKELY |\n",
    "| 80-84% | HIGHLY LIKELY |\n",
    "| 75-79% | LIKELY |\n",
    "| 70-74% | PROBABLE |\n",
    "| 65-69% | GOOD CHANCE |\n",
    "| 60-64% | FAVORABLE |\n",
    "| 55-59% | SLIGHT EDGE |\n",
    "| 50-54% | TOSS-UP |\n",
    "| 40-49% | COMPETITIVE |\n",
    "| 30-39% | REACH |\n",
    "| 20-29% | STRETCH |\n",
    "| 10-19% | LONG SHOT |\n",
    "| 1-9% | UNLIKELY |\n",
    "| 0% | NO CHANCE |\n",
    "\n",
    "## Summary Categories\n",
    "\n",
    "At the end, schools are grouped into:\n",
    "- **Very Likely (80%+)**: Strong safety schools\n",
    "- **Likely (55-79%)**: Good options with reasonable confidence  \n",
    "- **Competitive (30-54%)**: Match schools - could go either way\n",
    "- **Reach (10-29%)**: Ambitious choices - possible but not probable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T12:53:59.429280Z",
     "start_time": "2025-11-29T12:53:05.505254Z"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MONTE CARLO ADMISSION PROBABILITY SIMULATOR\n",
    "# ============================================================================\n",
    "# This tool estimates your probability of admission to each SEHS school\n",
    "# by running simulations where each school is ranked as your #1 choice.\n",
    "#\n",
    "# For each school, we run 50 simulations to estimate:\n",
    "#   - Probability of admission if that school is your top choice\n",
    "#   - Overall admission landscape for your score/tier profile\n",
    "# ============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sehs_simulation_v13 import generate_students, calculate_preferences, SCHOOLS\n",
    "from sehs_data import ADMISSIONS\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# SCHOOL LIST (ordered by prestige/competitiveness)\n",
    "# ----------------------------------------------------------------------------\n",
    "SCHOOL_LIST = [\n",
    "    (1, \"Walter Payton\", 99),\n",
    "    (2, \"Northside\", 98),\n",
    "    (3, \"Whitney Young\", 96),\n",
    "    (4, \"Jones\", 93),\n",
    "    (5, \"Lane Tech\", 92),\n",
    "    (6, \"Lindblom\", 81),\n",
    "    (7, \"Hancock\", 77),\n",
    "    (8, \"King\", 77),\n",
    "    (9, \"Brooks\", 76),\n",
    "    (10, \"Westinghouse\", 71),\n",
    "    (11, \"South Shore\", 66),\n",
    "]\n",
    "\n",
    "SCHOOL_NAMES = [s[1] for s in SCHOOL_LIST]\n",
    "\n",
    "\n",
    "def run_match_with_user_prefs(student_df: pd.DataFrame, user_idx: int, user_prefs: list, scale_factor: float = 1.0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Custom matching function that preserves user's preference list.\n",
    "    \n",
    "    Args:\n",
    "        student_df: DataFrame of students\n",
    "        user_idx: Index of the user in the DataFrame\n",
    "        user_prefs: User's preference list (preserved, not recalculated)\n",
    "        scale_factor: Seat scaling factor (n_students / 22000)\n",
    "    \"\"\"\n",
    "    # Initialize seat counts - SCALED to match student population size\n",
    "    seats = {}\n",
    "    for name, school in SCHOOLS.items():\n",
    "        # Scale seats proportionally to maintain realistic competition\n",
    "        scaled_seats = max(int(school.seats * scale_factor), 1)\n",
    "        seats[name] = {\n",
    "            'Rank': max(int(scaled_seats * ADMISSIONS['rank_fraction']), 1),\n",
    "            1: max(int(scaled_seats * ADMISSIONS['tier_fraction']), 1),\n",
    "            2: max(int(scaled_seats * ADMISSIONS['tier_fraction']), 1),\n",
    "            3: max(int(scaled_seats * ADMISSIONS['tier_fraction']), 1),\n",
    "            4: max(int(scaled_seats * ADMISSIONS['tier_fraction']), 1),\n",
    "        }\n",
    "    \n",
    "    student_df = student_df.copy()\n",
    "    \n",
    "    # Initialize Preferences column with None (must exist before setting values)\n",
    "    student_df['Preferences'] = None\n",
    "    student_df['Matched'] = None\n",
    "    student_df['MatchType'] = None\n",
    "    \n",
    "    # Calculate preferences for all students EXCEPT the user\n",
    "    for idx in student_df.index:\n",
    "        if idx != user_idx:\n",
    "            prefs = calculate_preferences(student_df.loc[idx])\n",
    "            student_df.at[idx, 'Preferences'] = prefs\n",
    "        else:\n",
    "            # Use object dtype assignment for list\n",
    "            student_df.at[idx, 'Preferences'] = user_prefs\n",
    "    \n",
    "    # Phase 1: Rank-based (top 30%)\n",
    "    rank_sorted = student_df.sort_values(['Score', 'TieBreaker'], ascending=[False, True])\n",
    "    \n",
    "    for idx in rank_sorted.index:\n",
    "        prefs = rank_sorted.loc[idx, 'Preferences']\n",
    "        if not isinstance(prefs, list) or len(prefs) == 0:\n",
    "            continue\n",
    "        \n",
    "        for school in prefs:\n",
    "            if school in seats and seats[school]['Rank'] > 0:\n",
    "                student_df.loc[idx, 'Matched'] = school\n",
    "                student_df.loc[idx, 'MatchType'] = 'Rank'\n",
    "                seats[school]['Rank'] -= 1\n",
    "                break\n",
    "    \n",
    "    # Phase 2: Tier-based (remaining 70%)\n",
    "    for tier in [1, 2, 3, 4]:\n",
    "        unmatched = student_df[student_df['Matched'].isna()]\n",
    "        tier_students = unmatched[unmatched['Tier'] == tier]\n",
    "        tier_sorted = tier_students.sort_values(['Score', 'TieBreaker'], ascending=[False, True])\n",
    "        \n",
    "        for idx in tier_sorted.index:\n",
    "            if student_df.loc[idx, 'Matched'] is not None:\n",
    "                continue\n",
    "            \n",
    "            prefs = student_df.loc[idx, 'Preferences']\n",
    "            if not isinstance(prefs, list) or len(prefs) == 0:\n",
    "                continue\n",
    "            \n",
    "            for school in prefs:\n",
    "                if school in seats and seats[school][tier] > 0:\n",
    "                    student_df.loc[idx, 'Matched'] = school\n",
    "                    student_df.loc[idx, 'MatchType'] = 'Tier'\n",
    "                    seats[school][tier] -= 1\n",
    "                    break\n",
    "    \n",
    "    return student_df\n",
    "\n",
    "\n",
    "def get_assessment(prob):\n",
    "    \"\"\"Convert probability to qualitative assessment with fine-grained ratings.\"\"\"\n",
    "    if prob >= 95:\n",
    "        return \"VIRTUALLY CERTAIN\"\n",
    "    elif prob >= 90:\n",
    "        return \"EXTREMELY LIKELY\"\n",
    "    elif prob >= 85:\n",
    "        return \"VERY LIKELY\"\n",
    "    elif prob >= 80:\n",
    "        return \"HIGHLY LIKELY\"\n",
    "    elif prob >= 75:\n",
    "        return \"LIKELY\"\n",
    "    elif prob >= 70:\n",
    "        return \"PROBABLE\"\n",
    "    elif prob >= 65:\n",
    "        return \"GOOD CHANCE\"\n",
    "    elif prob >= 60:\n",
    "        return \"FAVORABLE\"\n",
    "    elif prob >= 55:\n",
    "        return \"SLIGHT EDGE\"\n",
    "    elif prob >= 50:\n",
    "        return \"TOSS-UP\"\n",
    "    elif prob >= 40:\n",
    "        return \"COMPETITIVE\"\n",
    "    elif prob >= 30:\n",
    "        return \"REACH\"\n",
    "    elif prob >= 20:\n",
    "        return \"STRETCH\"\n",
    "    elif prob >= 10:\n",
    "        return \"LONG SHOT\"\n",
    "    elif prob > 0:\n",
    "        return \"UNLIKELY\"\n",
    "    else:\n",
    "        return \"NO CHANCE\"\n",
    "\n",
    "\n",
    "def run_full_probability_analysis(\n",
    "    user_score: float,\n",
    "    user_tier: int,\n",
    "    n_simulations: int = 100,\n",
    "    n_students: int = 2000\n",
    "):\n",
    "    \"\"\"\n",
    "    Run Monte Carlo simulation for ALL schools as potential #1 choice.\n",
    "    \n",
    "    Args:\n",
    "        user_score: User's composite score (400-900)\n",
    "        user_tier: User's tier (1-4)\n",
    "        n_simulations: Simulations per school (default 50)\n",
    "        n_students: Students per simulation (default 2000)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with admission probabilities for each school\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Your Profile: Score = {user_score}, Tier = {user_tier}\")\n",
    "    print(f\"Running {n_simulations} simulations for each of 11 schools...\")\n",
    "    print(f\"Total simulations: {n_simulations * 11}\")\n",
    "    print()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for school_num, top_choice, prestige in SCHOOL_LIST:\n",
    "        print(f\"  Simulating {SCHOOLS[top_choice].short_name}...\", end=\" \")\n",
    "        \n",
    "        # Build preference list: this school first, then others by prestige\n",
    "        user_prefs = [top_choice]\n",
    "        for num, name, prest in SCHOOL_LIST:\n",
    "            if name != top_choice:\n",
    "                user_prefs.append(name)\n",
    "        user_prefs = user_prefs[:6]  # Max 6 choices\n",
    "        \n",
    "        # Determine user region based on school location\n",
    "        if top_choice in [\"Walter Payton\", \"Northside\", \"Lane Tech\"]:\n",
    "            user_region = 'north'\n",
    "        elif top_choice in [\"Whitney Young\", \"Jones\"]:\n",
    "            user_region = 'loop'\n",
    "        elif top_choice == \"Westinghouse\":\n",
    "            user_region = 'west'\n",
    "        else:\n",
    "            user_region = 'south'\n",
    "        \n",
    "        admission_count = 0\n",
    "        \n",
    "        for sim in range(n_simulations):\n",
    "            # Generate student population\n",
    "            students = generate_students(n=n_students, seed=sim * 100 + school_num * 1000)\n",
    "            \n",
    "            # Create user row\n",
    "            user_row = pd.DataFrame([{\n",
    "                'Tier': user_tier,\n",
    "                'Region': user_region,\n",
    "                'Score': user_score,\n",
    "                'Lat': SCHOOLS[top_choice].lat,\n",
    "                'Lon': SCHOOLS[top_choice].lon,\n",
    "                'TieBreaker': np.random.random()\n",
    "            }])\n",
    "            \n",
    "            students = pd.concat([students, user_row], ignore_index=True)\n",
    "            user_idx = len(students) - 1\n",
    "            \n",
    "            # Run matching with scaled seats\n",
    "            scale_factor = n_students / 22000.0\n",
    "            matched_students = run_match_with_user_prefs(students, user_idx, user_prefs, scale_factor)\n",
    "            \n",
    "            # Check if user got into their top choice\n",
    "            user_result = matched_students.loc[user_idx, 'Matched']\n",
    "            if user_result == top_choice:\n",
    "                admission_count += 1\n",
    "        \n",
    "        prob = admission_count / n_simulations * 100\n",
    "        print(f\"{prob:.0f}%\")\n",
    "        \n",
    "        results.append({\n",
    "            'Rank': school_num,\n",
    "            'School': SCHOOLS[top_choice].short_name,\n",
    "            'Full Name': top_choice,\n",
    "            'Seats': SCHOOLS[top_choice].seats,\n",
    "            'Probability': prob,\n",
    "            'Assessment': get_assessment(prob),\n",
    "            'Admissions': admission_count,\n",
    "            'Simulations': n_simulations\n",
    "        })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Display results\n",
    "    print()\n",
    "    print(\"=\" * 70)\n",
    "    print(\"ADMISSION PROBABILITY RESULTS\")\n",
    "    print(f\"Score: {user_score} | Tier: {user_tier} | Simulations per school: {n_simulations}\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "    print(f\"{'#':<3} {'School':<12} {'Seats':>6} {'Probability':>14} {'Assessment':<18}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for _, row in results_df.iterrows():\n",
    "        prob_str = f\"{row['Probability']:5.1f}%\"\n",
    "        print(f\"{row['Rank']:<3} {row['School']:<12} {row['Seats']:>6} {prob_str:>14} {row['Assessment']:<18}\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Summary with more granular breakdown\n",
    "    very_likely = results_df[results_df['Probability'] >= 80]['School'].tolist()\n",
    "    likely = results_df[(results_df['Probability'] >= 55) & (results_df['Probability'] < 80)]['School'].tolist()\n",
    "    competitive = results_df[(results_df['Probability'] >= 30) & (results_df['Probability'] < 55)]['School'].tolist()\n",
    "    reach = results_df[(results_df['Probability'] >= 10) & (results_df['Probability'] < 30)]['School'].tolist()\n",
    "    \n",
    "    print(\"SUMMARY:\")\n",
    "    if very_likely:\n",
    "        print(f\"  Very Likely (>=80%): {', '.join(very_likely)}\")\n",
    "    if likely:\n",
    "        print(f\"  Likely (55-79%): {', '.join(likely)}\")\n",
    "    if competitive:\n",
    "        print(f\"  Competitive (30-54%): {', '.join(competitive)}\")\n",
    "    if reach:\n",
    "        print(f\"  Reach (10-29%): {', '.join(reach)}\")\n",
    "    \n",
    "    if not very_likely and not likely and not competitive:\n",
    "        print(\"  All schools are reaches or long shots for your profile.\")\n",
    "        print(\"  Consider improving your score or exploring other options.\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# INTERACTIVE INPUT\n",
    "# ============================================================================\n",
    "print(\"=\" * 50)\n",
    "print(\"SEHS ADMISSION PROBABILITY CALCULATOR\")\n",
    "print(\"=\" * 50)\n",
    "print()\n",
    "print(\"This tool calculates your admission probability\")\n",
    "print(\"for each school if you rank it as #1.\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    user_score = float(input(\"Enter your composite score (400-900): \"))\n",
    "    user_score = max(400, min(900, user_score))\n",
    "    \n",
    "    user_tier = int(input(\"Enter your tier (1-4): \"))\n",
    "    user_tier = max(1, min(4, user_tier))\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Run full analysis\n",
    "    results = run_full_probability_analysis(\n",
    "        user_score=user_score,\n",
    "        user_tier=user_tier,\n",
    "        n_simulations=100,\n",
    "        n_students=2000\n",
    "    )\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(f\"Invalid input: {e}\")\n",
    "    print(\"Please enter numeric values.\")\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nSimulation cancelled.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Framework for the Monte Carlo Admission Simulator\n",
    "\n",
    "### Problem Formulation\n",
    "\n",
    "We seek to estimate the probability $P(A_s | X = x, T = t)$ that a student with composite score $x$ and tier $t$ gains admission to school $s$, conditional on ranking school $s$ as their first choice.\n",
    "\n",
    "Since the admission process involves stochastic competition from other applicants, we employ Monte Carlo simulation to estimate these probabilities empirically.\n",
    "\n",
    "---\n",
    "\n",
    "### Random Variables and Sample Space\n",
    "\n",
    "Let the following random variables be defined:\n",
    "\n",
    "| Variable | Description | Support |\n",
    "|----------|-------------|---------|\n",
    "| $X_i$ | Composite score of student $i$ | $[400, 900] \\subset \\mathbb{R}$ |\n",
    "| $T_i$ | Tier assignment of student $i$ | $\\{1, 2, 3, 4\\}$ |\n",
    "| $R_i$ | Geographic region of student $i$ | $\\{\\text{North}, \\text{Loop}, \\text{West}, \\text{South}\\}$ |\n",
    "| $\\mathbf{P}_i$ | Preference list of student $i$ | $\\mathcal{S}^{\\leq 6}$ (ordered subsets of schools) |\n",
    "| $M_i$ | Matched school for student $i$ | $\\mathcal{S} \\cup \\{\\emptyset\\}$ |\n",
    "\n",
    "where $\\mathcal{S} = \\{s_1, s_2, \\ldots, s_{11}\\}$ denotes the set of 11 SEHS schools, and $\\emptyset$ represents the unmatched state.\n",
    "\n",
    "The **sample space** for a single simulation is:\n",
    "\n",
    "$$\\Omega = \\prod_{i=1}^{n} \\left( [400, 900] \\times \\{1,2,3,4\\} \\times \\{N, L, W, S\\} \\times \\mathcal{S}^{\\leq 6} \\right)$$\n",
    "\n",
    "where $n \\approx 2000$ is the simulated applicant pool size.\n",
    "\n",
    "---\n",
    "\n",
    "### Score Distribution Model\n",
    "\n",
    "Scores are generated from a **skew-normal distribution** conditional on region and tier:\n",
    "\n",
    "$$X_i \\mid (R_i = r, T_i = t) \\sim \\text{SkewNormal}(\\xi_{r,t}, \\omega_{r,t}, \\alpha_{r,t})$$\n",
    "\n",
    "The subscript notation $(r, t)$ indexes a specific combination of region $r \\in \\{\\text{North}, \\text{Loop}, \\text{West}, \\text{South}\\}$ and tier $t \\in \\{1, 2, 3, 4\\}$. This yields a $4 \\times 4 = 16$ parameter grid, reflecting the empirical observation that score distributions vary systematically across both geographic and socioeconomic dimensions. For example, $\\xi_{\\text{North}, 4}$ denotes the location parameter for Tier 4 students residing in the North regiona subpopulation that tends to exhibit higher scores due to correlation between neighborhood characteristics and academic preparation.\n",
    "\n",
    "The parameters are:\n",
    "- $\\xi_{r,t}$ (**location**): Controls the central tendency of the distribution. Higher values shift the distribution rightward toward higher scores.\n",
    "- $\\omega_{r,t}$ (**scale**): Controls the dispersion. Larger values produce wider score spreads within the subpopulation.\n",
    "- $\\alpha_{r,t}$ (**shape/skewness**): Controls asymmetry. Positive values ($\\alpha > 0$) produce right-skewed distributions (long tail toward high scores), while negative values ($\\alpha < 0$) produce left-skewed distributions (mass concentrated at high scores with a tail toward lower scores).\n",
    "\n",
    "The probability density function is:\n",
    "\n",
    "$$f(x; \\xi, \\omega, \\alpha) = \\frac{2}{\\omega} \\phi\\left(\\frac{x - \\xi}{\\omega}\\right) \\Phi\\left(\\alpha \\cdot \\frac{x - \\xi}{\\omega}\\right)$$\n",
    "\n",
    "where $\\phi(\\cdot)$ and $\\Phi(\\cdot)$ are the standard normal PDF and CDF, respectively.\n",
    "\n",
    "**Justification for the skew-normal family:** Empirical score distributions in standardized testing typically exhibit asymmetryparticularly ceiling effects near the maximum score (900) for high-performing subpopulations. The skew-normal distribution captures this behavior parsimoniously with a single additional parameter beyond the normal distribution, while remaining analytically tractable.\n",
    "\n",
    "Scores are subsequently clipped to enforce the domain constraint:\n",
    "\n",
    "$$\\tilde{X}_i = \\min(\\max(X_i, 400), 900)$$\n",
    "\n",
    "---\n",
    "\n",
    "### The Matching Mechanism\n",
    "\n",
    "The CPS admission process implements a **serial dictatorship** mechanism, a classical assignment algorithm from mechanism design theory. This procedure is **strategy-proof**, meaning students have no incentive to misrepresent their true preferencestruthful reporting is a dominant strategy.\n",
    "\n",
    "Define the capacity constraints:\n",
    "\n",
    "- $C_s^{\\text{Rank}}$: Rank-based seats at school $s$ (30% of total capacity)\n",
    "- $C_s^{(t)}$: Tier-$t$ seats at school $s$ (17.5% of total capacity, for $t \\in \\{1,2,3,4\\}$)\n",
    "\n",
    "The algorithm proceeds in two phases:\n",
    "\n",
    "**Phase 1 (Rank-Based Matching):** \n",
    "\n",
    "All students, regardless of tier, are sorted by composite score in descending order. Beginning with the highest-scoring student, each student is considered in sequence. When a student is processed, the algorithm examines their preference list from most-preferred to least-preferred school. The student is assigned to the first school on their list that still has available rank-based seats. Once assigned, that school's rank seat count is decremented by one. If no preferred school has available rank seats, the student remains unmatched and proceeds to Phase 2.\n",
    "\n",
    "This phase allocates 30% of each school's capacity to the highest-scoring applicants citywide, irrespective of their tier classification.\n",
    "\n",
    "**Phase 2 (Tier-Based Matching):**\n",
    "\n",
    "The remaining 70% of seats are allocated within tier. For each tier $t$ from 1 to 4, the algorithm considers only unmatched students belonging to that tier, sorted by score in descending order. Each student is assigned to their highest-preference school that still has available tier-$t$ seats. This ensures that students compete primarily against others in their same socioeconomic tier for the majority of seats.\n",
    "\n",
    "#### Formalization via Permutations\n",
    "\n",
    "To express this algorithm precisely, we introduce the concept of a **permutation**. In group theory, a permutation of a set $S$ is a bijective function $\\pi: S \\to S$. The set of all permutations of $n$ elements forms the **symmetric group** $S_n$, which has $n!$ elements. Permutations are useful here because the matching algorithm processes students in a specific order determined by their scores.\n",
    "\n",
    "**Notation:** We write $\\pi(k) = i$ to mean \"the student in position $k$ of the ordering is student $i$.\" Equivalently, $\\pi^{-1}(i) = k$ gives student $i$'s position in the ordering.\n",
    "\n",
    "Let $\\pi: \\{1, \\ldots, n\\} \\to \\{1, \\ldots, n\\}$ be the permutation that orders students by score in descending order. Formally:\n",
    "\n",
    "$$X_{\\pi(1)} \\geq X_{\\pi(2)} \\geq \\cdots \\geq X_{\\pi(n)}$$\n",
    "\n",
    "**Tie-breaking:** When two students $i$ and $j$ have identical scores ($X_i = X_j$), the ordering is ambiguous. To resolve this, each student is assigned a **tie-breaker** $U_i \\sim \\text{Uniform}(0, 1)$ independently at random. The permutation $\\pi$ then satisfies:\n",
    "\n",
    "$$\\pi^{-1}(i) < \\pi^{-1}(j) \\iff (X_i > X_j) \\text{ or } (X_i = X_j \\text{ and } U_i < U_j)$$\n",
    "\n",
    "This ensures a strict total ordering exists with probability 1.\n",
    "\n",
    "The matching function $M: \\{1, \\ldots, n\\} \\to \\mathcal{S} \\cup \\{\\emptyset\\}$ is then computed as:\n",
    "\n",
    "$$M_i = \\begin{cases}\n",
    "s^* & \\text{if } \\exists s^* \\in \\mathbf{P}_i : C_{s^*}^{(\\cdot)} > 0 \\text{ when student } i \\text{ is processed} \\\\\n",
    "\\emptyset & \\text{otherwise}\n",
    "\\end{cases}$$\n",
    "\n",
    "where $C_{s^*}^{(\\cdot)}$ denotes the relevant capacity (rank or tier-specific) at the time of processing.\n",
    "\n",
    "---\n",
    "\n",
    "### Monte Carlo Estimator\n",
    "\n",
    "For each school $s$, we run $B = 100$ independent simulations. Let $Y_s^{(b)} \\in \\{0, 1\\}$ be the indicator that the user is admitted to school $s$ in simulation $b$:\n",
    "\n",
    "$$Y_s^{(b)} = \\mathbf{1}\\{M_{\\text{user}}^{(b)} = s\\}$$\n",
    "\n",
    "The Monte Carlo estimator for $P(A_s | X = x, T = t)$ is:\n",
    "\n",
    "$$\\hat{p}_s = \\frac{1}{B} \\sum_{b=1}^{B} Y_s^{(b)}$$\n",
    "\n",
    "By the Strong Law of Large Numbers:\n",
    "\n",
    "$$\\hat{p}_s \\xrightarrow{a.s.} P(A_s | X = x, T = t) \\quad \\text{as } B \\to \\infty$$\n",
    "\n",
    "#### Standard Error and Confidence Intervals\n",
    "\n",
    "Since $Y_s^{(b)} \\sim \\text{Bernoulli}(p_s)$ and the simulations are independent, the variance of the estimator is:\n",
    "\n",
    "$$\\text{Var}(\\hat{p}_s) = \\frac{p_s(1 - p_s)}{B}$$\n",
    "\n",
    "The standard error, estimated from the data, is:\n",
    "\n",
    "$$\\widehat{\\text{SE}}(\\hat{p}_s) = \\sqrt{\\frac{\\hat{p}_s(1 - \\hat{p}_s)}{B}}$$\n",
    "\n",
    "For $B = 100$ simulations:\n",
    "- If $\\hat{p}_s = 0.50$, then $\\widehat{\\text{SE}} = \\sqrt{0.25/100} = 0.05$, yielding a 95% CI of approximately $\\pm 10\\%$\n",
    "- If $\\hat{p}_s = 0.80$, then $\\widehat{\\text{SE}} = \\sqrt{0.16/100} = 0.04$, yielding a 95% CI of approximately $\\pm 8\\%$\n",
    "\n",
    "Compared to $B = 50$ simulations (where the 95% CI would be $\\pm 14\\%$ at $\\hat{p} = 0.50$), doubling the simulation count reduces the confidence interval width by a factor of $\\sqrt{2} \\approx 1.41$. This reflects the general principle that Monte Carlo standard errors decrease at rate $O(1/\\sqrt{B})$.\n",
    "\n",
    "---\n",
    "\n",
    "### Assumptions and Limitations\n",
    "\n",
    "1. **Independence across simulations**: Each simulation $b$ draws an independent applicant pool from the score distribution model. This assumes the score-generating process is stationary across hypothetical replications.\n",
    "\n",
    "2. **Deterministic preferences for competitors**: Other students' preferences are computed via a deterministic utility function that depends on school prestige, geographic distance, and region-specific penalties. Only the user's preferences are fixed exogenously (set to the school being tested as #1 choice). \n",
    "\n",
    "   *In plain terms: your simulated competitors always \"decide\" where to apply using the same formula based on where they live and their scores. You, however, get to specify your own preference list. This means the simulation captures realistic competition patterns while letting you explore \"what if I ranked school X first?\" and running 100 simulations based of that set of rotating assumptions*\n",
    "\n",
    "3. **Proportional scaling**: Seat counts are scaled by $\\lambda = n/22000$ to maintain realistic competition ratios:\n",
    "   $$C_s^{(\\cdot)} \\leftarrow \\lfloor \\lambda \\cdot C_s^{(\\cdot)} \\rfloor$$\n",
    "   This preserves the seats-to-applicants ratio when using a smaller simulated population.\n",
    "\n",
    "4. **Model misspecification**: The skew-normal score distributions are calibrated via Optuna hyperparameter optimization (a Bayesian optimization framework using Tree-structured Parzen Estimators) to minimize discrepancy between simulated and historical cutoff scores. However, this calibration targets aggregate statistics (cutoffs, acceptance rates) rather than the full distributional shape. Consequently, the fitted parameters $\\{\\xi_{r,t}, \\omega_{r,t}, \\alpha_{r,t}\\}$ may not perfectly capture features such as:\n",
    "   - Multimodality in the true score distribution\n",
    "   - Heavy tails or outlier behavior\n",
    "   - Temporal non-stationarity (year-to-year variation in applicant pools)\n",
    "   - Correlation structure between scores and unobserved confounders\n",
    "   \n",
    "   The simulation should therefore be interpreted as providing *plausible* probability estimates under the assumed model, not exact forecasts.\n",
    "\n",
    "5. **No strategic behavior**: Students are assumed to submit preferences truthfully. This assumption is justified by the strategy-proofness of serial dictatorship mechanismsno student can improve their outcome by misrepresenting preferences, regardless of others' strategies.\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "The output $\\hat{p}_s$ represents the **frequentist probability** of admission under repeated sampling from the model. It answers:\n",
    "\n",
    "> \"If we drew many applicant pools from this model and ran the CPS matching algorithm each time, in what fraction would a student with your profile be admitted to school $s$?\"\n",
    "\n",
    "This differs from a Bayesian posterior probability, which would incorporate prior beliefs about model parameters. The frequentist interpretation treats the model parameters as fixed (though estimated) and quantifies uncertainty arising solely from the randomness in competitor draws."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animated Visualization: The Serial Dictatorship Match Process\n",
    "\n",
    "This animation provides a visual demonstration of how the CPS selective enrollment matching algorithm processes students. Each student is represented as a dot, with:\n",
    "\n",
    "- **Color**: Indicates the student's home region (North=blue, Loop=orange, West=green, South=red)\n",
    "- **Shade intensity**: Indicates tier (darker = higher tier)\n",
    "\n",
    "The animation shows:\n",
    "1. Students sorted by score (rank phase) or by tier+score (tier phase)\n",
    "2. Each student \"moving\" from the applicant pool to their matched school\n",
    "3. Real-time seat availability updates\n",
    "4. Unmatched students collecting in the \"Unmatched\" area\n",
    "\n",
    "This visualization helps illustrate the competitive dynamics and geographic patterns in SEHS admissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T12:16:45.275311Z",
     "start_time": "2025-11-29T12:16:04.970220Z"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ANIMATED MATCH VISUALIZATION\n",
    "# ============================================================================\n",
    "# This cell creates an animated visualization of the serial dictatorship\n",
    "# matching process, showing how students flow from the applicant pool to \n",
    "# their matched schools.\n",
    "#\n",
    "# Features:\n",
    "#   - Log-scaled Y-axis to spread out top scores for visibility\n",
    "#   - Students \"pop\" from top of stack and move to matched school\n",
    "#   - Cap indicators show when tier/rank seats are exhausted\n",
    "#   - Complete simulation: Phase 1 (Rank 30%) + Phase 2 (Tiers 1-4, 70%)\n",
    "#   - Rank matches shown in black, tier matches in region colors\n",
    "# ============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "from collections import defaultdict\n",
    "\n",
    "# Import simulation functions from v13 module\n",
    "from sehs_simulation_v13 import generate_students, calculate_preferences, SCHOOLS\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# REGION COLOR SCHEME\n",
    "# Region determines hue, tier determines intensity (darker = higher tier)\n",
    "# Rank-based matches are shown in black\n",
    "# ----------------------------------------------------------------------------\n",
    "REGION_BASE_COLORS = {\n",
    "    'north': '#3182bd',   # Blue\n",
    "    'loop':  '#fd8d3c',   # Orange  \n",
    "    'west':  '#31a354',   # Green\n",
    "    'south': '#e6550d',   # Red-orange\n",
    "}\n",
    "\n",
    "TIER_COLORS = {\n",
    "    1: '#fee5d9',  # Light (T1)\n",
    "    2: '#fcae91',  # Medium-light (T2)\n",
    "    3: '#fb6a4a',  # Medium-dark (T3)\n",
    "    4: '#cb181d',  # Dark (T4)\n",
    "}\n",
    "\n",
    "def get_student_color(region, tier, match_type='tier'):\n",
    "    \"\"\"\n",
    "    Generate color for a student based on region, tier, and match type.\n",
    "    \n",
    "    Args:\n",
    "        region: Student's home region\n",
    "        tier: Student's tier (1-4)\n",
    "        match_type: 'rank' (black) or 'tier' (region-colored)\n",
    "    \n",
    "    Returns:\n",
    "        RGBA tuple\n",
    "    \"\"\"\n",
    "    import matplotlib.colors as mcolors\n",
    "    \n",
    "    if match_type == 'rank':\n",
    "        # Rank matches are black\n",
    "        return (0.1, 0.1, 0.1, 0.9)\n",
    "    \n",
    "    base = REGION_BASE_COLORS.get(region, '#888888')\n",
    "    rgb = mcolors.to_rgb(base)\n",
    "    \n",
    "    # Tier-based intensity: T1=lighter, T4=darker\n",
    "    tier_alphas = {1: 0.5, 2: 0.65, 3: 0.8, 4: 1.0}\n",
    "    alpha = tier_alphas.get(tier, 0.7)\n",
    "    \n",
    "    return (*rgb, alpha)\n",
    "\n",
    "\n",
    "def score_to_y(score, y_min=0, y_max=10):\n",
    "    \"\"\"\n",
    "    Convert score to Y position using exponential-like scaling.\n",
    "    Bunches low scores at bottom, spreads out high scores at top.\n",
    "    \n",
    "    Uses a power transform with exponent > 1: higher scores get more vertical space.\n",
    "    This highlights the fewer high-scoring students at the top.\n",
    "    \"\"\"\n",
    "    # Normalize score to 0-1 range (assuming 400-900 score range)\n",
    "    normalized = (score - 400) / 500\n",
    "    normalized = np.clip(normalized, 0, 1)\n",
    "    \n",
    "    # Apply power transform to spread out TOP scores (power > 1)\n",
    "    # Power of 2.5 means: bottom 50% of scores use ~18% of vertical space\n",
    "    #                     top 20% of scores use ~45% of vertical space\n",
    "    transformed = np.power(normalized, 2.5)\n",
    "    \n",
    "    # Map to y range\n",
    "    return y_min + transformed * (y_max - y_min)\n",
    "\n",
    "\n",
    "def create_match_animation(\n",
    "    students_df, \n",
    "    sample_size=400, \n",
    "    interval_ms=40,\n",
    "    students_per_frame=3,\n",
    "    seed=42\n",
    "):\n",
    "    \"\"\"\n",
    "    Create an animated visualization of the SEHS matching process.\n",
    "    \n",
    "    The animation shows the complete matching algorithm:\n",
    "    - Phase 1: Rank-based (30% of seats, highest scorers first)\n",
    "    - Phase 2: Tier-based (70% of seats, by tier then by score)\n",
    "    \n",
    "    Visual features:\n",
    "    - Students sorted by score, popped from top of stack\n",
    "    - Log-scaled Y-axis spreads out top scores\n",
    "    - Rank matches in black, tier matches in region colors\n",
    "    - Cap indicators when seats exhausted\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # SAMPLE AND PREPARE STUDENTS\n",
    "    # -------------------------------------------------------------------------\n",
    "    if len(students_df) > sample_size:\n",
    "        sample_idx = np.random.choice(len(students_df), sample_size, replace=False)\n",
    "        sample_df = students_df.iloc[sample_idx].copy()\n",
    "    else:\n",
    "        sample_df = students_df.copy()\n",
    "    \n",
    "    sample_df = sample_df.reset_index(drop=True)\n",
    "    \n",
    "    # Sort by score descending (highest first - they get processed first)\n",
    "    sample_df = sample_df.sort_values(['Score'], ascending=False)\n",
    "    sample_df = sample_df.reset_index(drop=True)\n",
    "    \n",
    "    n_students = len(sample_df)\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # SCHOOL CONFIGURATION\n",
    "    # -------------------------------------------------------------------------\n",
    "    school_order = [\n",
    "        \"Walter Payton\", \"Northside\", \"Whitney Young\", \"Jones\", \"Lane Tech\",\n",
    "        \"Lindblom\", \"Hancock\", \"Brooks\", \"King\", \"Westinghouse\", \"South Shore\"\n",
    "    ]\n",
    "    school_to_idx = {name: i for i, name in enumerate(school_order)}\n",
    "    n_schools = len(school_order)\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # INITIALIZE SEAT COUNTS (actual seats / 10 for visualization)\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Use actual school seats divided by 10 (matching 2000/22000 scale)\n",
    "    seat_counts = {}\n",
    "    for school_name in school_order:\n",
    "        school = SCHOOLS.get(school_name)\n",
    "        if school:\n",
    "            total = max(school.seats // 10, 5)  # Actual seats / 10\n",
    "            seat_counts[school_name] = {\n",
    "                'Rank': max(int(total * 0.30), 1),\n",
    "                1: max(int(total * 0.175), 1),\n",
    "                2: max(int(total * 0.175), 1),\n",
    "                3: max(int(total * 0.175), 1),\n",
    "                4: max(int(total * 0.175), 1),\n",
    "                'total': total\n",
    "            }\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # FIGURE SETUP\n",
    "    # -------------------------------------------------------------------------\n",
    "    fig, ax = plt.subplots(figsize=(20, 12))\n",
    "\n",
    "    # Layout parameters\n",
    "    pool_x = 1.0\n",
    "    school_start_x = 3.5\n",
    "    school_spacing = 1.5\n",
    "    unmatched_x = school_start_x + n_schools * school_spacing + 1\n",
    "\n",
    "    y_min, y_max = 0, 10\n",
    "\n",
    "    ax.set_xlim(-0.5, unmatched_x + 1.5)\n",
    "    ax.set_ylim(y_min - 1.5, y_max + 2.5)\n",
    "    ax.set_aspect('auto')\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Title\n",
    "    title_text = ax.text(\n",
    "        (unmatched_x + 1) / 2, y_max + 2,\n",
    "        'SEHS Serial Dictatorship Match',\n",
    "        fontsize=14, fontweight='bold', ha='center'\n",
    "    )\n",
    "\n",
    "    # Phase indicator\n",
    "    phase_text = ax.text(\n",
    "        (unmatched_x + 1) / 2, y_max + 1.4,\n",
    "        '',\n",
    "        fontsize=11, ha='center', color='darkblue'\n",
    "    )\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # COLUMN LABELS\n",
    "    # -------------------------------------------------------------------------\n",
    "    ax.text(pool_x, y_max + 0.7, 'APPLICANTS', fontsize=10, fontweight='bold',\n",
    "            ha='center', va='bottom')\n",
    "    ax.text(pool_x, y_max + 0.2, '(by score)', fontsize=8, ha='center',\n",
    "            va='bottom', color='gray')\n",
    "\n",
    "    # Region labels under applicant pool (matching the histogram columns)\n",
    "    region_x_offsets = {'north': -0.6, 'loop': -0.2, 'west': 0.2, 'south': 0.6}\n",
    "    region_labels = {'north': 'N', 'loop': 'L', 'west': 'W', 'south': 'S'}\n",
    "    for region, offset in region_x_offsets.items():\n",
    "        ax.text(pool_x + offset, y_min - 0.3, region_labels[region],\n",
    "                fontsize=7, ha='center', va='top',\n",
    "                color=REGION_BASE_COLORS[region], fontweight='bold')\n",
    "\n",
    "    # School column indicators at top (simplified - names are at bottom)\n",
    "    for i, school in enumerate(school_order):\n",
    "        x = school_start_x + i * school_spacing\n",
    "        ax.text(x, y_max + 0.5, '|', fontsize=12, ha='center', va='bottom',\n",
    "                color='#999999')\n",
    "\n",
    "    ax.text(unmatched_x, y_max + 0.7, 'UNMATCHED', fontsize=10, fontweight='bold',\n",
    "            ha='center', va='bottom', color='#666666')\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # SEAT COUNT DISPLAYS AND CAP INDICATORS\n",
    "    # -------------------------------------------------------------------------\n",
    "    seat_texts = {}\n",
    "    cap_indicators = {}  # Will hold cap indicator text objects\n",
    "\n",
    "    for i, school in enumerate(school_order):\n",
    "        x = school_start_x + i * school_spacing\n",
    "        total = seat_counts[school]['total']\n",
    "        short_name = SCHOOLS[school].short_name\n",
    "\n",
    "        # School name (centered under column)\n",
    "        ax.text(x, y_min - 0.2, short_name, fontsize=8, ha='center', va='top',\n",
    "                fontweight='bold', color='#333333')\n",
    "\n",
    "        # Seat count text (below school name)\n",
    "        seat_texts[school] = ax.text(\n",
    "            x, y_min - 0.55, f'[{total}]',\n",
    "            fontsize=8, ha='center', va='top', color='darkblue'\n",
    "        )\n",
    "\n",
    "        # Cap indicator (below seat count) - shows which categories are capped\n",
    "        cap_indicators[school] = ax.text(\n",
    "            x, y_min - 0.85, '',\n",
    "            fontsize=6, ha='center', va='top', color='red'\n",
    "        )\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # SCORE AXIS LABELS (showing the exponential scale - bunched at bottom, spread at top)\n",
    "    # -------------------------------------------------------------------------\n",
    "    for score in [450, 550, 650, 750, 825, 875, 900]:\n",
    "        y = score_to_y(score, y_min + 0.5, y_max - 0.5)\n",
    "        ax.text(-0.3, y, str(score), fontsize=7, ha='right', va='center', color='gray')\n",
    "        ax.axhline(y=y, xmin=0.01, xmax=0.05, color='lightgray', linewidth=0.5)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # INITIALIZE STUDENT POSITIONS\n",
    "    # Students start stacked by score (highest at top)\n",
    "    # Regions are aligned in vertical columns to show distribution histogram\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # Region x-offsets for histogram-like display\n",
    "    region_x_offsets = {\n",
    "        'north': -0.6,   # Leftmost\n",
    "        'loop':  -0.2,   # Center-left\n",
    "        'west':   0.2,   # Center-right\n",
    "        'south':  0.6,   # Rightmost\n",
    "    }\n",
    "\n",
    "    student_x = np.array([\n",
    "        pool_x + region_x_offsets.get(row['Region'], 0)\n",
    "        for _, row in sample_df.iterrows()\n",
    "    ], dtype=float)\n",
    "\n",
    "    student_y = np.array([\n",
    "        score_to_y(row['Score'], y_min + 0.5, y_max - 0.5)\n",
    "        for _, row in sample_df.iterrows()\n",
    "    ])\n",
    "\n",
    "    # Add small vertical jitter only (keep horizontal alignment for histogram effect)\n",
    "    student_y += np.random.uniform(-0.05, 0.05, n_students)\n",
    "    # Small horizontal jitter within region column\n",
    "    student_x += np.random.uniform(-0.12, 0.12, n_students)\n",
    "\n",
    "    # Initial colors (all students shown by region/tier)\n",
    "    student_colors = [\n",
    "        get_student_color(row['Region'], row['Tier'], 'tier')\n",
    "        for _, row in sample_df.iterrows()\n",
    "    ]\n",
    "\n",
    "    # Track match type for color updates\n",
    "    match_types = ['pool'] * n_students  # 'pool', 'rank', 'tier', 'unmatched'\n",
    "\n",
    "    scatter = ax.scatter(student_x, student_y, c=student_colors, s=20,\n",
    "                        edgecolors='white', linewidths=0.3, zorder=5)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # TRACKING STATE\n",
    "    # -------------------------------------------------------------------------\n",
    "    remaining_seats = {\n",
    "        school: {k: v for k, v in counts.items()}\n",
    "        for school, counts in seat_counts.items()\n",
    "    }\n",
    "\n",
    "    dest_counts = defaultdict(int)  # Count per destination for stacking\n",
    "\n",
    "    # Build processing order:\n",
    "    # Phase 1: All students by score (for rank seats)\n",
    "    # Phase 2: Students by tier, then by score within tier\n",
    "\n",
    "    # Create tier-sorted indices for phase 2\n",
    "    tier_indices = {t: [] for t in [1, 2, 3, 4]}\n",
    "    for idx, row in sample_df.iterrows():\n",
    "        tier_indices[row['Tier']].append(idx)\n",
    "\n",
    "    # Processing queue: list of (student_idx, phase, tier_for_phase2)\n",
    "    processing_queue = []\n",
    "\n",
    "    # Phase 1: all students in score order (already sorted)\n",
    "    for idx in range(n_students):\n",
    "        processing_queue.append((idx, 'rank', None))\n",
    "\n",
    "    # Phase 2: by tier, each tier in score order\n",
    "    for tier in [1, 2, 3, 4]:\n",
    "        for idx in tier_indices[tier]:\n",
    "            processing_queue.append((idx, 'tier', tier))\n",
    "\n",
    "    state = {\n",
    "        'queue_pos': 0,\n",
    "        'phase': 'rank',\n",
    "        'current_tier': None,\n",
    "        'matched': set(),  # Track which students are already matched\n",
    "        'rank_phase_done': False,\n",
    "    }\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # LEGEND\n",
    "    # -------------------------------------------------------------------------\n",
    "    legend_handles = [\n",
    "        mpatches.Patch(color='#111111', label='Rank Match', alpha=0.9),\n",
    "        mpatches.Patch(color=REGION_BASE_COLORS['north'], label='North', alpha=0.8),\n",
    "        mpatches.Patch(color=REGION_BASE_COLORS['loop'], label='Loop', alpha=0.8),\n",
    "        mpatches.Patch(color=REGION_BASE_COLORS['west'], label='West', alpha=0.8),\n",
    "        mpatches.Patch(color=REGION_BASE_COLORS['south'], label='South', alpha=0.8),\n",
    "    ]\n",
    "    ax.legend(handles=legend_handles, loc='lower left', fontsize=5,\n",
    "             title='Match Type / Region', framealpha=0.9)\n",
    "\n",
    "    # Progress counter\n",
    "    progress_text = ax.text(\n",
    "        unmatched_x, y_min - 1.5,\n",
    "        'Matched: 0 | Unmatched: 0',\n",
    "        fontsize=9, ha='center', va='top'\n",
    "    )\n",
    "\n",
    "    matched_count = [0]\n",
    "    unmatched_count = [0]\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # HELPER: Update cap indicators for a school\n",
    "    # -------------------------------------------------------------------------\n",
    "    def update_caps(school_name):\n",
    "        caps = []\n",
    "        if remaining_seats[school_name].get('Rank', 0) == 0:\n",
    "            caps.append('R')\n",
    "        for t in [1, 2, 3, 4]:\n",
    "            if remaining_seats[school_name].get(t, 0) == 0:\n",
    "                caps.append(f'T{t}')\n",
    "        cap_indicators[school_name].set_text(' '.join(caps))\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # HELPER: Assign student to destination\n",
    "    # -------------------------------------------------------------------------\n",
    "    def assign_student(student_idx, dest_type, school_name=None, match_type='tier'):\n",
    "        if dest_type == 'school' and school_name:\n",
    "            dest_key = school_name\n",
    "            x = school_start_x + school_to_idx[school_name] * school_spacing\n",
    "        else:\n",
    "            dest_key = 'unmatched'\n",
    "            x = unmatched_x\n",
    "\n",
    "        count = dest_counts[dest_key]\n",
    "        dest_counts[dest_key] += 1\n",
    "\n",
    "        # Stack from bottom, wrap if too many\n",
    "        col_height = y_max - y_min - 1\n",
    "        row = count % 40\n",
    "        col_offset = (count // 40) * 0.25\n",
    "\n",
    "        y = y_min + 0.3 + (row * 0.2)\n",
    "        x_jitter = np.random.uniform(-0.25, 0.25) + col_offset\n",
    "\n",
    "        student_x[student_idx] = x + x_jitter\n",
    "        student_y[student_idx] = y\n",
    "        match_types[student_idx] = match_type\n",
    "\n",
    "        # Update color based on match type\n",
    "        row_data = sample_df.iloc[student_idx]\n",
    "        if match_type == 'rank':\n",
    "            student_colors[student_idx] = (0.1, 0.1, 0.1, 0.9)  # Black for rank\n",
    "        elif match_type == 'unmatched':\n",
    "            student_colors[student_idx] = (0.5, 0.5, 0.5, 0.5)  # Gray for unmatched\n",
    "        else:\n",
    "            student_colors[student_idx] = get_student_color(\n",
    "                row_data['Region'], row_data['Tier'], 'tier'\n",
    "            )\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # ANIMATION UPDATE\n",
    "    # -------------------------------------------------------------------------\n",
    "    def update(frame):\n",
    "        # Process multiple students per frame\n",
    "        for _ in range(students_per_frame):\n",
    "            if state['queue_pos'] >= len(processing_queue):\n",
    "                # Animation complete\n",
    "                title_text.set_text('SEHS Match Complete')\n",
    "                phase_text.set_text(\n",
    "                    f'Total Matched: {matched_count[0]} | Unmatched: {unmatched_count[0]}'\n",
    "                )\n",
    "                return scatter, title_text, phase_text, progress_text\n",
    "            \n",
    "            student_idx, phase, tier_target = processing_queue[state['queue_pos']]\n",
    "            state['queue_pos'] += 1\n",
    "            \n",
    "            # Skip if already matched\n",
    "            if student_idx in state['matched']:\n",
    "                continue\n",
    "            \n",
    "            student = sample_df.iloc[student_idx]\n",
    "            student_tier = student['Tier']\n",
    "            prefs = student.get('Preferences', [])\n",
    "            \n",
    "            if phase == 'rank':\n",
    "                # Phase 1: Rank-based matching\n",
    "                if not state['rank_phase_done']:\n",
    "                    title_text.set_text('CPS Selective Enrollment Match Process Simulation (Scaled down 10x)')\n",
    "                    phase_text.set_text('Phase 1: RANK-BASED (Top 30% of seats)')\n",
    "                    state['phase'] = 'rank'\n",
    "                \n",
    "                # Check if all rank seats are gone\n",
    "                total_rank_seats = sum(\n",
    "                    remaining_seats[s].get('Rank', 0) for s in school_order\n",
    "                )\n",
    "                if total_rank_seats == 0:\n",
    "                    state['rank_phase_done'] = True\n",
    "                    continue\n",
    "                \n",
    "                if isinstance(prefs, list) and len(prefs) > 0:\n",
    "                    for school in prefs:\n",
    "                        if school in remaining_seats:\n",
    "                            if remaining_seats[school].get('Rank', 0) > 0:\n",
    "                                # Match!\n",
    "                                assign_student(student_idx, 'school', school, 'rank')\n",
    "                                remaining_seats[school]['Rank'] -= 1\n",
    "                                state['matched'].add(student_idx)\n",
    "                                matched_count[0] += 1\n",
    "                                \n",
    "                                # Update displays\n",
    "                                total_rem = sum(\n",
    "                                    v for k, v in remaining_seats[school].items() \n",
    "                                    if k != 'total'\n",
    "                                )\n",
    "                                seat_texts[school].set_text(str(total_rem))\n",
    "                                update_caps(school)\n",
    "                                break\n",
    "            \n",
    "            else:\n",
    "                # Phase 2: Tier-based matching\n",
    "                state['phase'] = 'tier'\n",
    "                state['current_tier'] = tier_target\n",
    "                title_text.set_text('CPS Selective Enrollment Match Process Simulation (Scaled down 10x)')\n",
    "                phase_text.set_text(f'Phase 2: TIER-BASED (Tier {tier_target})')\n",
    "                \n",
    "                # Only process if student is in current tier\n",
    "                if student_tier != tier_target:\n",
    "                    continue\n",
    "                \n",
    "                if isinstance(prefs, list) and len(prefs) > 0:\n",
    "                    matched = False\n",
    "                    for school in prefs:\n",
    "                        if school in remaining_seats:\n",
    "                            if remaining_seats[school].get(student_tier, 0) > 0:\n",
    "                                # Match!\n",
    "                                assign_student(student_idx, 'school', school, 'tier')\n",
    "                                remaining_seats[school][student_tier] -= 1\n",
    "                                state['matched'].add(student_idx)\n",
    "                                matched_count[0] += 1\n",
    "                                matched = True\n",
    "                                \n",
    "                                # Update displays\n",
    "                                total_rem = sum(\n",
    "                                    v for k, v in remaining_seats[school].items() \n",
    "                                    if k != 'total'\n",
    "                                )\n",
    "                                seat_texts[school].set_text(str(total_rem))\n",
    "                                update_caps(school)\n",
    "                                break\n",
    "                    \n",
    "                    if not matched:\n",
    "                        # No seats available - unmatched\n",
    "                        assign_student(student_idx, 'unmatched', match_type='unmatched')\n",
    "                        state['matched'].add(student_idx)\n",
    "                        unmatched_count[0] += 1\n",
    "                else:\n",
    "                    # No preferences - unmatched\n",
    "                    assign_student(student_idx, 'unmatched', match_type='unmatched')\n",
    "                    state['matched'].add(student_idx)\n",
    "                    unmatched_count[0] += 1\n",
    "        \n",
    "        # Update scatter plot\n",
    "        scatter.set_offsets(np.column_stack([student_x, student_y]))\n",
    "        scatter.set_facecolors(student_colors)\n",
    "        \n",
    "        # Update progress\n",
    "        progress_text.set_text(\n",
    "            f'Matched: {matched_count[0]} | Unmatched: {unmatched_count[0]}'\n",
    "        )\n",
    "        \n",
    "        return scatter, title_text, phase_text, progress_text\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # CREATE ANIMATION\n",
    "    # -------------------------------------------------------------------------\n",
    "    n_frames = (len(processing_queue) // students_per_frame) + 10\n",
    "    \n",
    "    anim = animation.FuncAnimation(\n",
    "        fig, update, frames=n_frames,\n",
    "        interval=interval_ms, blit=False, repeat=False\n",
    "    )\n",
    "    \n",
    "    plt.close(fig)\n",
    "    return anim\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# RUN THE ANIMATION\n",
    "# ============================================================================\n",
    "print(\"Generating students for animation...\")\n",
    "# Generate 2000 students (scaled down from 22000 for visualization)\n",
    "students_for_anim = generate_students(n=2000, seed=42)\n",
    "\n",
    "print(\"Calculating preferences...\")\n",
    "students_for_anim['Preferences'] = students_for_anim.apply(calculate_preferences, axis=1)\n",
    "students_for_anim['TieBreaker'] = np.random.random(len(students_for_anim))\n",
    "\n",
    "print(\"Creating animation (this may take a moment)...\")\n",
    "print(f\"Simulating {len(students_for_anim)} students competing for ~{sum(s.seats//10 for s in SCHOOLS.values())} seats\")\n",
    "print(\"The animation will show:\")\n",
    "print(\"  - Phase 1: Rank-based matching (30% of seats, black dots)\")\n",
    "print(\"  - Phase 2: Tier-based matching (Tiers 1-4, colored by region)\")\n",
    "print()\n",
    "\n",
    "# Increase embed limit for larger animations\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['animation.embed_limit'] = 100  # 100 MB limit\n",
    "\n",
    "anim = create_match_animation(\n",
    "    students_for_anim,\n",
    "    sample_size=2000,      # Use all 2000 generated students\n",
    "    interval_ms=5,        # Very fast animation\n",
    "    students_per_frame=10  # Process 20 students per frame for speed\n",
    ")\n",
    "\n",
    "print(\"Rendering animation... (this may take 30-60 seconds)\")\n",
    "HTML(anim.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Findings and Implications\n",
    "\n",
    "## Summary of Insights\n",
    "\n",
    "This analysis reveals several striking patterns in the CPS Selective Enrollment High School admissions process. The findings are organized into four major themes, each with significant implications for students, families, and policymakers.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. The Tier System Creates Massive Score Advantages (40-113 Points)\n",
    "\n",
    "The tier-based admissions policy generates substantial score differentials across socioeconomic groups:\n",
    "\n",
    "| School | Tier 1 Cutoff | Tier 4 Cutoff | Tier Gap |\n",
    "|--------|---------------|---------------|----------|\n",
    "| **Lane Tech** | 746 | 859 | **113 pts** |\n",
    "| **Northside** | 706.5 | 893 | **186.5 pts** |\n",
    "| **Whitney Young** | 807 | 880 | **73 pts** |\n",
    "| **Payton** | 796 | 898 | **102 pts** |\n",
    "| **Jones** | 775 | 864 | **89 pts** |\n",
    "\n",
    "**Interpretation:** A Tier 1 student can gain admission to Lane Tech with a score that would be 113 points below the Tier 4 threshold. This is the policy working as designedcreating pathways for students from under-resourced neighborhoodsbut the magnitude is striking. At elite schools, tier assignment can be worth more than an entire letter grade on the composite score.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Published Averages Are Systematically Misleading (~140-150 Points)\n",
    "\n",
    "The MLE analysis reveals a fundamental statistical illusion in CPS's published data:\n",
    "\n",
    "| School | Published Average (Admitted) | MLE-Recovered Population Mean | Selection Bias |\n",
    "|--------|------------------------------|-------------------------------|----------------|\n",
    "| Payton T1 | 841.3 | ~719 | **~122 pts** |\n",
    "| Lane Tech T1 | 758.2 | ~546 | **~212 pts** |\n",
    "| Northside T4 | 894.3 | ~888 | **~6 pts** |\n",
    "\n",
    "**The Truncation Problem:** CPS publishes the average score of *admitted* students, not all applicants. This is mathematically guaranteed to exceed the true population mean due to truncation at the cutoff. Our MLE recovers the hidden parameters by inverting the truncated normal distribution.\n",
    "\n",
    "**Practical Impact:** A parent seeing \"average: 876 at Payton\" might conclude their 850-scoring child is below average. In reality, an 850 likely places them well above the applicant pool mean. The published statistics, while accurate, create a distorted picture of competitiveness.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Two Distinct SEHS Systems Exist Within One Policy\n",
    "\n",
    "The data reveals a **bifurcated system** with fundamentally different competitive dynamics:\n",
    "\n",
    "### Elite Schools (Payton, Northside, Young, Jones, Lane Tech)\n",
    "- **T4 Hidden Mean:** $\\mu \\approx 830-870$\n",
    "- **T4 Hidden SD:** $\\sigma \\approx 15-25$ (very tight)\n",
    "- **Competition:** Extremely intense; 5-10 point differences are decisive\n",
    "- **Geographic draw:** Citywide, especially North Side and Loop\n",
    "\n",
    "### Regional Schools (Lindblom, Hancock, Brooks, King, Westinghouse, South Shore)\n",
    "- **T4 Hidden Mean:** $\\mu \\approx 600-700$\n",
    "- **T4 Hidden SD:** $\\sigma \\approx 60-100$ (much wider)\n",
    "- **Competition:** Less intense; 30-50 point buffers are common\n",
    "- **Geographic draw:** Primarily local neighborhoods\n",
    "\n",
    "**Implication:** These are not simply \"more selective\" vs \"less selective\" versions of the same school type. They serve different populations with different score distributions, different geographic catchments, and different competitive pressures. Modeling them requires distinct parameter sets.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Three Regional Schools Exhibit Inverted Tier Gaps\n",
    "\n",
    "A counterintuitive pattern emerges at Lindblom, King, and South Shore:\n",
    "\n",
    "| School | Tier 1 Cutoff | Tier 4 Cutoff | Gap Direction |\n",
    "|--------|---------------|---------------|---------------|\n",
    "| Lindblom | 703 | 792 | Normal (+89) |\n",
    "| King | 654 | 774 | Normal (+120) |\n",
    "| South Shore | 576 | 711 | Normal (+135) |\n",
    "\n",
    "*2024 data shows these gaps, but 2025 shows dramatic inversions at some schools.*\n",
    "\n",
    "**Possible Explanations:**\n",
    "1. **Geographic preference:** Tier 1 students in South/West Side neighborhoods may preferentially rank local schools higher, creating concentrated demand\n",
    "2. **Elite school avoidance:** High-scoring Tier 1 students may not apply to Payton/Northside due to distance or cultural factors, redirecting competition to regional schools\n",
    "3. **Information asymmetry:** Tier 4 families may be more likely to use regional schools as \"safety\" choices, diluting competition\n",
    "\n",
    "This warrants further investigationit suggests the tier system's effects are not uniform across the school landscape.\n",
    "\n",
    "---\n",
    "\n",
    "## Policy Implications\n",
    "\n",
    "### For Parents and Students\n",
    "\n",
    "1. **Don't be intimidated by published averages.** They are inflated by 100-200 points due to selection bias. Your score's percentile in the applicant pool is far higher than it appears.\n",
    "\n",
    "2. **Tier 1/2 families have significant structural advantages at elite schools.** A Tier 1 student scoring 750 has realistic chances at Lane Tech; a Tier 4 student needs 860+.\n",
    "\n",
    "3. **Regional schools offer genuine pathways for students scoring 550-750.** These are not \"lesser\" optionsthey are academically rigorous schools with less cutthroat admissions.\n",
    "\n",
    "4. **Consider geographic distance seriously.** The simulation shows cross-region penalties in student preferences. A South Side student ranking only North Side schools may face implicit disadvantages.\n",
    "\n",
    "### For CPS and Policymakers\n",
    "\n",
    "1. **The tier system is achieving socioeconomic diversity**, but the magnitude of tier advantage varies wildly by school (40 pts at some, 180+ at others). Consider whether this variation is intentional.\n",
    "\n",
    "2. **Publishing applicant-pool statistics** (not just admitted) would help families make informed choices and reduce the misleading nature of current data.\n",
    "\n",
    "3. **The inverted gaps at regional schools** suggest uneven demand patterns worth investigating. Are Tier 1 students being funneled into a subset of schools?\n",
    "\n",
    "4. **Model transparency:** The matching algorithm is strategy-proof, but the score distributions and preference models that determine outcomes are opaque. Greater transparency would build trust.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T13:34:07.511974Z",
     "start_time": "2025-11-29T13:34:05.404323Z"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# COMPREHENSIVE FINAL ANALYSIS: KEY VISUALIZATIONS\n",
    "# ============================================================================\n",
    "# This cell generates a series of publication-quality visualizations that\n",
    "# highlight the most striking findings from the MLE and simulation analysis.\n",
    "# ============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "\n",
    "# Use a clean style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# DATA: MLE-Recovered Parameters and Cutoffs\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "# MLE-recovered hidden population parameters (from individual school analyses)\n",
    "mle_params = {\n",
    "    'Walter Payton': {1: {'mu': 266.7, 'sigma': 200.0}, 4: {'mu': 770.0, 'sigma': 81.9}},\n",
    "    'Northside': {1: {'mu': 448.0, 'sigma': 167.4}, 4: {'mu': 887.7, 'sigma': 3.4}},\n",
    "    'Whitney Young': {1: {'mu': 548.4, 'sigma': 169.0}, 4: {'mu': 844.1, 'sigma': 23.5}},\n",
    "    'Jones': {1: {'mu': 605.6, 'sigma': 110.7}, 4: {'mu': 838.8, 'sigma': 16.5}},\n",
    "    'Lane Tech': {1: {'mu': 545.6, 'sigma': 109.7}, 4: {'mu': 830.6, 'sigma': 18.7}},\n",
    "    'Lindblom': {1: {'mu': 490.4, 'sigma': 152.5}, 4: {'mu': 671.4, 'sigma': 86.5}},\n",
    "    'Hancock': {1: {'mu': 642.6, 'sigma': 74.2}, 4: {'mu': 659.2, 'sigma': 81.6}},\n",
    "    'Brooks': {1: {'mu': 430.0, 'sigma': 200.0}, 4: {'mu': 663.1, 'sigma': 73.8}},\n",
    "    'King': {1: {'mu': 383.9, 'sigma': 200.0}, 4: {'mu': 690.3, 'sigma': 60.1}},\n",
    "    'Westinghouse': {1: {'mu': 411.9, 'sigma': 173.0}, 4: {'mu': 603.1, 'sigma': 96.4}},\n",
    "    'South Shore': {1: {'mu': 304.6, 'sigma': 196.9}, 4: {'mu': 590.1, 'sigma': 87.7}},\n",
    "}\n",
    "\n",
    "# Actual cutoffs (2024 calibration data)\n",
    "cutoffs = {\n",
    "    'Walter Payton': {1: 796, 4: 898, 'Rank': 900},\n",
    "    'Northside': {1: 706.5, 4: 893, 'Rank': 895},\n",
    "    'Whitney Young': {1: 807, 4: 880, 'Rank': 893},\n",
    "    'Jones': {1: 775, 4: 864, 'Rank': 880},\n",
    "    'Lane Tech': {1: 712, 4: 859, 'Rank': 877},\n",
    "    'Lindblom': {1: 703, 4: 792, 'Rank': 827},\n",
    "    'Hancock': {1: 746, 4: 773, 'Rank': 808},\n",
    "    'Brooks': {1: 683, 4: 766, 'Rank': 825},\n",
    "    'King': {1: 654, 4: 774, 'Rank': 808},\n",
    "    'Westinghouse': {1: 653, 4: 737.5, 'Rank': 780},\n",
    "    'South Shore': {1: 576, 4: 711, 'Rank': 777},\n",
    "}\n",
    "\n",
    "# Published averages (admitted students only)\n",
    "published_avgs = {\n",
    "    'Walter Payton': {1: 841.3, 4: 899.7},\n",
    "    'Northside': {1: 768.5, 4: 894.3},\n",
    "    'Whitney Young': {1: 846.0, 4: 887.4},\n",
    "    'Jones': {1: 815.7, 4: 871.1},\n",
    "    'Lane Tech': {1: 758.2, 4: 867.1},\n",
    "    'Lindblom': {1: 720.1, 4: 667.4},\n",
    "    'Hancock': {1: 779.3, 4: 807.9},\n",
    "    'Brooks': {1: 729.0, 4: 747.7},\n",
    "    'King': {1: 567.0, 4: 573.1},\n",
    "    'Westinghouse': {1: 700.2, 4: 703.6},\n",
    "    'South Shore': {1: 587.9, 4: 568.1},\n",
    "}\n",
    "\n",
    "elite_schools = ['Walter Payton', 'Northside', 'Whitney Young', 'Jones', 'Lane Tech']\n",
    "regional_schools = ['Lindblom', 'Hancock', 'Brooks', 'King', 'Westinghouse', 'South Shore']\n",
    "all_schools = elite_schools + regional_schools\n",
    "\n",
    "# Short names for plotting\n",
    "short_names = {\n",
    "    'Walter Payton': 'Payton', 'Northside': 'Northside', 'Whitney Young': 'Young',\n",
    "    'Jones': 'Jones', 'Lane Tech': 'Lane', 'Lindblom': 'Lindblom',\n",
    "    'Hancock': 'Hancock', 'Brooks': 'Brooks', 'King': 'King',\n",
    "    'Westinghouse': 'Westinghouse', 'South Shore': 'S. Shore'\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# FIGURE 1: The Tier Gap - How Much Is Your Tier Worth?\n",
    "# ============================================================================\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "schools = all_schools\n",
    "x = np.arange(len(schools))\n",
    "width = 0.35\n",
    "\n",
    "t1_cutoffs = [cutoffs[s][1] for s in schools]\n",
    "t4_cutoffs = [cutoffs[s][4] for s in schools]\n",
    "tier_gaps = [t4 - t1 for t1, t4 in zip(t1_cutoffs, t4_cutoffs)]\n",
    "\n",
    "# Create grouped bar chart\n",
    "bars1 = ax1.bar(x - width/2, t1_cutoffs, width, label='Tier 1 Cutoff', color='#2ecc71', alpha=0.8)\n",
    "bars2 = ax1.bar(x + width/2, t4_cutoffs, width, label='Tier 4 Cutoff', color='#e74c3c', alpha=0.8)\n",
    "\n",
    "# Add tier gap annotations\n",
    "for i, (t1, t4, gap) in enumerate(zip(t1_cutoffs, t4_cutoffs, tier_gaps)):\n",
    "    mid = (t1 + t4) / 2\n",
    "    ax1.annotate(f'+{gap:.0f}', xy=(i, mid), ha='center', va='center',\n",
    "                fontsize=9, fontweight='bold', color='#2c3e50',\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', edgecolor='gray', alpha=0.8))\n",
    "\n",
    "# Highlight elite vs regional\n",
    "ax1.axvline(x=4.5, color='gray', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "ax1.text(2, 920, 'ELITE SCHOOLS', ha='center', fontsize=11, fontweight='bold', color='#2c3e50')\n",
    "ax1.text(7.5, 920, 'REGIONAL SCHOOLS', ha='center', fontsize=11, fontweight='bold', color='#2c3e50')\n",
    "\n",
    "ax1.set_xlabel('School', fontsize=12)\n",
    "ax1.set_ylabel('Cutoff Score', fontsize=12)\n",
    "ax1.set_title('The Tier Advantage: Cutoff Score Gaps Between Tier 1 and Tier 4\\n(Numbers show point advantage for Tier 1 students)', \n",
    "              fontsize=14, fontweight='bold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels([short_names[s] for s in schools], rotation=45, ha='right')\n",
    "ax1.set_ylim(500, 950)\n",
    "ax1.legend(loc='lower right')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('insight_1_tier_gaps.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure 1: Tier gaps range from 27 points (Hancock) to 186 points (Northside)\")\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# FIGURE 2: Selection Bias - Published vs True Means\n",
    "# ============================================================================\n",
    "\n",
    "fig2, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# Left panel: Tier 1\n",
    "ax2a = axes[0]\n",
    "schools_t1 = all_schools\n",
    "x = np.arange(len(schools_t1))\n",
    "width = 0.35\n",
    "\n",
    "published_t1 = [published_avgs[s][1] for s in schools_t1]\n",
    "true_t1 = [mle_params[s][1]['mu'] for s in schools_t1]\n",
    "bias_t1 = [p - t for p, t in zip(published_t1, true_t1)]\n",
    "\n",
    "bars1 = ax2a.bar(x - width/2, true_t1, width, label='True Population Mean (MLE)', color='#3498db', alpha=0.8)\n",
    "bars2 = ax2a.bar(x + width/2, published_t1, width, label='Published Average (Admitted)', color='#e67e22', alpha=0.8)\n",
    "\n",
    "# Add bias annotations for largest gaps\n",
    "for i, bias in enumerate(bias_t1):\n",
    "    if bias > 100:\n",
    "        ax2a.annotate(f'+{bias:.0f}', xy=(i + width/2, published_t1[i] + 10), \n",
    "                     ha='center', fontsize=8, color='#c0392b', fontweight='bold')\n",
    "\n",
    "ax2a.set_xlabel('School', fontsize=11)\n",
    "ax2a.set_ylabel('Score', fontsize=11)\n",
    "ax2a.set_title('Tier 1: Selection Bias in Published Averages', fontsize=12, fontweight='bold')\n",
    "ax2a.set_xticks(x)\n",
    "ax2a.set_xticklabels([short_names[s] for s in schools_t1], rotation=45, ha='right')\n",
    "ax2a.set_ylim(200, 900)\n",
    "ax2a.legend(loc='upper left', fontsize=9)\n",
    "ax2a.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Right panel: Tier 4\n",
    "ax2b = axes[1]\n",
    "published_t4 = [published_avgs[s][4] for s in schools_t1]\n",
    "true_t4 = [mle_params[s][4]['mu'] for s in schools_t1]\n",
    "bias_t4 = [p - t for p, t in zip(published_t4, true_t4)]\n",
    "\n",
    "bars1 = ax2b.bar(x - width/2, true_t4, width, label='True Population Mean (MLE)', color='#3498db', alpha=0.8)\n",
    "bars2 = ax2b.bar(x + width/2, published_t4, width, label='Published Average (Admitted)', color='#e67e22', alpha=0.8)\n",
    "\n",
    "ax2b.set_xlabel('School', fontsize=11)\n",
    "ax2b.set_ylabel('Score', fontsize=11)\n",
    "ax2b.set_title('Tier 4: Selection Bias in Published Averages', fontsize=12, fontweight='bold')\n",
    "ax2b.set_xticks(x)\n",
    "ax2b.set_xticklabels([short_names[s] for s in schools_t1], rotation=45, ha='right')\n",
    "ax2b.set_ylim(500, 950)\n",
    "ax2b.legend(loc='upper left', fontsize=9)\n",
    "ax2b.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.suptitle('The Selection Bias Illusion: What CPS Publishes vs. Reality\\n(Published averages are truncated means that overstate typical applicant scores)', \n",
    "             fontsize=13, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('insight_2_selection_bias.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure 2: Selection bias inflates published T1 averages by 100-300+ points at elite schools\")\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# FIGURE 3: Two SEHS Systems - Elite vs Regional Distribution Comparison\n",
    "# ============================================================================\n",
    "\n",
    "fig3, ax3 = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "x_range = np.linspace(400, 920, 500)\n",
    "\n",
    "# Plot T4 distributions for elite schools\n",
    "elite_colors = plt.cm.Blues(np.linspace(0.4, 0.9, len(elite_schools)))\n",
    "for i, school in enumerate(elite_schools):\n",
    "    mu = mle_params[school][4]['mu']\n",
    "    sigma = mle_params[school][4]['sigma']\n",
    "    y = norm.pdf(x_range, mu, sigma)\n",
    "    ax3.fill_between(x_range, y, alpha=0.3, color=elite_colors[i])\n",
    "    ax3.plot(x_range, y, linewidth=2, color=elite_colors[i], label=f'{short_names[school]} (={mu:.0f}, ={sigma:.0f})')\n",
    "\n",
    "# Plot T4 distributions for regional schools\n",
    "regional_colors = plt.cm.Oranges(np.linspace(0.4, 0.9, len(regional_schools)))\n",
    "for i, school in enumerate(regional_schools):\n",
    "    mu = mle_params[school][4]['mu']\n",
    "    sigma = mle_params[school][4]['sigma']\n",
    "    y = norm.pdf(x_range, mu, sigma)\n",
    "    ax3.fill_between(x_range, y, alpha=0.3, color=regional_colors[i])\n",
    "    ax3.plot(x_range, y, linewidth=2, color=regional_colors[i], linestyle='--',\n",
    "             label=f'{short_names[school]} (={mu:.0f}, ={sigma:.0f})')\n",
    "\n",
    "ax3.set_xlabel('Composite Score', fontsize=12)\n",
    "ax3.set_ylabel('Probability Density', fontsize=12)\n",
    "ax3.set_title('Two Distinct Systems: Tier 4 Score Distributions at Elite vs Regional Schools\\n(MLE-Recovered Hidden Population Distributions)', \n",
    "              fontsize=13, fontweight='bold')\n",
    "ax3.legend(loc='upper left', fontsize=8, ncol=2)\n",
    "ax3.set_xlim(400, 920)\n",
    "ax3.grid(alpha=0.3)\n",
    "\n",
    "# Add annotation boxes\n",
    "ax3.annotate('ELITE SCHOOLS\\nTight distributions (  15-80)\\nCentered around 830-890', \n",
    "            xy=(850, 0.08), fontsize=10, ha='center',\n",
    "            bbox=dict(boxstyle='round,pad=0.5', facecolor='#d5e8f7', edgecolor='#3498db', alpha=0.9))\n",
    "ax3.annotate('REGIONAL SCHOOLS\\nWide distributions (  60-100)\\nCentered around 590-700', \n",
    "            xy=(650, 0.012), fontsize=10, ha='center',\n",
    "            bbox=dict(boxstyle='round,pad=0.5', facecolor='#fdebd0', edgecolor='#e67e22', alpha=0.9))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('insight_3_two_systems.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure 3: Elite T4 distributions are extremely tight; regional schools have 4-5x wider spreads\")\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# FIGURE 4: The Sigma Story - Distribution Width by School Type\n",
    "# ============================================================================\n",
    "\n",
    "fig4, ax4 = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# Collect sigma values\n",
    "schools_ordered = elite_schools + regional_schools\n",
    "t1_sigmas = [mle_params[s][1]['sigma'] for s in schools_ordered]\n",
    "t4_sigmas = [mle_params[s][4]['sigma'] for s in schools_ordered]\n",
    "\n",
    "x = np.arange(len(schools_ordered))\n",
    "width = 0.35\n",
    "\n",
    "colors_t1 = ['#27ae60' if s in elite_schools else '#f39c12' for s in schools_ordered]\n",
    "colors_t4 = ['#2980b9' if s in elite_schools else '#e74c3c' for s in schools_ordered]\n",
    "\n",
    "bars1 = ax4.bar(x - width/2, t1_sigmas, width, label='Tier 1 ', color=colors_t1, alpha=0.8, edgecolor='white')\n",
    "bars2 = ax4.bar(x + width/2, t4_sigmas, width, label='Tier 4 ', color=colors_t4, alpha=0.8, edgecolor='white')\n",
    "\n",
    "ax4.axvline(x=4.5, color='gray', linestyle='--', linewidth=2, alpha=0.7)\n",
    "ax4.text(2, 210, 'ELITE', ha='center', fontsize=12, fontweight='bold')\n",
    "ax4.text(7.5, 210, 'REGIONAL', ha='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Highlight the extremes\n",
    "ax4.annotate('Northside T4:\\n = 3.4 (!)', xy=(1 + width/2, 3.4), xytext=(1.5, 50),\n",
    "            arrowprops=dict(arrowstyle='->', color='#c0392b'), fontsize=9, color='#c0392b')\n",
    "\n",
    "ax4.set_xlabel('School', fontsize=12)\n",
    "ax4.set_ylabel('Standard Deviation ()', fontsize=12)\n",
    "ax4.set_title('Distribution Width (): How Spread Out Are Applicant Scores?\\n(Lower  = more competitive, tighter clustering at high scores)', \n",
    "              fontsize=13, fontweight='bold')\n",
    "ax4.set_xticks(x)\n",
    "ax4.set_xticklabels([short_names[s] for s in schools_ordered], rotation=45, ha='right')\n",
    "ax4.legend(loc='upper right')\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('insight_4_sigma_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure 4: Northside T4 has =3.4 (essentially everyone scores 885-895)\")\n",
    "print(\"         Regional schools have =60-100 (much more variance in applicant quality)\")\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# FIGURE 5: Combined Summary - The Complete Picture\n",
    "# ============================================================================\n",
    "\n",
    "fig5, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "\n",
    "# Panel A: Tier Gap Heatmap\n",
    "ax5a = axes[0, 0]\n",
    "tier_gap_data = []\n",
    "for school in all_schools:\n",
    "    gap = cutoffs[school][4] - cutoffs[school][1]\n",
    "    tier_gap_data.append({\n",
    "        'School': short_names[school],\n",
    "        'Type': 'Elite' if school in elite_schools else 'Regional',\n",
    "        'Tier Gap': gap\n",
    "    })\n",
    "tier_gap_df = pd.DataFrame(tier_gap_data)\n",
    "\n",
    "colors = ['#3498db' if t == 'Elite' else '#e74c3c' for t in tier_gap_df['Type']]\n",
    "bars = ax5a.barh(tier_gap_df['School'], tier_gap_df['Tier Gap'], color=colors, alpha=0.8)\n",
    "ax5a.set_xlabel('Tier Gap (T4 Cutoff - T1 Cutoff)', fontsize=11)\n",
    "ax5a.set_title('A. Tier Advantage by School', fontsize=12, fontweight='bold')\n",
    "ax5a.axvline(x=0, color='gray', linewidth=0.5)\n",
    "\n",
    "for i, (gap, school) in enumerate(zip(tier_gap_df['Tier Gap'], tier_gap_df['School'])):\n",
    "    ax5a.text(gap + 3, i, f'{gap:.0f}', va='center', fontsize=9)\n",
    "\n",
    "# Panel B: Selection Bias (T1)\n",
    "ax5b = axes[0, 1]\n",
    "bias_data = []\n",
    "for school in all_schools:\n",
    "    pub = published_avgs[school][1]\n",
    "    true = mle_params[school][1]['mu']\n",
    "    bias_data.append({\n",
    "        'School': short_names[school],\n",
    "        'Bias': pub - true,\n",
    "        'Type': 'Elite' if school in elite_schools else 'Regional'\n",
    "    })\n",
    "bias_df = pd.DataFrame(bias_data)\n",
    "\n",
    "colors = ['#3498db' if t == 'Elite' else '#e74c3c' for t in bias_df['Type']]\n",
    "bars = ax5b.barh(bias_df['School'], bias_df['Bias'], color=colors, alpha=0.8)\n",
    "ax5b.set_xlabel('Selection Bias (Published - True Mean)', fontsize=11)\n",
    "ax5b.set_title('B. How Much Published Averages Overstate Reality (Tier 1)', fontsize=12, fontweight='bold')\n",
    "ax5b.axvline(x=100, color='orange', linestyle='--', alpha=0.7, label='100 pt bias')\n",
    "ax5b.legend(loc='lower right', fontsize=9)\n",
    "\n",
    "# Panel C: Mean comparison scatter\n",
    "ax5c = axes[1, 0]\n",
    "for school in all_schools:\n",
    "    mu1 = mle_params[school][1]['mu']\n",
    "    mu4 = mle_params[school][4]['mu']\n",
    "    color = '#3498db' if school in elite_schools else '#e74c3c'\n",
    "    marker = 'o' if school in elite_schools else 's'\n",
    "    ax5c.scatter(mu1, mu4, s=150, c=color, marker=marker, alpha=0.8, edgecolors='white', linewidth=2)\n",
    "    ax5c.annotate(short_names[school], (mu1, mu4), xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "\n",
    "ax5c.plot([200, 900], [200, 900], 'k--', alpha=0.3, label='Equal means line')\n",
    "ax5c.set_xlabel('Tier 1 Population Mean ()', fontsize=11)\n",
    "ax5c.set_ylabel('Tier 4 Population Mean ()', fontsize=11)\n",
    "ax5c.set_title('C. Population Means: T1 vs T4 by School', fontsize=12, fontweight='bold')\n",
    "ax5c.set_xlim(200, 900)\n",
    "ax5c.set_ylim(500, 920)\n",
    "ax5c.legend(loc='lower right')\n",
    "ax5c.grid(alpha=0.3)\n",
    "\n",
    "# Panel D: Sigma comparison scatter\n",
    "ax5d = axes[1, 1]\n",
    "for school in all_schools:\n",
    "    sig1 = mle_params[school][1]['sigma']\n",
    "    sig4 = mle_params[school][4]['sigma']\n",
    "    color = '#3498db' if school in elite_schools else '#e74c3c'\n",
    "    marker = 'o' if school in elite_schools else 's'\n",
    "    ax5d.scatter(sig1, sig4, s=150, c=color, marker=marker, alpha=0.8, edgecolors='white', linewidth=2)\n",
    "    ax5d.annotate(short_names[school], (sig1, sig4), xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "\n",
    "ax5d.set_xlabel('Tier 1 Population SD ()', fontsize=11)\n",
    "ax5d.set_ylabel('Tier 4 Population SD ()', fontsize=11)\n",
    "ax5d.set_title('D. Distribution Width: T1 vs T4 by School', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Add legend\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='#3498db', markersize=12, label='Elite Schools'),\n",
    "    Line2D([0], [0], marker='s', color='w', markerfacecolor='#e74c3c', markersize=12, label='Regional Schools')\n",
    "]\n",
    "ax5d.legend(handles=legend_elements, loc='upper right')\n",
    "ax5d.grid(alpha=0.3)\n",
    "\n",
    "plt.suptitle('Comprehensive Analysis: The Hidden Structure of SEHS Admissions', \n",
    "             fontsize=15, fontweight='bold', y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.savefig('insight_5_comprehensive.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"Key Takeaways:\")\n",
    "print(\"  1. Tier gaps range from 27 to 186 points - tier assignment is decisive\")\n",
    "print(\"  2. Published averages overstate applicant means by 100-300+ points\")\n",
    "print(\"  3. Elite and regional schools have fundamentally different distributions\")\n",
    "print(\"  4. Northside T4 is the most competitive (=3.4), South Shore the least (=87.7)\")\n",
    "print()\n",
    "print(\"Figures saved:\")\n",
    "print(\"  - insight_1_tier_gaps.png\")\n",
    "print(\"  - insight_2_selection_bias.png\")\n",
    "print(\"  - insight_3_two_systems.png\")\n",
    "print(\"  - insight_4_sigma_comparison.png\")\n",
    "print(\"  - insight_5_comprehensive.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
